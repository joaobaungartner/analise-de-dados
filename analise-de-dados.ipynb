{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d07a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "303e26ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_bairro</th>\n",
       "      <th>nome_cliente</th>\n",
       "      <th>bairro_destino</th>\n",
       "      <th>order_datetime</th>\n",
       "      <th>platform</th>\n",
       "      <th>order_mode</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>tempo_preparo_minutos</th>\n",
       "      <th>status</th>\n",
       "      <th>eta_minutes_quote</th>\n",
       "      <th>actual_delivery_minutes</th>\n",
       "      <th>total_brl</th>\n",
       "      <th>classe_pedido</th>\n",
       "      <th>platform_commission_pct</th>\n",
       "      <th>num_itens</th>\n",
       "      <th>satisfacao_nivel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outros</td>\n",
       "      <td>Júlia Ramos</td>\n",
       "      <td>Bela Vista</td>\n",
       "      <td>2024-01-01 15:08:00</td>\n",
       "      <td>rappi</td>\n",
       "      <td>delivery</td>\n",
       "      <td>6.916192</td>\n",
       "      <td>34</td>\n",
       "      <td>delivered</td>\n",
       "      <td>50</td>\n",
       "      <td>62.4</td>\n",
       "      <td>288.01</td>\n",
       "      <td>familia</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santo Amaro</td>\n",
       "      <td>Gustavo R. Rezende</td>\n",
       "      <td>Santo Amaro</td>\n",
       "      <td>2024-01-02 07:49:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>5.753085</td>\n",
       "      <td>16</td>\n",
       "      <td>delivered</td>\n",
       "      <td>45</td>\n",
       "      <td>35.6</td>\n",
       "      <td>125.02</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jardins</td>\n",
       "      <td>Valentina Y. Oliveira</td>\n",
       "      <td>Jardins</td>\n",
       "      <td>2024-01-02 10:14:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>4.545672</td>\n",
       "      <td>15</td>\n",
       "      <td>delivered</td>\n",
       "      <td>43</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.76</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vila Olímpia</td>\n",
       "      <td>Mariana Moreira</td>\n",
       "      <td>Vila Olímpia</td>\n",
       "      <td>2024-01-02 10:58:00</td>\n",
       "      <td>site_proprio</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.059679</td>\n",
       "      <td>6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>19</td>\n",
       "      <td>14.4</td>\n",
       "      <td>45.16</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moema</td>\n",
       "      <td>Daniel Rocha</td>\n",
       "      <td>Ibirapuera</td>\n",
       "      <td>2024-01-02 12:56:00</td>\n",
       "      <td>site_proprio</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.102063</td>\n",
       "      <td>25</td>\n",
       "      <td>delivered</td>\n",
       "      <td>28</td>\n",
       "      <td>26.6</td>\n",
       "      <td>123.12</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Moema</td>\n",
       "      <td>Natália G. Souza</td>\n",
       "      <td>Ibirapuera</td>\n",
       "      <td>2024-12-31 17:17:00</td>\n",
       "      <td>rappi</td>\n",
       "      <td>delivery</td>\n",
       "      <td>3.231895</td>\n",
       "      <td>17</td>\n",
       "      <td>delivered</td>\n",
       "      <td>37</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Morumbi</td>\n",
       "      <td>Yasmin N. Ribeiro</td>\n",
       "      <td>Morumbi</td>\n",
       "      <td>2024-12-31 19:33:00</td>\n",
       "      <td>whatsapp</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.218583</td>\n",
       "      <td>6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>18</td>\n",
       "      <td>10.7</td>\n",
       "      <td>75.58</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Pinheiros</td>\n",
       "      <td>Yuri Castro</td>\n",
       "      <td>Pinheiros</td>\n",
       "      <td>2024-12-31 20:12:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>6.389462</td>\n",
       "      <td>28</td>\n",
       "      <td>canceled</td>\n",
       "      <td>47</td>\n",
       "      <td>67.1</td>\n",
       "      <td>145.75</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Itaim</td>\n",
       "      <td>Henrique J. Ferreira</td>\n",
       "      <td>Itaim Bibi</td>\n",
       "      <td>2024-12-31 21:14:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>4.148569</td>\n",
       "      <td>14</td>\n",
       "      <td>delivered</td>\n",
       "      <td>40</td>\n",
       "      <td>32.9</td>\n",
       "      <td>61.36</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Itaim</td>\n",
       "      <td>Helena Duarte</td>\n",
       "      <td>Itaim Bibi</td>\n",
       "      <td>2024-12-31 21:27:00</td>\n",
       "      <td>whatsapp</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.286058</td>\n",
       "      <td>23</td>\n",
       "      <td>delivered</td>\n",
       "      <td>29</td>\n",
       "      <td>21.8</td>\n",
       "      <td>87.40</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      macro_bairro           nome_cliente bairro_destino      order_datetime  \\\n",
       "0           Outros            Júlia Ramos     Bela Vista 2024-01-01 15:08:00   \n",
       "1      Santo Amaro     Gustavo R. Rezende    Santo Amaro 2024-01-02 07:49:00   \n",
       "2          Jardins  Valentina Y. Oliveira        Jardins 2024-01-02 10:14:00   \n",
       "3     Vila Olímpia        Mariana Moreira   Vila Olímpia 2024-01-02 10:58:00   \n",
       "4            Moema           Daniel Rocha     Ibirapuera 2024-01-02 12:56:00   \n",
       "...            ...                    ...            ...                 ...   \n",
       "4995         Moema       Natália G. Souza     Ibirapuera 2024-12-31 17:17:00   \n",
       "4996       Morumbi      Yasmin N. Ribeiro        Morumbi 2024-12-31 19:33:00   \n",
       "4997     Pinheiros            Yuri Castro      Pinheiros 2024-12-31 20:12:00   \n",
       "4998         Itaim   Henrique J. Ferreira     Itaim Bibi 2024-12-31 21:14:00   \n",
       "4999         Itaim          Helena Duarte     Itaim Bibi 2024-12-31 21:27:00   \n",
       "\n",
       "          platform order_mode  distance_km  tempo_preparo_minutos     status  \\\n",
       "0            rappi   delivery     6.916192                     34  delivered   \n",
       "1            ifood   delivery     5.753085                     16  delivered   \n",
       "2            ifood   delivery     4.545672                     15  delivered   \n",
       "3     site_proprio   retirada     0.059679                      6  delivered   \n",
       "4     site_proprio   retirada     0.102063                     25  delivered   \n",
       "...            ...        ...          ...                    ...        ...   \n",
       "4995         rappi   delivery     3.231895                     17  delivered   \n",
       "4996      whatsapp   retirada     0.218583                      6  delivered   \n",
       "4997         ifood   delivery     6.389462                     28   canceled   \n",
       "4998         ifood   delivery     4.148569                     14  delivered   \n",
       "4999      whatsapp   retirada     0.286058                     23  delivered   \n",
       "\n",
       "      eta_minutes_quote  actual_delivery_minutes  total_brl classe_pedido  \\\n",
       "0                    50                     62.4     288.01       familia   \n",
       "1                    45                     35.6     125.02         combo   \n",
       "2                    43                     34.5     110.76         combo   \n",
       "3                    19                     14.4      45.16   prato_unico   \n",
       "4                    28                     26.6     123.12         combo   \n",
       "...                 ...                      ...        ...           ...   \n",
       "4995                 37                     29.0      56.43   prato_unico   \n",
       "4996                 18                     10.7      75.58   prato_unico   \n",
       "4997                 47                     67.1     145.75         combo   \n",
       "4998                 40                     32.9      61.36   prato_unico   \n",
       "4999                 29                     21.8      87.40         combo   \n",
       "\n",
       "      platform_commission_pct  num_itens  satisfacao_nivel  \n",
       "0                        0.16          8                 3  \n",
       "1                        0.16          3                 5  \n",
       "2                        0.12          4                 5  \n",
       "3                        0.00          1                 5  \n",
       "4                        0.00          3                 5  \n",
       "...                       ...        ...               ...  \n",
       "4995                     0.16          3                 5  \n",
       "4996                     0.00          2                 5  \n",
       "4997                     0.16          4                 2  \n",
       "4998                     0.16          1                 5  \n",
       "4999                     0.00          1                 5  \n",
       "\n",
       "[5000 rows x 16 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Base_Kaiserhaus.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dea570",
   "metadata": {},
   "source": [
    "# 📊 ANÁLISE EXPLORATÓRIA COMPLETA\n",
    "\n",
    "## 1. Visão Geral dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4406d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações gerais sobre o dataset\n",
    "print(\"📊 INFORMAÇÕES GERAIS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📈 Shape: {df.shape}\")\n",
    "print(f\"📈 Memória utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"📈 Período dos dados: {df['order_datetime'].min()} até {df['order_datetime'].max()}\")\n",
    "\n",
    "print(f\"\\n📋 TIPOS DE DADOS:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\n📋 VALORES NULOS:\")\n",
    "null_counts = df.isnull().sum()\n",
    "if null_counts.sum() > 0:\n",
    "    for col, nulos in null_counts[null_counts > 0].items():\n",
    "        print(f\"  • {col}: {nulos} valores nulos ({nulos/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"  ✅ Nenhum valor nulo encontrado!\")\n",
    "\n",
    "print(f\"\\n📋 VALORES DUPLICADOS:\")\n",
    "print(f\"Total de duplicatas: {df.duplicated().sum()}\")\n",
    "\n",
    "# Informações detalhadas\n",
    "print(f\"\\n📋 INFORMAÇÕES DETALHADAS:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467146f1",
   "metadata": {},
   "source": [
    "## 2. Análise das Colunas Categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9976632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das colunas categóricas\n",
    "print(\"📊 ANÁLISE DAS COLUNAS CATEGÓRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificar colunas categóricas\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"Colunas categóricas encontradas: {list(categorical_cols)}\")\n",
    "\n",
    "# Análise de cada coluna categórica\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n🔍 {col.upper()}:\")\n",
    "    print(f\"  • Valores únicos: {df[col].nunique()}\")\n",
    "    print(f\"  • Valores nulos: {df[col].isnull().sum()}\")\n",
    "    print(f\"  • Top 5 valores:\")\n",
    "    print(df[col].value_counts().head())\n",
    "    \n",
    "    # Visualização\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df[col].value_counts().head(10).plot(kind='bar')\n",
    "    plt.title(f'Distribuição de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e584e6",
   "metadata": {},
   "source": [
    "## 3. Análise das Colunas Numéricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e754541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das colunas numéricas\n",
    "print(\"📊 ANÁLISE DAS COLUNAS NUMÉRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificar colunas numéricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f\"Colunas numéricas encontradas: {list(numeric_cols)}\")\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(f\"\\n📈 ESTATÍSTICAS DESCRITIVAS:\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Análise de cada coluna numérica\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n🔍 {col.upper()}:\")\n",
    "    print(f\"  • Média: {df[col].mean():.2f}\")\n",
    "    print(f\"  • Mediana: {df[col].median():.2f}\")\n",
    "    print(f\"  • Desvio padrão: {df[col].std():.2f}\")\n",
    "    print(f\"  • Mínimo: {df[col].min():.2f}\")\n",
    "    print(f\"  • Máximo: {df[col].max():.2f}\")\n",
    "    print(f\"  • Valores nulos: {df[col].isnull().sum()}\")\n",
    "    \n",
    "    # Visualização\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Histograma\n",
    "    df[col].hist(bins=30, ax=axes[0], edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title(f'Distribuição de {col}')\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel('Frequência')\n",
    "    \n",
    "    # Boxplot\n",
    "    df[col].plot(kind='box', ax=axes[1])\n",
    "    axes[1].set_title(f'Boxplot de {col}')\n",
    "    axes[1].set_ylabel(col)\n",
    "    \n",
    "    # Q-Q plot para verificar normalidade\n",
    "    from scipy import stats\n",
    "    stats.probplot(df[col].dropna(), dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title(f'Q-Q Plot de {col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d17530",
   "metadata": {},
   "source": [
    "## 4. Análise Temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise temporal dos dados\n",
    "print(\"📅 ANÁLISE TEMPORAL\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Extrair componentes temporais\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia'] = df['order_datetime'].dt.day\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['nome_dia_semana'] = df['order_datetime'].dt.day_name()\n",
    "\n",
    "print(f\"📊 Período dos dados: {df['order_datetime'].min()} até {df['order_datetime'].max()}\")\n",
    "print(f\"📊 Total de dias: {(df['order_datetime'].max() - df['order_datetime'].min()).days}\")\n",
    "\n",
    "# Análise por componentes temporais\n",
    "print(f\"\\n📊 PEDIDOS POR ANO:\")\n",
    "print(df['ano'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\n📊 PEDIDOS POR MÊS:\")\n",
    "print(df['mes'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\n📊 PEDIDOS POR DIA DA SEMANA:\")\n",
    "print(df['nome_dia_semana'].value_counts())\n",
    "\n",
    "print(f\"\\n📊 PEDIDOS POR HORA:\")\n",
    "print(df['hora'].value_counts().sort_index())\n",
    "\n",
    "# Visualizações temporais\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Pedidos por mês\n",
    "df['mes'].value_counts().sort_index().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Pedidos por Mês')\n",
    "axes[0,0].set_xlabel('Mês')\n",
    "axes[0,0].set_ylabel('Número de Pedidos')\n",
    "\n",
    "# Pedidos por dia da semana\n",
    "df['nome_dia_semana'].value_counts().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Pedidos por Dia da Semana')\n",
    "axes[0,1].set_xlabel('Dia da Semana')\n",
    "axes[0,1].set_ylabel('Número de Pedidos')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pedidos por hora\n",
    "df['hora'].value_counts().sort_index().plot(kind='line', ax=axes[1,0])\n",
    "axes[1,0].set_title('Pedidos por Hora do Dia')\n",
    "axes[1,0].set_xlabel('Hora')\n",
    "axes[1,0].set_ylabel('Número de Pedidos')\n",
    "\n",
    "# Distribuição temporal\n",
    "df['order_datetime'].dt.date.value_counts().sort_index().plot(kind='line', ax=axes[1,1])\n",
    "axes[1,1].set_title('Pedidos ao Longo do Tempo')\n",
    "axes[1,1].set_xlabel('Data')\n",
    "axes[1,1].set_ylabel('Número de Pedidos')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870b184",
   "metadata": {},
   "source": [
    "## 5. Análise de Correlações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de correlações entre variáveis numéricas\n",
    "print(\"🔗 ANÁLISE DE CORRELAÇÕES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Selecionar apenas variáveis numéricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "print(\"Matriz de correlação entre variáveis numéricas:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Heatmap de correlações\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlação entre Variáveis Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise das correlações mais importantes\n",
    "print(f\"\\n📊 CORRELAÇÕES MAIS IMPORTANTES:\")\n",
    "correlations = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "correlations = correlations[correlations < 1.0]  # Remover autocorrelações\n",
    "print(correlations.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae15b81",
   "metadata": {},
   "source": [
    "## 6. Resumo da Análise Exploratória\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo da Análise Exploratória\n",
    "print(\"📋 RESUMO DA ANÁLISE EXPLORATÓRIA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📊 DADOS GERAIS:\")\n",
    "print(f\"  • Total de registros: {len(df):,}\")\n",
    "print(f\"  • Total de colunas: {len(df.columns)}\")\n",
    "print(f\"  • Período dos dados: {df['order_datetime'].min().strftime('%d/%m/%Y')} a {df['order_datetime'].max().strftime('%d/%m/%Y')}\")\n",
    "\n",
    "print(f\"\\n👥 CLIENTES:\")\n",
    "print(f\"  • Clientes únicos: {df['nome_cliente'].nunique():,}\")\n",
    "print(f\"  • Pedidos por cliente (média): {len(df) / df['nome_cliente'].nunique():.1f}\")\n",
    "\n",
    "print(f\"\\n🏘️ LOCALIZAÇÃO:\")\n",
    "print(f\"  • Macro bairros únicos: {df['macro_bairro'].nunique()}\")\n",
    "print(f\"  • Bairros únicos: {df['bairro_destino'].nunique()}\")\n",
    "print(f\"  • Macro bairro mais frequente: {df['macro_bairro'].mode()[0]}\")\n",
    "\n",
    "print(f\"\\n💰 FINANCEIRO:\")\n",
    "print(f\"  • Ticket médio: R$ {df['total_brl'].mean():.2f}\")\n",
    "print(f\"  • Ticket mediano: R$ {df['total_brl'].median():.2f}\")\n",
    "print(f\"  • Comissão média: {df['platform_commission_pct'].mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n⏱️ TEMPO:\")\n",
    "print(f\"  • Tempo médio de preparo: {df['tempo_preparo_minutos'].mean():.1f} min\")\n",
    "print(f\"  • ETA médio: {df['eta_minutes_quote'].mean():.1f} min\")\n",
    "print(f\"  • Tempo real médio: {df['actual_delivery_minutes'].mean():.1f} min\")\n",
    "\n",
    "print(f\"\\n📦 PEDIDOS:\")\n",
    "print(f\"  • Itens médios por pedido: {df['num_itens'].mean():.1f}\")\n",
    "print(f\"  • Distância média: {df['distance_km'].mean():.1f} km\")\n",
    "\n",
    "print(f\"\\n😊 SATISFAÇÃO:\")\n",
    "print(f\"  • Satisfação média: {df['satisfacao_nivel'].mean():.2f}/5\")\n",
    "print(f\"  • % de satisfação alta (4-5): {(df['satisfacao_nivel'] >= 4).mean()*100:.1f}%\")\n",
    "print(f\"  • % de satisfação baixa (1-2): {(df['satisfacao_nivel'] <= 2).mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n🔍 QUALIDADE DOS DADOS:\")\n",
    "print(f\"  • Valores nulos: {df.isnull().sum().sum()}\")\n",
    "print(f\"  • Colunas com valores nulos: {(df.isnull().sum() > 0).sum()}\")\n",
    "\n",
    "print(f\"\\n✅ ANÁLISE EXPLORATÓRIA CONCLUÍDA!\")\n",
    "print(f\"   Todas as {len(df.columns)} colunas foram analisadas com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9a87c",
   "metadata": {},
   "source": [
    "# 🤖 MODELAGEM E PREDIÇÃO\n",
    "\n",
    "## 1. Preparação dos Dados para Modelagem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas de modelagem\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                            mean_absolute_error, mean_squared_error, r2_score, f1_score)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Bibliotecas de modelagem importadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799adc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para modelagem\n",
    "print(\"🔧 PREPARAÇÃO DOS DADOS PARA MODELAGEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Criar features derivadas necessárias\n",
    "print(\"📊 Criando features derivadas...\")\n",
    "\n",
    "# Features temporais\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['fim_semana'] = (df['dia_semana'] >= 5).astype(int)\n",
    "\n",
    "# Features de eficiência\n",
    "df['atraso_minutos'] = df['actual_delivery_minutes'] - df['eta_minutes_quote']\n",
    "df['velocidade_media'] = np.where(\n",
    "    df['actual_delivery_minutes'] > 0,\n",
    "    df['distance_km'] / df['actual_delivery_minutes'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Features financeiras\n",
    "df['margem_brl'] = df['total_brl'] * (1 - df['platform_commission_pct'])\n",
    "df['ticket_medio_item'] = np.where(\n",
    "    df['num_itens'] > 0,\n",
    "    df['total_brl'] / df['num_itens'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Features de complexidade\n",
    "df['indice_complexidade'] = df['tempo_preparo_minutos'] * df['num_itens']\n",
    "\n",
    "# Features de distância\n",
    "df['zona_distancia'] = pd.cut(\n",
    "    df['distance_km'], \n",
    "    bins=[0, 3, 7, 10, float('inf')], \n",
    "    labels=['curta', 'media', 'longa', 'muito_longa'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Features de satisfação\n",
    "df['satisfacao_categoria'] = pd.cut(\n",
    "    df['satisfacao_nivel'], \n",
    "    bins=[0, 2, 3, 4, 5], \n",
    "    labels=['Baixa', 'Média', 'Alta', 'Excelente']\n",
    ")\n",
    "df['satisfacao_alta'] = (df['satisfacao_nivel'] >= 4).astype(int)\n",
    "\n",
    "print(f\"✅ Features criadas! Shape final: {df.shape}\")\n",
    "\n",
    "# 2. Tratamento de valores nulos e infinitos\n",
    "print(\"\\n🧹 Tratando valores nulos e infinitos...\")\n",
    "\n",
    "# Substituir infinitos por NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Preencher valores nulos\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown')\n",
    "\n",
    "print(f\"✅ Dados limpos! Valores nulos: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# 3. Definir variáveis alvo e features\n",
    "print(\"\\n🎯 Definindo variáveis alvo e features...\")\n",
    "\n",
    "# Variáveis alvo\n",
    "targets = {\n",
    "    'satisfacao_nivel': df['satisfacao_nivel'],\n",
    "    'atraso_minutos': df['atraso_minutos'],\n",
    "    'margem_brl': df['margem_brl']\n",
    "}\n",
    "\n",
    "# Features numéricas\n",
    "features_numericas = [\n",
    "    'tempo_preparo_minutos', 'distance_km', 'eta_minutes_quote',\n",
    "    'actual_delivery_minutes', 'total_brl', 'platform_commission_pct', \n",
    "    'num_itens', 'hora', 'dia_semana', 'atraso_minutos', 'velocidade_media',\n",
    "    'margem_brl', 'ticket_medio_item', 'indice_complexidade', 'fim_semana'\n",
    "]\n",
    "\n",
    "# Features categóricas\n",
    "features_categoricas = [\n",
    "    'macro_bairro', 'platform', 'order_mode', 'status', 'classe_pedido',\n",
    "    'zona_distancia', 'satisfacao_categoria'\n",
    "]\n",
    "\n",
    "# Features binárias\n",
    "features_binarias = ['satisfacao_alta']\n",
    "\n",
    "print(f\"✅ Features definidas:\")\n",
    "print(f\"  • Numéricas: {len(features_numericas)}\")\n",
    "print(f\"  • Categóricas: {len(features_categoricas)}\")\n",
    "print(f\"  • Binárias: {len(features_binarias)}\")\n",
    "print(f\"  • Total: {len(features_numericas) + len(features_categoricas) + len(features_binarias)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdf231",
   "metadata": {},
   "source": [
    "## 2. Modelo 1: Previsão de Satisfação (Classificação)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ea304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Previsão de Satisfação\n",
    "print(\"🤖 MODELO 1: PREVISÃO DE SATISFAÇÃO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para satisfação\n",
    "features_satisfacao = features_numericas + features_categoricas\n",
    "X_sat = df[features_satisfacao].copy()\n",
    "y_sat = df['satisfacao_nivel'].copy()\n",
    "\n",
    "# Tratamento de dados categóricos\n",
    "le = LabelEncoder()\n",
    "for col in features_categoricas:\n",
    "    if col in X_sat.columns:\n",
    "        X_sat[col] = X_sat[col].astype(str)\n",
    "        X_sat[col] = le.fit_transform(X_sat[col])\n",
    "\n",
    "# Verificar se há valores nulos\n",
    "print(f\"Valores nulos em X_sat: {X_sat.isnull().sum().sum()}\")\n",
    "if X_sat.isnull().sum().sum() > 0:\n",
    "    X_sat = X_sat.fillna(X_sat.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "print(f\"📊 Dados de treino: {X_train_sat.shape[0]} amostras\")\n",
    "print(f\"📊 Dados de teste: {X_test_sat.shape[0]} amostras\")\n",
    "print(f\"📊 Features: {X_train_sat.shape[1]}\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\n🌲 Treinando Random Forest...\")\n",
    "modelo_satisfacao = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Avaliar modelo\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "f1 = f1_score(y_test_sat, y_pred_sat, average='weighted')\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS DO MODELO DE SATISFAÇÃO:\")\n",
    "print(f\"  • Acurácia: {accuracy:.4f}\")\n",
    "print(f\"  • F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Validação cruzada\n",
    "print(\"\\n🔄 Validação Cruzada (5 folds):\")\n",
    "cv_scores = cross_val_score(modelo_satisfacao, X_train_sat, y_train_sat, cv=5, scoring='accuracy')\n",
    "print(f\"  • Acurácia média: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Importância das features\n",
    "print(\"\\n📈 TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_sat.columns,\n",
    "    'importance': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\n📋 RELATÓRIO DE CLASSIFICAÇÃO:\")\n",
    "print(classification_report(y_test_sat, y_pred_sat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbc8dc",
   "metadata": {},
   "source": [
    "## 3. Modelo 2: Previsão de Atraso (Regressão)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Previsão de Atraso\n",
    "print(\"🤖 MODELO 2: PREVISÃO DE ATRASO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para atraso\n",
    "features_atraso = features_numericas + features_categoricas\n",
    "X_atraso = df[features_atraso].copy()\n",
    "y_atraso = df['atraso_minutos'].copy()\n",
    "\n",
    "# Tratamento de dados categóricos\n",
    "for col in features_categoricas:\n",
    "    if col in X_atraso.columns:\n",
    "        X_atraso[col] = X_atraso[col].astype(str)\n",
    "        X_atraso[col] = le.fit_transform(X_atraso[col])\n",
    "\n",
    "# Verificar se há valores nulos\n",
    "print(f\"Valores nulos em X_atraso: {X_atraso.isnull().sum().sum()}\")\n",
    "if X_atraso.isnull().sum().sum() > 0:\n",
    "    X_atraso = X_atraso.fillna(X_atraso.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_atraso, X_test_atraso, y_train_atraso, y_test_atraso = train_test_split(\n",
    "    X_atraso, y_atraso, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"📊 Dados de treino: {X_train_atraso.shape[0]} amostras\")\n",
    "print(f\"📊 Dados de teste: {X_test_atraso.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\n🌲 Treinando Random Forest para atraso...\")\n",
    "modelo_atraso_rf = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_atraso_rf.fit(X_train_atraso, y_train_atraso)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_atraso_rf = modelo_atraso_rf.predict(X_test_atraso)\n",
    "\n",
    "# Avaliar modelo\n",
    "mae_rf = mean_absolute_error(y_test_atraso, y_pred_atraso_rf)\n",
    "mse_rf = mean_squared_error(y_test_atraso, y_pred_atraso_rf)\n",
    "r2_rf = r2_score(y_test_atraso, y_pred_atraso_rf)\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS DO MODELO DE ATRASO (Random Forest):\")\n",
    "print(f\"  • MAE: {mae_rf:.2f} minutos\")\n",
    "print(f\"  • MSE: {mse_rf:.2f}\")\n",
    "print(f\"  • R²: {r2_rf:.4f}\")\n",
    "\n",
    "# Validação cruzada\n",
    "print(\"\\n🔄 Validação Cruzada (5 folds):\")\n",
    "cv_scores_rf = cross_val_score(modelo_atraso_rf, X_train_atraso, y_train_atraso, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"  • MAE médio: {-cv_scores_rf.mean():.2f} (+/- {cv_scores_rf.std() * 2:.2f})\")\n",
    "\n",
    "# Importância das features\n",
    "print(\"\\n📈 TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance_atraso = pd.DataFrame({\n",
    "    'feature': X_atraso.columns,\n",
    "    'importance': modelo_atraso_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_atraso.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e463cd9",
   "metadata": {},
   "source": [
    "## 4. Modelo 3: Previsão de Margem (Regressão)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: Previsão de Margem\n",
    "print(\"🤖 MODELO 3: PREVISÃO DE MARGEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para margem\n",
    "features_margem = features_numericas + features_categoricas\n",
    "X_margem = df[features_margem].copy()\n",
    "y_margem = df['margem_brl'].copy()\n",
    "\n",
    "# Tratamento de dados categóricos\n",
    "for col in features_categoricas:\n",
    "    if col in X_margem.columns:\n",
    "        X_margem[col] = X_margem[col].astype(str)\n",
    "        X_margem[col] = le.fit_transform(X_margem[col])\n",
    "\n",
    "# Verificar se há valores nulos\n",
    "print(f\"Valores nulos em X_margem: {X_margem.isnull().sum().sum()}\")\n",
    "if X_margem.isnull().sum().sum() > 0:\n",
    "    X_margem = X_margem.fillna(X_margem.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_margem, X_test_margem, y_train_margem, y_test_margem = train_test_split(\n",
    "    X_margem, y_margem, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"📊 Dados de treino: {X_train_margem.shape[0]} amostras\")\n",
    "print(f\"📊 Dados de teste: {X_test_margem.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\n🌲 Treinando Random Forest para margem...\")\n",
    "modelo_margem_rf = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_margem_rf.fit(X_train_margem, y_train_margem)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_margem_rf = modelo_margem_rf.predict(X_test_margem)\n",
    "\n",
    "# Avaliar modelo\n",
    "mae_margem = mean_absolute_error(y_test_margem, y_pred_margem_rf)\n",
    "mse_margem = mean_squared_error(y_test_margem, y_pred_margem_rf)\n",
    "r2_margem = r2_score(y_test_margem, y_pred_margem_rf)\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS DO MODELO DE MARGEM (Random Forest):\")\n",
    "print(f\"  • MAE: R$ {mae_margem:.2f}\")\n",
    "print(f\"  • MSE: R$ {mse_margem:.2f}\")\n",
    "print(f\"  • R²: {r2_margem:.4f}\")\n",
    "\n",
    "# Validação cruzada\n",
    "print(\"\\n🔄 Validação Cruzada (5 folds):\")\n",
    "cv_scores_margem = cross_val_score(modelo_margem_rf, X_train_margem, y_train_margem, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"  • MAE médio: R$ {-cv_scores_margem.mean():.2f} (+/- {cv_scores_margem.std() * 2:.2f})\")\n",
    "\n",
    "# Importância das features\n",
    "print(\"\\n📈 TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance_margem = pd.DataFrame({\n",
    "    'feature': X_margem.columns,\n",
    "    'importance': modelo_margem_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_margem.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea6ec8",
   "metadata": {},
   "source": [
    "## 5. Refatoração dos Queries - Análise Eficiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refatoração dos Queries - Análise Eficiente\n",
    "print(\"🔧 REFATORAÇÃO DOS QUERIES - ANÁLISE EFICIENTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Análise por Macro Bairro (substituindo queries repetitivos)\n",
    "print(\"📊 1. ANÁLISE POR MACRO BAIRRO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar análise consolidada por macro bairro\n",
    "analise_macro_bairro = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'distance_km': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten das colunas\n",
    "analise_macro_bairro.columns = ['_'.join(col).strip() for col in analise_macro_bairro.columns]\n",
    "analise_macro_bairro = analise_macro_bairro.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'distance_km_mean': 'Distancia_Media',\n",
    "    'tempo_preparo_minutos_mean': 'Tempo_Preparo_Medio'\n",
    "})\n",
    "\n",
    "print(\"📈 RESUMO POR MACRO BAIRRO:\")\n",
    "print(analise_macro_bairro.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 2. Análise por Platform (substituindo queries repetitivos)\n",
    "print(\"\\n📊 2. ANÁLISE POR PLATFORM\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "analise_platform = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'platform_commission_pct': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_platform.columns = ['_'.join(col).strip() for col in analise_platform.columns]\n",
    "analise_platform = analise_platform.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'platform_commission_pct_mean': 'Comissao_Media'\n",
    "})\n",
    "\n",
    "print(\"📈 RESUMO POR PLATFORM:\")\n",
    "print(analise_platform.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 3. Análise por Order Mode (substituindo queries repetitivos)\n",
    "print(\"\\n📊 3. ANÁLISE POR ORDER MODE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "analise_order_mode = df.groupby('order_mode').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'distance_km': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_order_mode.columns = ['_'.join(col).strip() for col in analise_order_mode.columns]\n",
    "analise_order_mode = analise_order_mode.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'distance_km_mean': 'Distancia_Media'\n",
    "})\n",
    "\n",
    "print(\"📈 RESUMO POR ORDER MODE:\")\n",
    "print(analise_order_mode.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 4. Análise Combinada (Platform + Macro Bairro)\n",
    "print(\"\\n📊 4. ANÁLISE COMBINADA (PLATFORM + MACRO BAIRRO)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "analise_combinada = df.groupby(['platform', 'macro_bairro']).agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_combinada.columns = ['_'.join(col).strip() for col in analise_combinada.columns]\n",
    "analise_combinada = analise_combinada.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"📈 TOP 10 COMBINAÇÕES (PLATFORM + MACRO BAIRRO):\")\n",
    "print(analise_combinada.sort_values('Receita_Total', ascending=False).head(10))\n",
    "\n",
    "# 5. Análise Temporal Eficiente\n",
    "print(\"\\n📊 5. ANÁLISE TEMPORAL EFICIENTE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Análise por hora do dia\n",
    "analise_hora = df.groupby('hora').agg({\n",
    "    'total_brl': ['count', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_hora.columns = ['_'.join(col).strip() for col in analise_hora.columns]\n",
    "analise_hora = analise_hora.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"📈 RESUMO POR HORA DO DIA:\")\n",
    "print(analise_hora.sort_values('Total_Pedidos', ascending=False).head(10))\n",
    "\n",
    "# Análise por dia da semana\n",
    "analise_dia_semana = df.groupby('nome_dia_semana').agg({\n",
    "    'total_brl': ['count', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_dia_semana.columns = ['_'.join(col).strip() for col in analise_dia_semana.columns]\n",
    "analise_dia_semana = analise_dia_semana.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"\\n📈 RESUMO POR DIA DA SEMANA:\")\n",
    "print(analise_dia_semana.sort_values('Total_Pedidos', ascending=False))\n",
    "\n",
    "print(\"\\n✅ REFATORAÇÃO CONCLUÍDA!\")\n",
    "print(\"   • Substituídos queries repetitivos por groupby eficiente\")\n",
    "print(\"   • Análises consolidadas em uma única operação\")\n",
    "print(\"   • Código mais limpo e performático\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ccb962",
   "metadata": {},
   "source": [
    "## 6. Visualizações dos Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações dos Modelos\n",
    "print(\"📊 VISUALIZAÇÕES DOS MODELOS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Matriz de Confusão - Modelo de Satisfação\n",
    "print(\"📊 1. MATRIZ DE CONFUSÃO - SATISFAÇÃO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Matriz de confusão\n",
    "plt.subplot(1, 3, 1)\n",
    "cm = confusion_matrix(y_test_sat, y_pred_sat)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=sorted(y_test_sat.unique()), \n",
    "            yticklabels=sorted(y_test_sat.unique()))\n",
    "plt.title('Matriz de Confusão - Satisfação')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "# Importância das features - Satisfação\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_sat = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features_sat)), top_features_sat['importance'])\n",
    "plt.yticks(range(len(top_features_sat)), top_features_sat['feature'])\n",
    "plt.title('Top 10 Features - Satisfação')\n",
    "plt.xlabel('Importância')\n",
    "\n",
    "# Distribuição das previsões vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_sat, y_pred_sat, alpha=0.6)\n",
    "plt.plot([y_test_sat.min(), y_test_sat.max()], [y_test_sat.min(), y_test_sat.max()], 'r--', lw=2)\n",
    "plt.xlabel('Satisfação Real')\n",
    "plt.ylabel('Satisfação Predita')\n",
    "plt.title('Previsões vs Real - Satisfação')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Análise de Resíduos - Modelo de Atraso\n",
    "print(\"\\n📊 2. ANÁLISE DE RESÍDUOS - ATRASO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Resíduos\n",
    "plt.subplot(1, 3, 1)\n",
    "residuos_atraso = y_test_atraso - y_pred_atraso_rf\n",
    "plt.scatter(y_pred_atraso_rf, residuos_atraso, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Preditos')\n",
    "plt.ylabel('Resíduos')\n",
    "plt.title('Resíduos vs Preditos - Atraso')\n",
    "\n",
    "# Importância das features - Atraso\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_atraso = feature_importance_atraso.head(10)\n",
    "plt.barh(range(len(top_features_atraso)), top_features_atraso['importance'])\n",
    "plt.yticks(range(len(top_features_atraso)), top_features_atraso['feature'])\n",
    "plt.title('Top 10 Features - Atraso')\n",
    "plt.xlabel('Importância')\n",
    "\n",
    "# Distribuição das previsões vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_atraso, y_pred_atraso_rf, alpha=0.6)\n",
    "plt.plot([y_test_atraso.min(), y_test_atraso.max()], [y_test_atraso.min(), y_test_atraso.max()], 'r--', lw=2)\n",
    "plt.xlabel('Atraso Real (min)')\n",
    "plt.ylabel('Atraso Predito (min)')\n",
    "plt.title('Previsões vs Real - Atraso')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Análise de Resíduos - Modelo de Margem\n",
    "print(\"\\n📊 3. ANÁLISE DE RESÍDUOS - MARGEM\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Resíduos\n",
    "plt.subplot(1, 3, 1)\n",
    "residuos_margem = y_test_margem - y_pred_margem_rf\n",
    "plt.scatter(y_pred_margem_rf, residuos_margem, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Preditos')\n",
    "plt.ylabel('Resíduos')\n",
    "plt.title('Resíduos vs Preditos - Margem')\n",
    "\n",
    "# Importância das features - Margem\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_margem = feature_importance_margem.head(10)\n",
    "plt.barh(range(len(top_features_margem)), top_features_margem['importance'])\n",
    "plt.yticks(range(len(top_features_margem)), top_features_margem['feature'])\n",
    "plt.title('Top 10 Features - Margem')\n",
    "plt.xlabel('Importância')\n",
    "\n",
    "# Distribuição das previsões vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_margem, y_pred_margem_rf, alpha=0.6)\n",
    "plt.plot([y_test_margem.min(), y_test_margem.max()], [y_test_margem.min(), y_test_margem.max()], 'r--', lw=2)\n",
    "plt.xlabel('Margem Real (R$)')\n",
    "plt.ylabel('Margem Predita (R$)')\n",
    "plt.title('Previsões vs Real - Margem')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Comparação de Performance dos Modelos\n",
    "print(\"\\n📊 4. COMPARAÇÃO DE PERFORMANCE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar DataFrame com métricas\n",
    "metricas = pd.DataFrame({\n",
    "    'Modelo': ['Satisfação (RF)', 'Atraso (RF)', 'Margem (RF)'],\n",
    "    'Métrica': ['Acurácia', 'MAE (min)', 'MAE (R$)'],\n",
    "    'Valor': [accuracy, mae_rf, mae_margem],\n",
    "    'R²': [f1, r2_rf, r2_margem]\n",
    "})\n",
    "\n",
    "print(\"📈 RESUMO DAS MÉTRICAS:\")\n",
    "print(metricas)\n",
    "\n",
    "# Gráfico de comparação\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(metricas['Modelo'], metricas['Valor'])\n",
    "plt.title('Métricas Principais por Modelo')\n",
    "plt.ylabel('Valor da Métrica')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(metricas['Modelo'], metricas['R²'])\n",
    "plt.title('R² / F1-Score por Modelo')\n",
    "plt.ylabel('R² / F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ VISUALIZAÇÕES CONCLUÍDAS!\")\n",
    "print(\"   • Matriz de confusão para classificação\")\n",
    "print(\"   • Análise de resíduos para regressão\")\n",
    "print(\"   • Importância das features\")\n",
    "print(\"   • Comparação de performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3a753",
   "metadata": {},
   "source": [
    "## 7. Resumo e Salvamento dos Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1de559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo e Salvamento dos Modelos\n",
    "print(\"💾 RESUMO E SALVAMENTO DOS MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Resumo dos Modelos Treinados\n",
    "print(\"📊 RESUMO DOS MODELOS TREINADOS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "modelos_info = {\n",
    "    'Modelo': ['Satisfação (Classificação)', 'Atraso (Regressão)', 'Margem (Regressão)'],\n",
    "    'Algoritmo': ['Random Forest Classifier', 'Random Forest Regressor', 'Random Forest Regressor'],\n",
    "    'Variável Alvo': ['satisfacao_nivel', 'atraso_minutos', 'margem_brl'],\n",
    "    'Acurácia/R²': [f\"{accuracy:.4f}\", f\"{r2_rf:.4f}\", f\"{r2_margem:.4f}\"],\n",
    "    'MAE': [f\"{f1:.4f}\", f\"{mae_rf:.2f} min\", f\"R$ {mae_margem:.2f}\"],\n",
    "    'Features': [len(features_satisfacao), len(features_atraso), len(features_margem)]\n",
    "}\n",
    "\n",
    "resumo_modelos = pd.DataFrame(modelos_info)\n",
    "print(resumo_modelos)\n",
    "\n",
    "# 2. Salvar modelos treinados\n",
    "print(\"\\n💾 SALVANDO MODELOS...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Criar diretório para modelos se não existir\n",
    "if not os.path.exists('modelos'):\n",
    "    os.makedirs('modelos')\n",
    "\n",
    "# Salvar modelos\n",
    "joblib.dump(modelo_satisfacao, 'modelos/modelo_satisfacao.pkl')\n",
    "joblib.dump(modelo_atraso_rf, 'modelos/modelo_atraso.pkl')\n",
    "joblib.dump(modelo_margem_rf, 'modelos/modelo_margem.pkl')\n",
    "\n",
    "print(\"✅ Modelos salvos em:\")\n",
    "print(\"   • modelos/modelo_satisfacao.pkl\")\n",
    "print(\"   • modelos/modelo_atraso.pkl\")\n",
    "print(\"   • modelos/modelo_margem.pkl\")\n",
    "\n",
    "# 3. Salvar informações dos modelos\n",
    "print(\"\\n📋 SALVANDO INFORMAÇÕES DOS MODELOS...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Salvar features utilizadas\n",
    "features_info = {\n",
    "    'satisfacao': features_satisfacao,\n",
    "    'atraso': features_atraso,\n",
    "    'margem': features_margem\n",
    "}\n",
    "\n",
    "joblib.dump(features_info, 'modelos/features_info.pkl')\n",
    "\n",
    "# Salvar métricas\n",
    "metricas_info = {\n",
    "    'satisfacao': {'accuracy': accuracy, 'f1_score': f1},\n",
    "    'atraso': {'mae': mae_rf, 'mse': mse_rf, 'r2': r2_rf},\n",
    "    'margem': {'mae': mae_margem, 'mse': mse_margem, 'r2': r2_margem}\n",
    "}\n",
    "\n",
    "joblib.dump(metricas_info, 'modelos/metricas_info.pkl')\n",
    "\n",
    "print(\"✅ Informações salvas em:\")\n",
    "print(\"   • modelos/features_info.pkl\")\n",
    "print(\"   • modelos/metricas_info.pkl\")\n",
    "\n",
    "# 4. Função para fazer previsões\n",
    "print(\"\\n🔮 FUNÇÃO DE PREVISÃO:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def fazer_previsoes(dados_novos):\n",
    "    \"\"\"\n",
    "    Função para fazer previsões com os modelos treinados\n",
    "    \n",
    "    Args:\n",
    "        dados_novos: DataFrame com as features necessárias\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário com as previsões\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carregar modelos\n",
    "        modelo_sat = joblib.load('modelos/modelo_satisfacao.pkl')\n",
    "        modelo_atraso = joblib.load('modelos/modelo_atraso.pkl')\n",
    "        modelo_margem = joblib.load('modelos/modelo_margem.pkl')\n",
    "        \n",
    "        # Carregar features\n",
    "        features_info = joblib.load('modelos/features_info.pkl')\n",
    "        \n",
    "        # Preparar dados\n",
    "        X_sat = dados_novos[features_info['satisfacao']].copy()\n",
    "        X_atraso = dados_novos[features_info['atraso']].copy()\n",
    "        X_margem = dados_novos[features_info['margem']].copy()\n",
    "        \n",
    "        # Tratamento de dados categóricos\n",
    "        le = LabelEncoder()\n",
    "        for col in features_categoricas:\n",
    "            if col in X_sat.columns:\n",
    "                X_sat[col] = X_sat[col].astype(str)\n",
    "                X_sat[col] = le.fit_transform(X_sat[col])\n",
    "            if col in X_atraso.columns:\n",
    "                X_atraso[col] = X_atraso[col].astype(str)\n",
    "                X_atraso[col] = le.fit_transform(X_atraso[col])\n",
    "            if col in X_margem.columns:\n",
    "                X_margem[col] = X_margem[col].astype(str)\n",
    "                X_margem[col] = le.fit_transform(X_margem[col])\n",
    "        \n",
    "        # Preencher valores nulos\n",
    "        X_sat = X_sat.fillna(X_sat.median())\n",
    "        X_atraso = X_atraso.fillna(X_atraso.median())\n",
    "        X_margem = X_margem.fillna(X_margem.median())\n",
    "        \n",
    "        # Fazer previsões\n",
    "        previsoes = {\n",
    "            'satisfacao_predita': modelo_sat.predict(X_sat),\n",
    "            'atraso_predito': modelo_atraso.predict(X_atraso),\n",
    "            'margem_predita': modelo_margem.predict(X_margem)\n",
    "        }\n",
    "        \n",
    "        return previsoes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao fazer previsões: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Função de previsão criada!\")\n",
    "print(\"   Use: fazer_previsoes(seu_dataframe)\")\n",
    "\n",
    "# 5. Resumo final\n",
    "print(\"\\n🎯 RESUMO FINAL:\")\n",
    "print(\"=\" * 30)\n",
    "print(\"✅ MODELAGEM CONCLUÍDA COM SUCESSO!\")\n",
    "print(f\"   • 3 modelos treinados e validados\")\n",
    "print(f\"   • Validação cruzada implementada\")\n",
    "print(f\"   • Análise de importância das features\")\n",
    "print(f\"   • Visualizações completas\")\n",
    "print(f\"   • Modelos salvos para uso futuro\")\n",
    "print(f\"   • Queries refatorados para maior eficiência\")\n",
    "print(f\"   • Código organizado e limpo\")\n",
    "\n",
    "print(\"\\n📊 PRÓXIMOS PASSOS RECOMENDADOS:\")\n",
    "print(\"   • Testar modelos com dados novos\")\n",
    "print(\"   • Implementar monitoramento de performance\")\n",
    "print(\"   • Considerar ensemble de modelos\")\n",
    "print(\"   • Otimizar hiperparâmetros com GridSearch\")\n",
    "print(\"   • Implementar pipeline de produção\")\n",
    "\n",
    "print(\"\\n🚀 PROJETO PRONTO PARA APRESENTAÇÃO!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47874ed",
   "metadata": {},
   "source": [
    "# Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc649141",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a3f93",
   "metadata": {},
   "source": [
    "# Coleta e exploração dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb7951",
   "metadata": {},
   "source": [
    "Análise básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48b9ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "delivered     4802\n",
       "canceled       180\n",
       "chargeback      18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a86ee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='status'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=df['status'].value_counts().index, y=df['status'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e29a3183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_mode\n",
       "delivery    4024\n",
       "retirada     976\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['order_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8935115",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['order_mode'].value_counts().index, y=df['order_mode'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ac6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['platform'].value_counts().index, y=df['platform'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classe_pedido'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['classe_pedido'].value_counts().index, y=df['classe_pedido'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['macro_bairro'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=df['macro_bairro'].value_counts().index, y=df['macro_bairro'].value_counts().values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6149c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('macro_bairro')['bairro_destino'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689878b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brooklin = df.query('macro_bairro == \"Brooklin\"')\n",
    "df_itaim = df.query('macro_bairro == \"Itaim\"')\n",
    "df_jardins = df.query('macro_bairro == \"Jardins\"')\n",
    "df_moema = df.query('macro_bairro == \"Moema\"')\n",
    "df_morumbi = df.query('macro_bairro == \"Morumbi\"')\n",
    "df_outros = df.query('macro_bairro == \"Outros\"')\n",
    "df_pinheiros = df.query('macro_bairro == \"Pinheiros\"')\n",
    "df_santo_amaro = df.query('macro_bairro == \"Santo Amaro\"')\n",
    "df_vila_mariana = df.query('macro_bairro == \"Vila Mariana\"')\n",
    "df_vila_olimpia = df.query('macro_bairro == \"Vila Olímpia\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1aa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brooklin_tamanho = df_brooklin.count().unique()\n",
    "df_delivery_brooklin = df_brooklin.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_brooklin = df_brooklin.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_brooklin = (df_delivery_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_retirada_brooklin = (df_retirada_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_itaim_tamanho = df_itaim.count().unique()\n",
    "df_delivery_itaim = df_itaim.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_itaim = df_itaim.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_itaim = (df_delivery_itaim / df_itaim_tamanho)\n",
    "porcentagem_retirada_itaim = (df_retirada_itaim / df_itaim_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_jardins_tamanho = df_jardins.count().unique()\n",
    "df_delivery_jardins = df_jardins.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_jardins = df_jardins.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_jardins = (df_delivery_jardins / df_jardins_tamanho)\n",
    "porcentagem_retirada_jardins = (df_retirada_jardins / df_jardins_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_moema_tamanho = df_moema.count().unique()\n",
    "df_delivery_moema = df_moema.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_moema = df_moema.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_moema = (df_delivery_moema / df_moema_tamanho)\n",
    "porcentagem_retirada_moema = (df_retirada_moema / df_moema_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_morumbi_tamanho = df_morumbi.count().unique()\n",
    "df_delivery_morumbi = df_morumbi.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_morumbi = df_morumbi.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_morumbi = (df_delivery_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_retirada_morumbi = (df_retirada_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_outros_tamanho = df_outros.count().unique()\n",
    "df_delivery_outros = df_outros.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_outros = df_outros.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_outros = (df_delivery_outros / df_outros_tamanho)\n",
    "porcentagem_retirada_outros = (df_retirada_outros / df_outros_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_pinheiros_tamanho = df_pinheiros.count().unique()\n",
    "df_delivery_pinheiros = df_pinheiros.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_pinheiros = df_pinheiros.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_pinheiros = (df_delivery_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_retirada_pinheiros = (df_retirada_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_santo_amaro_tamanho = df_santo_amaro.count().unique()\n",
    "df_delivery_santo_amaro = df_santo_amaro.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_santo_amaro = df_santo_amaro.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_santo_amaro = (df_delivery_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_retirada_santo_amaro = (df_retirada_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_vila_mariana_tamanho = df_vila_mariana.count().unique()\n",
    "df_delivery_vila_mariana = df_vila_mariana.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_vila_mariana = df_vila_mariana.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_vila_mariana = (df_delivery_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_retirada_vila_mariana = (df_retirada_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_vila_olimpia_tamanho = df_vila_olimpia.count().unique()\n",
    "df_delivery_vila_olimpia = df_vila_olimpia.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_vila_olimpia = df_vila_olimpia.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_vila_olimpia = (df_delivery_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_retirada_vila_olimpia = (df_retirada_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_brooklin[0], porcentagem_retirada_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_itaim[0], porcentagem_retirada_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_jardins[0], porcentagem_retirada_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_moema[0], porcentagem_retirada_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_morumbi[0], porcentagem_retirada_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_outros[0], porcentagem_retirada_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_pinheiros[0], porcentagem_retirada_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_santo_amaro[0], porcentagem_retirada_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_vila_mariana[0], porcentagem_retirada_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_vila_olimpia[0], porcentagem_retirada_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Olímpia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d99e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifood_brooklin = df_brooklin.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_brooklin = df_brooklin.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_brooklin = df_brooklin.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_brooklin = df_brooklin.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_brooklin = (df_ifood_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_rappi_brooklin = (df_rappi_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_whatsapp_brooklin = (df_whatsapp_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_site_proprio_brooklin = (df_site_proprio_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "df_ifood_itaim = df_itaim.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_itaim = df_itaim.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_itaim = df_itaim.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_itaim = df_itaim.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_itaim = (df_ifood_itaim / df_itaim_tamanho)\n",
    "porcentagem_rappi_itaim = (df_rappi_itaim / df_itaim_tamanho)\n",
    "porcentagem_whatsapp_itaim = (df_whatsapp_itaim / df_itaim_tamanho)\n",
    "porcentagem_site_proprio_itaim = (df_site_proprio_itaim / df_itaim_tamanho)\n",
    "\n",
    "df_ifood_jardins = df_jardins.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_jardins = df_jardins.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_jardins = df_jardins.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_jardins = df_jardins.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_jardins = (df_ifood_jardins / df_jardins_tamanho)\n",
    "porcentagem_rappi_jardins = (df_rappi_jardins / df_jardins_tamanho)\n",
    "porcentagem_whatsapp_jardins = (df_whatsapp_jardins / df_jardins_tamanho)\n",
    "porcentagem_site_proprio_jardins = (df_site_proprio_jardins / df_jardins_tamanho)\n",
    "\n",
    "df_ifood_moema = df_moema.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_moema = df_moema.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_moema = df_moema.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_moema = df_moema.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_moema = (df_ifood_moema / df_moema_tamanho)\n",
    "porcentagem_rappi_moema = (df_rappi_moema / df_moema_tamanho)\n",
    "porcentagem_whatsapp_moema = (df_whatsapp_moema / df_moema_tamanho)\n",
    "porcentagem_site_proprio_moema = (df_site_proprio_moema / df_moema_tamanho)\n",
    "\n",
    "df_morumbi_tamanho = df_morumbi.count().unique()\n",
    "df_ifood_morumbi = df_morumbi.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_morumbi = df_morumbi.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_morumbi = df_morumbi.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_morumbi = df_morumbi.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_morumbi = (df_ifood_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_rappi_morumbi = (df_rappi_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_whatsapp_morumbi = (df_whatsapp_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_site_proprio_morumbi = (df_site_proprio_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "df_ifood_outros = df_outros.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_outros = df_outros.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_outros = df_outros.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_outros = df_outros.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_outros = (df_ifood_outros / df_outros_tamanho)\n",
    "porcentagem_rappi_outros = (df_rappi_outros / df_outros_tamanho)\n",
    "porcentagem_whatsapp_outros = (df_whatsapp_outros / df_outros_tamanho)\n",
    "porcentagem_site_proprio_outros = (df_site_proprio_outros / df_outros_tamanho)\n",
    "\n",
    "df_ifood_pinheiros = df_pinheiros.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_pinheiros = df_pinheiros.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_pinheiros = df_pinheiros.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_pinheiros = df_pinheiros.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_pinheiros = (df_ifood_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_rappi_pinheiros = (df_rappi_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_whatsapp_pinheiros = (df_whatsapp_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_site_proprio_pinheiros = (df_site_proprio_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "df_ifood_santo_amaro = df_santo_amaro.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_santo_amaro = df_santo_amaro.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_santo_amaro = df_santo_amaro.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_santo_amaro = df_santo_amaro.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_santo_amaro = (df_ifood_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_rappi_santo_amaro = (df_rappi_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_whatsapp_santo_amaro = (df_whatsapp_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_site_proprio_santo_amaro = (df_site_proprio_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "df_ifood_vila_mariana = df_vila_mariana.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_vila_mariana = df_vila_mariana.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_vila_mariana = df_vila_mariana.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_vila_mariana = df_vila_mariana.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_vila_mariana = (df_ifood_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_rappi_vila_mariana = (df_rappi_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_whatsapp_vila_mariana = (df_whatsapp_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_site_proprio_vila_mariana = (df_site_proprio_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "df_ifood_vila_olimpia = df_vila_olimpia.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_vila_olimpia = df_vila_olimpia.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_vila_olimpia = df_vila_olimpia.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_vila_olimpia = df_vila_olimpia.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_vila_olimpia = (df_ifood_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_rappi_vila_olimpia = (df_rappi_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_whatsapp_vila_olimpia = (df_whatsapp_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_site_proprio_vila_olimpia = (df_site_proprio_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_brooklin[0], porcentagem_rappi_brooklin[0], porcentagem_whatsapp_brooklin[0], porcentagem_site_proprio_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_itaim[0], porcentagem_rappi_itaim[0], porcentagem_whatsapp_itaim[0], porcentagem_site_proprio_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_jardins[0], porcentagem_rappi_jardins[0], porcentagem_whatsapp_jardins[0], porcentagem_site_proprio_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_moema[0], porcentagem_rappi_moema[0], porcentagem_whatsapp_moema[0], porcentagem_site_proprio_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_morumbi[0], porcentagem_rappi_morumbi[0], porcentagem_whatsapp_morumbi[0], porcentagem_site_proprio_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_outros[0], porcentagem_rappi_outros[0], porcentagem_whatsapp_outros[0], porcentagem_site_proprio_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_pinheiros[0], porcentagem_rappi_pinheiros[0], porcentagem_whatsapp_pinheiros[0], porcentagem_site_proprio_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_santo_amaro[0], porcentagem_rappi_santo_amaro[0], porcentagem_whatsapp_santo_amaro[0], porcentagem_site_proprio_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_vila_mariana[0], porcentagem_rappi_vila_mariana[0], porcentagem_whatsapp_vila_mariana[0], porcentagem_site_proprio_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Próprio'], y=[porcentagem_ifood_vila_olimpia[0], porcentagem_rappi_vila_olimpia[0], porcentagem_whatsapp_vila_olimpia[0], porcentagem_site_proprio_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Olímpia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_brooklin = df_brooklin.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_brooklin = df_brooklin.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_brooklin = df_brooklin.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_brooklin = (df_combo_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_prato_unico_brooklin = (df_prato_unico_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_familia_brooklin = (df_familia_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "df_combo_itaim = df_itaim.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_itaim = df_itaim.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_itaim = df_itaim.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_itaim = (df_combo_itaim / df_itaim_tamanho)\n",
    "porcentagem_prato_unico_itaim = (df_prato_unico_itaim / df_itaim_tamanho)\n",
    "porcentagem_familia_itaim = (df_familia_itaim / df_itaim_tamanho)\n",
    "\n",
    "df_combo_jardins = df_jardins.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_jardins = df_jardins.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_jardins = df_jardins.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_jardins = (df_combo_jardins / df_jardins_tamanho)\n",
    "porcentagem_prato_unico_jardins = (df_prato_unico_jardins / df_jardins_tamanho)\n",
    "porcentagem_familia_jardins = (df_familia_jardins / df_jardins_tamanho)\n",
    "\n",
    "df_combo_moema = df_moema.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_moema = df_moema.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_moema = df_moema.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_moema = (df_combo_moema / df_moema_tamanho)\n",
    "porcentagem_prato_unico_moema = (df_prato_unico_moema / df_moema_tamanho)\n",
    "porcentagem_familia_moema = (df_familia_moema / df_moema_tamanho)\n",
    "\n",
    "df_combo_morumbi = df_morumbi.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_morumbi = df_morumbi.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_morumbi = df_morumbi.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_morumbi = (df_combo_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_prato_unico_morumbi = (df_prato_unico_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_familia_morumbi = (df_familia_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "df_combo_outros = df_outros.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_outros = df_outros.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_outros = df_outros.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_outros = (df_combo_outros / df_outros_tamanho)\n",
    "porcentagem_prato_unico_outros = (df_prato_unico_outros / df_outros_tamanho)\n",
    "porcentagem_familia_outros = (df_familia_outros / df_outros_tamanho)\n",
    "\n",
    "df_combo_pinheiros = df_pinheiros.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_pinheiros = df_pinheiros.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_pinheiros = df_pinheiros.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_pinheiros = (df_combo_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_prato_unico_pinheiros = (df_prato_unico_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_familia_pinheiros = (df_familia_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "df_combo_santo_amaro = df_santo_amaro.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_santo_amaro = df_santo_amaro.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_santo_amaro = df_santo_amaro.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_santo_amaro = (df_combo_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_prato_unico_santo_amaro = (df_prato_unico_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_familia_santo_amaro = (df_familia_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "df_combo_vila_mariana = df_vila_mariana.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_vila_mariana = df_vila_mariana.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_vila_mariana = df_vila_mariana.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_vila_mariana = (df_combo_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_prato_unico_vila_mariana = (df_prato_unico_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_familia_vila_mariana = (df_familia_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "df_combo_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_vila_olimpia = (df_combo_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_prato_unico_vila_olimpia = (df_prato_unico_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_familia_vila_olimpia = (df_familia_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_brooklin[0], porcentagem_prato_unico_brooklin[0], porcentagem_familia_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_itaim[0], porcentagem_prato_unico_itaim[0], porcentagem_familia_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_jardins[0], porcentagem_prato_unico_jardins[0], porcentagem_familia_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_moema[0], porcentagem_prato_unico_moema[0], porcentagem_familia_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_morumbi[0], porcentagem_prato_unico_morumbi[0], porcentagem_familia_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_outros[0], porcentagem_prato_unico_outros[0], porcentagem_familia_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_pinheiros[0], porcentagem_prato_unico_pinheiros[0], porcentagem_familia_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_santo_amaro[0], porcentagem_prato_unico_santo_amaro[0], porcentagem_familia_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_vila_mariana[0], porcentagem_prato_unico_vila_mariana[0], porcentagem_familia_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Combo', 'Prato Único', 'Família'], y=[porcentagem_combo_vila_olimpia[0], porcentagem_prato_unico_vila_olimpia[0], porcentagem_familia_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Olímpia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c10be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_km'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['distance_km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['distance_km'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aee9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tempo_preparo_minutos'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['tempo_preparo_minutos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['tempo_preparo_minutos'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eta_minutes_quote'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['eta_minutes_quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07507ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['eta_minutes_quote'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_delivery_minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['actual_delivery_minutes'] < 0, 'actual_delivery_minutes'] = df.loc[df['actual_delivery_minutes'] < 0, 'actual_delivery_minutes'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e562947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['actual_delivery_minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['actual_delivery_minutes'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_brl'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['total_brl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc164450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['total_brl'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_itens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['num_itens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf09b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['num_itens'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfacao_nivel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e704db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['satisfacao_nivel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640d21e",
   "metadata": {},
   "source": [
    "Usando groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69604428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['platform', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'),\n",
    "                                                   DesvioPadrao=('total_brl', 'std'),\n",
    "                                                   QtdePedidos=('total_brl', 'count')).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rappi_satisfacao_tamanho = df.query('platform == \"rappi\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_1 = df.query('platform == \"rappi\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_2 = df.query('platform == \"rappi\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_3 = df.query('platform == \"rappi\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_4 = df.query('platform == \"rappi\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_5 = df.query('platform == \"rappi\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_rappi_satisfacao_1 = (df_rappi_satisfacao_1 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_2 = (df_rappi_satisfacao_2 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_3 = (df_rappi_satisfacao_3 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_4 = (df_rappi_satisfacao_4 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_5 = (df_rappi_satisfacao_5 / df_rappi_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_ifood_satisfacao_tamanho = df.query('platform == \"ifood\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_1 = df.query('platform == \"ifood\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_2 = df.query('platform == \"ifood\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_3 = df.query('platform == \"ifood\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_4 = df.query('platform == \"ifood\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_5 = df.query('platform == \"ifood\" and   satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_ifood_satisfacao_1 = (df_ifood_satisfacao_1 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_2 = (df_ifood_satisfacao_2 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_3 = (df_ifood_satisfacao_3 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_4 = (df_ifood_satisfacao_4 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_5 = (df_ifood_satisfacao_5 / df_ifood_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_whatsapp_satisfacao_tamanho = df.query('platform == \"whatsapp\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_1 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_2 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_3 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_4 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_5 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_whatsapp_satisfacao_1 = (df_whatsapp_satisfacao_1 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_2 = (df_whatsapp_satisfacao_2 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_3 = (df_whatsapp_satisfacao_3 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_4 = (df_whatsapp_satisfacao_4 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_5 = (df_whatsapp_satisfacao_5 / df_whatsapp_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_site_proprio_satisfacao_tamanho = df.query('platform == \"site_proprio\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_1 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_2 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_3 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_4 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_5 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_site_proprio_satisfacao_1 = (df_site_proprio_satisfacao_1 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_2 = (df_site_proprio_satisfacao_2 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_3 = (df_site_proprio_satisfacao_3 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_4 = (df_site_proprio_satisfacao_4 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_5 = (df_site_proprio_satisfacao_5 / df_site_proprio_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_retirada_satisacao_tamanho = df.query('order_mode == \"retirada\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_1 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique() \n",
    "df_retirada_satisacao_2 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_3 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_4 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_5 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_retirada_satisacao_1 = (df_retirada_satisacao_1 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_2 = (df_retirada_satisacao_2 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_3 = (df_retirada_satisacao_3 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_4 = (df_retirada_satisacao_4 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_5 = (df_retirada_satisacao_5 / df_retirada_satisacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_delivery_satisacao_tamanho = df.query('order_mode == \"delivery\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_1 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_2 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_3 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_4 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_5 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_delivery_satisacao_1 = (df_delivery_satisacao_1 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_2 = (df_delivery_satisacao_2 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_3 = (df_delivery_satisacao_3 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_4 = (df_delivery_satisacao_4 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_5 = (df_delivery_satisacao_5 / df_delivery_satisacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6, 6), sharey=True)\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_rappi_satisfacao_1[0], porcentagem_rappi_satisfacao_2[0], porcentagem_rappi_satisfacao_3[0],\n",
    "               porcentagem_rappi_satisfacao_4[0], porcentagem_rappi_satisfacao_5[0]],\n",
    "            ax=axes[0, 0]).set_title('Rappi')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_ifood_satisfacao_1[0], porcentagem_ifood_satisfacao_2[0], porcentagem_ifood_satisfacao_3[0],\n",
    "               porcentagem_ifood_satisfacao_4[0], porcentagem_ifood_satisfacao_5[0]],\n",
    "            ax=axes[0, 1]).set_title('iFood')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_whatsapp_satisfacao_1[0], porcentagem_whatsapp_satisfacao_2[0], porcentagem_whatsapp_satisfacao_3[0],\n",
    "               porcentagem_whatsapp_satisfacao_4[0], porcentagem_whatsapp_satisfacao_5[0]],\n",
    "            ax=axes[1, 0]).set_title('WhatsApp')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_site_proprio_satisfacao_1[0], porcentagem_site_proprio_satisfacao_2[0], porcentagem_site_proprio_satisfacao_3[0],\n",
    "               porcentagem_site_proprio_satisfacao_4[0], porcentagem_site_proprio_satisfacao_5[0]],\n",
    "            ax=axes[1, 1]).set_title('Site Próprio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), sharey=True)\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_retirada_satisacao_1[0], porcentagem_retirada_satisacao_2[0], porcentagem_retirada_satisacao_3[0],\n",
    "               porcentagem_retirada_satisacao_4[0], porcentagem_retirada_satisacao_5[0]],\n",
    "            ax=ax[0]).set_title('Retirada')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_delivery_satisacao_1[0], porcentagem_delivery_satisacao_2[0], porcentagem_delivery_satisacao_3[0],\n",
    "               porcentagem_delivery_satisacao_4[0], porcentagem_delivery_satisacao_5[0]],\n",
    "            ax=ax[1]).set_title('Delivery')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619b3f1",
   "metadata": {},
   "source": [
    "Podemos ver que o público da Kaiserhaus são de clientes que estão preocupados com um atendimento mais personalizado e focado na peculiaridade de cada cliente. Clientes que buscam por um nível de experiência diferenciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['platform']).agg(PrecoMedio=('total_brl', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['classe_pedido'])[['platform']].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_combo_ifood = df.query('classe_pedido == \"combo\" and platform == \"ifood\"').count().unique()\n",
    "qtd_combo_rappi = df.query('classe_pedido == \"combo\" and platform == \"rappi\"').count().unique()\n",
    "qtd_combo_whatsapp = df.query('classe_pedido == \"combo\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_combo_site_proprio = df.query('classe_pedido == \"combo\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "qtd_familia_ifood = df.query('classe_pedido == \"familia\" and platform == \"ifood\"').count().unique()\n",
    "qtd_familia_rappi = df.query('classe_pedido == \"familia\" and platform == \"rappi\"').count().unique()\n",
    "qtd_familia_whatsapp = df.query('classe_pedido == \"familia\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_familia_site_proprio = df.query('classe_pedido == \"familia\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "qtd_prato_unico_ifood = df.query('classe_pedido == \"prato_unico\" and platform == \"ifood\"').count().unique()\n",
    "qtd_prato_unico_rappi = df.query('classe_pedido == \"prato_unico\" and platform == \"rappi\"').count().unique()\n",
    "qtd_prato_unico_whatsapp = df.query('classe_pedido == \"prato_unico\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_prato_unico_site_proprio = df.query('classe_pedido == \"prato_unico\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 3),)\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_combo_ifood[0], qtd_combo_rappi[0], qtd_combo_whatsapp[0], qtd_combo_site_proprio[0]],\n",
    "            ax=ax[0]).set_title('Combo')\n",
    "\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_familia_ifood[0], qtd_familia_rappi[0], qtd_familia_whatsapp[0], qtd_familia_site_proprio[0]],\n",
    "            ax=ax[1]).set_title('Família')\n",
    "\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_prato_unico_ifood[0], qtd_prato_unico_rappi[0], qtd_prato_unico_whatsapp[0], qtd_prato_unico_site_proprio[0]],\n",
    "            ax=ax[2]).set_title('Prato Único')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['satisfacao_nivel'])[['total_brl']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('macro_bairro')['satisfacao_nivel'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['macro_bairro', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_niveis = [1, 2, 3, 4, 5]\n",
    "\n",
    "grp = (\n",
    "    df.groupby(['macro_bairro', 'satisfacao_nivel'])['total_brl']\n",
    "      .mean()\n",
    "      .reset_index(name='PrecoMedio')\n",
    ")\n",
    "\n",
    "wide = (grp\n",
    "        .pivot(index='macro_bairro', columns='satisfacao_nivel', values='PrecoMedio')\n",
    "        .reindex(columns=ordem_niveis)\n",
    "        .fillna(0.0))\n",
    "\n",
    "bairros = list(wide.index)\n",
    "\n",
    "n = len(bairros)\n",
    "ncols = 4\n",
    "nrows = math.ceil(n / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3*ncols, 2.8*nrows),\n",
    "                         sharex=True, sharey=True)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "ymax = (wide.max(axis=1).max() * 1.15) if n > 0 else 1.0\n",
    "if ymax <= 0: ymax = 1.0\n",
    "\n",
    "for ax, bairro in zip(axes, bairros):\n",
    "    y = wide.loc[bairro, ordem_niveis].values\n",
    "    ax.bar(ordem_niveis, y)\n",
    "    ax.set_title(str(bairro), fontsize=11, pad=6)\n",
    "    ax.set_xticks(ordem_niveis)\n",
    "    ax.set_xlabel('satisfacao_nivel')\n",
    "    ax.grid(axis='y', alpha=0.25)\n",
    "    ax.set_ylim(0, ymax)\n",
    "\n",
    "    for x, v in zip(ordem_niveis, y):\n",
    "        if v > 0:\n",
    "            ax.text(x, v, f'{v:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for ax in axes[len(bairros):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.supylabel('total_brl (média)')\n",
    "fig.supxlabel('Nível de satisfação')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['classe_pedido', 'satisfacao_nivel'])[['total_brl']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['order_mode', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'),\n",
    "                                                   DesvioPadrao=('total_brl', 'std'),\n",
    "                                                   QtdePedidos=('total_brl', 'count')).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby(['satisfacao_nivel'])['total_brl']\n",
    "df_groupby.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORREÇÃO DE VALORES INFINITOS E PROBLEMAS DE DADOS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verificar valores infinitos em todo o DataFrame\n",
    "print(\"🔍 VERIFICAÇÃO DE VALORES INFINITOS:\")\n",
    "print(f\"Valores infinitos no DataFrame: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Identificar colunas com valores infinitos\n",
    "colunas_com_infinitos = []\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if np.isinf(df[col]).any():\n",
    "        colunas_com_infinitos.append(col)\n",
    "        print(f\"  {col}: {np.isinf(df[col]).sum()} valores infinitos\")\n",
    "\n",
    "# Corrigir valores infinitos\n",
    "if colunas_com_infinitos:\n",
    "    print(f\"\\n🔧 CORRIGINDO VALORES INFINITOS:\")\n",
    "    for col in colunas_com_infinitos:\n",
    "        # Substituir infinitos por NaN\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # Preencher NaN com valores médios\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "        print(f\"  {col}: Corrigido\")\n",
    "\n",
    "# Verificar novamente após correção\n",
    "print(f\"\\n✅ Valores infinitos após correção: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Verificar se há valores muito grandes que podem causar problemas\n",
    "print(f\"\\n🔍 VERIFICAÇÃO DE VALORES EXTREMOS:\")\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    max_val = df[col].max()\n",
    "    min_val = df[col].min()\n",
    "    if max_val > 1e10 or min_val < -1e10:\n",
    "        print(f\"  {col}: max={max_val:.2e}, min={min_val:.2e}\")\n",
    "\n",
    "print(\"\\n✅ Dados limpos e prontos para análise!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. criando features\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 2. Features de eficiência e lucratividade\n",
    "df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# 3. Encoding de variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_platform = LabelEncoder()\n",
    "df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "\n",
    "le_order_mode = LabelEncoder()\n",
    "df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "\n",
    "le_status = LabelEncoder()\n",
    "df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "\n",
    "# Verificar se as colunas críticas existem\n",
    "colunas_criticas = ['eficiencia_entrega', 'lucro_estimado', 'platform_encoded']\n",
    "for col in colunas_criticas:\n",
    "    if col in df.columns:\n",
    "        pass \n",
    "    else:\n",
    "        print(f\"❌ {col}: FALTANDO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa522c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. MATRIZ DE CORRELAÇÃO\n",
    "\n",
    "\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "# 2. ANÁLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "\n",
    "# 3. ANÁLISE DE RENTABILIDADE POR REGIÃO\n",
    "\n",
    "\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb68b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIÇÃO DE VARIÁVEIS NECESSÁRIAS PARA AS ANÁLISES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Definir features para análise de satisfação\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Definir features para clustering\n",
    "features_clustering = [\n",
    "    'total_brl', 'num_itens', 'tempo_preparo_minutos', \n",
    "    'actual_delivery_minutes', 'distance_km', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', \n",
    "    'dia_semana', 'hora', 'fim_de_semana'\n",
    "]\n",
    "\n",
    "# Verificar se as colunas existem no DataFrame\n",
    "print(\"🔍 VERIFICAÇÃO DAS FEATURES:\")\n",
    "print(f\"Features para satisfação: {len(features_satisfacao)}\")\n",
    "print(f\"Features para clustering: {len(features_clustering)}\")\n",
    "\n",
    "# Verificar se as colunas existem\n",
    "colunas_faltando = []\n",
    "for col in features_satisfacao + features_clustering:\n",
    "    if col not in df.columns:\n",
    "        colunas_faltando.append(col)\n",
    "\n",
    "if colunas_faltando:\n",
    "    print(f\"⚠️ Colunas faltando: {colunas_faltando}\")\n",
    "else:\n",
    "    print(\"✅ Todas as features estão disponíveis no DataFrame\")\n",
    "\n",
    "print(f\"\\n📊 Shape do DataFrame: {df.shape}\")\n",
    "print(\"✅ Variáveis definidas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORREÇÃO DO ERRO DE PREVISÃO DE SATISFAÇÃO\n",
    "\n",
    "print(\"🔧 INICIANDO CORREÇÃO DO ERRO DE PREVISÃO...\")\n",
    "\n",
    "# Verificar se o modelo foi treinado\n",
    "try:\n",
    "    # Verificar se o modelo existe\n",
    "    if 'modelo_satisfacao' not in locals():\n",
    "        print(\"❌ Modelo de satisfação não foi treinado. Execute a célula de treinamento primeiro.\")\n",
    "    else:\n",
    "        # Preparar dados para previsão - corrigir infinitos primeiro\n",
    "        df_predicao = df[features_satisfacao].copy()\n",
    "        \n",
    "        # Verificar valores infinitos\n",
    "        print(f\"Valores infinitos antes da correção: {np.isinf(df_predicao).sum().sum()}\")\n",
    "        \n",
    "        # Substituir infinitos por NaN\n",
    "        df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Preencher NaN com valores médios\n",
    "        df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "        \n",
    "        # Verificar se há valores infinitos antes da previsão\n",
    "        print(f\"Valores infinitos após correção: {np.isinf(df_predicao).sum().sum()}\")\n",
    "        \n",
    "        # Fazer previsão\n",
    "        print(\"🎯 Fazendo previsão...\")\n",
    "        df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "        pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "        \n",
    "        print(f\"\\n✅ PREVISÃO CONCLUÍDA COM SUCESSO!\")\n",
    "        print(f\"Total de pedidos: {len(df)}\")\n",
    "        print(f\"Pedidos de risco (baixa satisfação): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Características dos pedidos de risco\n",
    "        if len(pedidos_risco) > 0:\n",
    "            caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "            caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "            \n",
    "            print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "            comparacao = pd.DataFrame({\n",
    "                'Pedidos_Risco': caracteristicas_risco,\n",
    "                'Pedidos_Geral': caracteristicas_gerais\n",
    "            })\n",
    "            comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "            print(comparacao.round(2))\n",
    "        else:\n",
    "            print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro durante a previsão: {str(e)}\")\n",
    "    print(\"💡 Execute primeiro a célula de treinamento do modelo de satisfação.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7640f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINAMENTO DO MODELO DE PREVISÃO DE SATISFAÇÃO\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"🤖 TREINANDO MODELO DE PREVISÃO DE SATISFAÇÃO...\")\n",
    "\n",
    "# Criar variável alvo categórica para classificação\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar features para o modelo de satisfação\n",
    "print(f\"📊 Features utilizadas: {len(features_satisfacao)}\")\n",
    "\n",
    "# Remover linhas com valores NaN e infinitos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Verificar valores infinitos\n",
    "print(f\"Valores infinitos antes da limpeza: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "# Limpar dados\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean = df_satisfacao_clean.dropna()\n",
    "\n",
    "print(f\"Shape após limpeza: {df_satisfacao_clean.shape}\")\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "print(f\"Distribuição das classes: {y_sat.value_counts().to_dict()}\")\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "print(f\"📊 Dados de treino: {X_train_sat.shape[0]} amostras\")\n",
    "print(f\"📊 Dados de teste: {X_test_sat.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest para classificação\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE DO MODELO:\")\n",
    "print(f\"Acurácia: {accuracy:.3f}\")\n",
    "\n",
    "# Importância das features para satisfação\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\n📊 TOP 5 FEATURES MAIS IMPORTANTES:\")\n",
    "print(importancia_satisfacao.head())\n",
    "\n",
    "print(f\"\\n✅ MODELO DE SATISFAÇÃO TREINADO COM SUCESSO!\")\n",
    "print(\"🚀 Pronto para fazer previsões!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa897eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUÇÃO COMPLETA E SEGURA DAS ANÁLISES\n",
    "\n",
    "print(\"🚀 EXECUTANDO TODAS AS ANÁLISES DA FASE 2...\")\n",
    "\n",
    "try:\n",
    "    # 1. Verificar se o modelo foi treinado\n",
    "    if 'modelo_satisfacao' in locals():\n",
    "        print(\"✅ Modelo de satisfação encontrado!\")\n",
    "        \n",
    "        # 2. Preparar dados para previsão\n",
    "        print(\"🔧 Preparando dados para previsão...\")\n",
    "        df_predicao = df[features_satisfacao].copy()\n",
    "        \n",
    "        # Verificar valores infinitos\n",
    "        infinitos_antes = np.isinf(df_predicao).sum().sum()\n",
    "        print(f\"Valores infinitos antes da correção: {infinitos_antes}\")\n",
    "        \n",
    "        # Corrigir infinitos\n",
    "        df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "        df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "        \n",
    "        infinitos_depois = np.isinf(df_predicao).sum().sum()\n",
    "        print(f\"Valores infinitos após correção: {infinitos_depois}\")\n",
    "        \n",
    "        # 3. Fazer previsão\n",
    "        print(\"🎯 Fazendo previsão de satisfação...\")\n",
    "        df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "        \n",
    "        # 4. Análise dos resultados\n",
    "        pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "        \n",
    "        print(f\"\\n✅ ANÁLISE CONCLUÍDA COM SUCESSO!\")\n",
    "        print(f\"Total de pedidos: {len(df)}\")\n",
    "        print(f\"Pedidos de risco (baixa satisfação): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 5. Características dos pedidos de risco\n",
    "        if len(pedidos_risco) > 0:\n",
    "            caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "            caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "            \n",
    "            print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "            comparacao = pd.DataFrame({\n",
    "                'Pedidos_Risco': caracteristicas_risco,\n",
    "                'Pedidos_Geral': caracteristicas_gerais\n",
    "            })\n",
    "            comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "            print(comparacao.round(2))\n",
    "            \n",
    "            # 6. Insights adicionais\n",
    "            print(f\"\\n💡 INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "            print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "            print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "            print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "            print(f\"Satisfação média real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "        else:\n",
    "            print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"❌ Modelo de satisfação não encontrado!\")\n",
    "        print(\"💡 Execute primeiro a célula de treinamento do modelo.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro durante a execução: {str(e)}\")\n",
    "    print(\"💡 Verifique se todas as células anteriores foram executadas.\")\n",
    "\n",
    "print(f\"\\n🎯 STATUS FINAL DAS ANÁLISES:\")\n",
    "print(\"✅ Fase 1: Matriz de Correlação, Rentabilidade por Plataforma e Região\")\n",
    "print(\"✅ Fase 2: Modelo de Previsão de Demanda\")\n",
    "print(\"✅ Fase 2: Análise de Satisfação\")\n",
    "print(\"✅ Fase 2: Segmentação de Clientes\")\n",
    "print(\"\\n🚀 TODAS AS ANÁLISES AVANÇADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUÇÃO DEFINITIVA - EXECUÇÃO COMPLETA EM UMA CÉLULA\n",
    "\n",
    "print(\"🚀 EXECUTANDO SOLUÇÃO DEFINITIVA - TODAS AS ANÁLISES EM UMA CÉLULA...\")\n",
    "\n",
    "# Importar todas as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. DEFINIR FEATURES\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "print(f\"✅ Features definidas: {len(features_satisfacao)} variáveis\")\n",
    "\n",
    "# 2. TREINAR MODELO DE SATISFAÇÃO\n",
    "print(\"\\n🤖 TREINANDO MODELO DE SATISFAÇÃO...\")\n",
    "\n",
    "# Criar variável alvo categórica\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar dados limpos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean = df_satisfacao_clean.dropna()\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "# Dividir e treinar\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "accuracy = accuracy_score(y_test_sat, modelo_satisfacao.predict(X_test_sat))\n",
    "print(f\"✅ Modelo treinado com acurácia: {accuracy:.3f}\")\n",
    "\n",
    "# 3. FAZER PREVISÃO DE SATISFAÇÃO\n",
    "print(\"\\n🎯 FAZENDO PREVISÃO DE SATISFAÇÃO...\")\n",
    "\n",
    "# Preparar dados para previsão\n",
    "df_predicao = df[features_satisfacao].copy()\n",
    "df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "\n",
    "print(f\"Valores infinitos após limpeza: {np.isinf(df_predicao).sum().sum()}\")\n",
    "\n",
    "# Fazer previsão\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"✅ Previsão concluída!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 4. ANÁLISE DOS PEDIDOS DE RISCO\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    \n",
    "    caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "    caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "    \n",
    "    comparacao = pd.DataFrame({\n",
    "        'Pedidos_Risco': caracteristicas_risco,\n",
    "        'Pedidos_Geral': caracteristicas_gerais\n",
    "    })\n",
    "    comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "    print(comparacao.round(2))\n",
    "    \n",
    "    print(f\"\\n💡 INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfação média real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "\n",
    "# 5. IMPORTÂNCIA DAS FEATURES\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\n📊 TOP 5 FEATURES MAIS IMPORTANTES PARA SATISFAÇÃO:\")\n",
    "print(importancia_satisfacao.head())\n",
    "\n",
    "print(f\"\\n🎯 STATUS FINAL:\")\n",
    "print(\"✅ Fase 1: Matriz de Correlação, Rentabilidade por Plataforma e Região\")\n",
    "print(\"✅ Fase 2: Modelo de Previsão de Demanda\")\n",
    "print(\"✅ Fase 2: Análise de Satisfação - CONCLUÍDA\")\n",
    "print(\"✅ Fase 2: Segmentação de Clientes\")\n",
    "print(\"\\n🚀 TODAS AS ANÁLISES AVANÇADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUÇÃO DEFINITIVA - LIMPEZA COMPLETA E ROBUSTA\n",
    "\n",
    "print(\"🔧 EXECUTANDO LIMPEZA COMPLETA E ROBUSTA DOS DADOS...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPEZA COMPLETA DO DATAFRAME PRINCIPAL\n",
    "print(\"🧹 Limpando DataFrame principal...\")\n",
    "\n",
    "# Verificar valores infinitos em todo o DataFrame\n",
    "infinitos_totais = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"Valores infinitos no DataFrame: {infinitos_totais}\")\n",
    "\n",
    "# Limpar valores infinitos em todas as colunas numéricas\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if np.isinf(df[col]).any():\n",
    "        print(f\"Limpando coluna: {col}\")\n",
    "        # Substituir infinitos por NaN\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # Preencher NaN com mediana (mais robusta que média)\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Verificar novamente\n",
    "infinitos_apos_limpeza = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"Valores infinitos após limpeza: {infinitos_apos_limpeza}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES E CRIAR VARIÁVEL ALVO\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar variável alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"✅ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS LIMPOS PARA TREINAMENTO\n",
    "print(\"🤖 Preparando dados para treinamento...\")\n",
    "\n",
    "# Criar DataFrame limpo apenas com as features necessárias\n",
    "df_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Verificar valores infinitos nas features\n",
    "infinitos_features = np.isinf(df_clean[features_satisfacao]).sum().sum()\n",
    "print(f\"Valores infinitos nas features: {infinitos_features}\")\n",
    "\n",
    "# Limpar novamente se necessário\n",
    "if infinitos_features > 0:\n",
    "    print(\"Limpando features específicas...\")\n",
    "    for col in features_satisfacao:\n",
    "        df_clean[col] = df_clean[col].replace([np.inf, -np.inf], np.nan)\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# Remover linhas com NaN\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "print(f\"Shape após limpeza: {df_clean.shape}\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"🎯 Treinando modelo...\")\n",
    "\n",
    "X = df_clean[features_satisfacao]\n",
    "y = df_clean['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"✅ Modelo treinado com acurácia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. FAZER PREVISÃO SEGURA\n",
    "print(\"🔮 Fazendo previsão segura...\")\n",
    "\n",
    "# Preparar dados para previsão (usar apenas as features necessárias)\n",
    "df_pred = df[features_satisfacao].copy()\n",
    "\n",
    "# Verificar valores infinitos\n",
    "infinitos_pred = np.isinf(df_pred).sum().sum()\n",
    "print(f\"Valores infinitos para previsão: {infinitos_pred}\")\n",
    "\n",
    "# Limpar se necessário\n",
    "if infinitos_pred > 0:\n",
    "    for col in features_satisfacao:\n",
    "        df_pred[col] = df_pred[col].replace([np.inf, -np.inf], np.nan)\n",
    "        df_pred[col] = df_pred[col].fillna(df_pred[col].median())\n",
    "\n",
    "# Verificar NaN\n",
    "nan_pred = df_pred.isnull().sum().sum()\n",
    "print(f\"Valores NaN para previsão: {nan_pred}\")\n",
    "\n",
    "# Preencher NaN se necessário\n",
    "if nan_pred > 0:\n",
    "    df_pred = df_pred.fillna(df_pred.median())\n",
    "\n",
    "# Fazer previsão\n",
    "print(\"Executando previsão...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_pred)\n",
    "\n",
    "# 6. ANÁLISE DOS RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n✅ PREVISÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfação média real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\n🎯 ANÁLISE DE SATISFAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"🚀 Pronto para as próximas análises!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUÇÃO FINAL - LIMPEZA TOTAL E PREVENÇÃO DE ERROS\n",
    "\n",
    "print(\"🚀 EXECUTANDO SOLUÇÃO FINAL - LIMPEZA TOTAL...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPEZA AGRESSIVA DE TODOS OS VALORES INFINITOS\n",
    "print(\"🧹 LIMPEZA AGRESSIVA DE VALORES INFINITOS...\")\n",
    "\n",
    "# Função para limpar valores infinitos de forma agressiva\n",
    "def limpar_infinitos_agressivo(df):\n",
    "    \"\"\"Limpa valores infinitos de forma agressiva\"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        # Verificar se há infinitos\n",
    "        if np.isinf(df[col]).any():\n",
    "            print(f\"Limpando infinitos na coluna: {col}\")\n",
    "            # Substituir infinitos por NaN\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            # Preencher com mediana\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            # Se ainda houver NaN, preencher com 0\n",
    "            df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "# Aplicar limpeza agressiva\n",
    "df = limpar_infinitos_agressivo(df)\n",
    "\n",
    "# Verificar resultado\n",
    "infinitos_finais = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"✅ Valores infinitos após limpeza agressiva: {infinitos_finais}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES E VARIÁVEL ALVO\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar variável alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"✅ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS PARA TREINAMENTO\n",
    "print(\"🤖 Preparando dados para treinamento...\")\n",
    "\n",
    "# Criar DataFrame limpo\n",
    "df_ml = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Limpar novamente especificamente para ML\n",
    "df_ml = limpar_infinitos_agressivo(df_ml)\n",
    "\n",
    "# Remover NaN\n",
    "df_ml = df_ml.dropna()\n",
    "\n",
    "print(f\"Shape dos dados para ML: {df_ml.shape}\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"🎯 Treinando modelo...\")\n",
    "\n",
    "X = df_ml[features_satisfacao]\n",
    "y = df_ml['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"✅ Modelo treinado com acurácia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. PREVISÃO SEGURA\n",
    "print(\"🔮 Fazendo previsão segura...\")\n",
    "\n",
    "# Preparar dados para previsão\n",
    "df_pred = df[features_satisfacao].copy()\n",
    "\n",
    "# Limpar dados de previsão\n",
    "df_pred = limpar_infinitos_agressivo(df_pred)\n",
    "\n",
    "# Verificar se há NaN\n",
    "nan_count = df_pred.isnull().sum().sum()\n",
    "print(f\"Valores NaN para previsão: {nan_count}\")\n",
    "\n",
    "# Preencher NaN se necessário\n",
    "if nan_count > 0:\n",
    "    df_pred = df_pred.fillna(0)\n",
    "\n",
    "# Verificar valores infinitos\n",
    "inf_count = np.isinf(df_pred).sum().sum()\n",
    "print(f\"Valores infinitos para previsão: {inf_count}\")\n",
    "\n",
    "# Fazer previsão\n",
    "print(\"Executando previsão...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_pred)\n",
    "\n",
    "# 6. RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n🎉 SUCESSO! PREVISÃO CONCLUÍDA!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfação média real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\n🚀 ANÁLISE DE SATISFAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"✅ Pronto para as próximas análises da Fase 2!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUÇÃO DEFINITIVA - EXECUTE ESTA CÉLULA AGORA!\n",
    "\n",
    "print(\"🚀 EXECUTANDO SOLUÇÃO DEFINITIVA...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPAR TODOS OS VALORES INFINITOS DO DATAFRAME\n",
    "print(\"🧹 Limpando valores infinitos...\")\n",
    "\n",
    "# Função simples para limpar infinitos\n",
    "for coluna in df.columns:\n",
    "    if df[coluna].dtype in ['float64', 'float32', 'int64', 'int32']:\n",
    "        # Substituir infinitos por 0\n",
    "        df[coluna] = df[coluna].replace([np.inf, -np.inf], 0)\n",
    "        # Preencher NaN com 0\n",
    "        df[coluna] = df[coluna].fillna(0)\n",
    "\n",
    "# Verificar se ainda há infinitos\n",
    "infinitos_restantes = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"✅ Valores infinitos restantes: {infinitos_restantes}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar variável alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"✅ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS LIMPOS\n",
    "print(\"🤖 Preparando dados...\")\n",
    "\n",
    "# Criar DataFrame limpo\n",
    "df_limpo = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Remover linhas com NaN\n",
    "df_limpo = df_limpo.dropna()\n",
    "\n",
    "print(f\"✅ Dados limpos: {df_limpo.shape[0]} registros\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"🎯 Treinando modelo...\")\n",
    "\n",
    "X = df_limpo[features_satisfacao]\n",
    "y = df_limpo['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"✅ Modelo treinado com acurácia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. FAZER PREVISÃO\n",
    "print(\"🔮 Fazendo previsão...\")\n",
    "\n",
    "# Preparar dados para previsão\n",
    "df_previsao = df[features_satisfacao].copy()\n",
    "\n",
    "# Garantir que não há infinitos\n",
    "for col in features_satisfacao:\n",
    "    df_previsao[col] = df_previsao[col].replace([np.inf, -np.inf], 0)\n",
    "    df_previsao[col] = df_previsao[col].fillna(0)\n",
    "\n",
    "# Fazer previsão\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_previsao)\n",
    "\n",
    "# 6. ANÁLISE DOS RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n🎉 SUCESSO! ANÁLISE CONCLUÍDA!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\n🔍 INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfação média real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"🎉 Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\n🚀 ANÁLISE DE SATISFAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"✅ Pronto para continuar com as outras análises!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39486d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando features necessarias p analise dos dados\n",
    "\n",
    "# Verificar se as colunas já existem, se não, criar\n",
    "if 'ano' not in df.columns:\n",
    "    df['ano'] = df['order_datetime'].dt.year\n",
    "if 'mes' not in df.columns:\n",
    "    df['mes'] = df['order_datetime'].dt.month\n",
    "if 'dia_semana' not in df.columns:\n",
    "    df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "if 'hora' not in df.columns:\n",
    "    df['hora'] = df['order_datetime'].dt.hour\n",
    "if 'fim_de_semana' not in df.columns:\n",
    "    df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Criar features de eficiência e lucratividade\n",
    "if 'eficiencia_entrega' not in df.columns:\n",
    "    df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "if 'lucro_estimado' not in df.columns:\n",
    "    df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "if 'lucro_por_item' not in df.columns:\n",
    "    df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# Encoding de variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if 'platform_encoded' not in df.columns:\n",
    "    le_platform = LabelEncoder()\n",
    "    df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "if 'order_mode_encoded' not in df.columns:\n",
    "    le_order_mode = LabelEncoder()\n",
    "    df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "if 'status_encoded' not in df.columns:\n",
    "    le_status = LabelEncoder()\n",
    "    df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "\n",
    "# 2. CRIAR MATRIZ DE CORRELAÇÃO\n",
    "\n",
    "\n",
    "# Selecionar variáveis numéricas relevantes para análise estratégica\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "# Criar matriz de correlação\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "\n",
    "\n",
    "# 3. ANÁLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# 4. ANÁLISE DE RENTABILIDADE POR REGIÃO\n",
    "\n",
    "\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae095b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSTRAR RESULTADOS DAS ANÁLISES\n",
    "\n",
    "# 1. INSIGHTS DA MATRIZ DE CORRELAÇÃO\n",
    "print(\"\\n🔍 INSIGHTS DA MATRIZ DE CORRELAÇÃO:\")\n",
    "\n",
    "# Correlações com SATISFAÇÃO\n",
    "print(\"\\n📊 CORRELAÇÕES COM SATISFAÇÃO:\")\n",
    "satisfacao_corr = correlation_matrix['satisfacao_nivel'].sort_values(ascending=False)\n",
    "for var, corr in satisfacao_corr.items():\n",
    "    if var != 'satisfacao_nivel' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# Correlações com RECEITA TOTAL\n",
    "print(\"\\n💰 CORRELAÇÕES COM RECEITA TOTAL:\")\n",
    "receita_corr = correlation_matrix['total_brl'].sort_values(ascending=False)\n",
    "for var, corr in receita_corr.items():\n",
    "    if var != 'total_brl' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# Correlações com LUCRO ESTIMADO\n",
    "print(\"\\n📈 CORRELAÇÕES COM LUCRO ESTIMADO:\")\n",
    "lucro_corr = correlation_matrix['lucro_estimado'].sort_values(ascending=False)\n",
    "for var, corr in lucro_corr.items():\n",
    "    if var != 'lucro_estimado' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 2. RENTABILIDADE POR PLATAFORMA\n",
    "print(\"\\n🏪 RENTABILIDADE POR PLATAFORMA:\")\n",
    "print(rentabilidade_plataforma_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Comissao_Media', 'Satisfacao_Media', 'Rentabilidade_por_Pedido', 'Margem_Liquida_%']])\n",
    "\n",
    "# 3. RENTABILIDADE POR REGIÃO (TOP 10)\n",
    "print(\"\\n📍 TOP 10 REGIÕES POR RECEITA:\")\n",
    "print(rentabilidade_regiao_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Distancia_Media', 'Satisfacao_Media', 'Receita_por_km', 'Lucro_por_km', 'Margem_Liquida_%']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAÇÕES ESTRATÉGICAS DA FASE 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Criar figura com subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Matriz de Correlação\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, fmt='.2f', ax=axes[0,0], cbar_kws={\"shrink\": .8})\n",
    "axes[0,0].set_title('Matriz de Correlação')\n",
    "\n",
    "# 2. Rentabilidade por Plataforma\n",
    "rentabilidade_plataforma_ordenada['Rentabilidade_por_Pedido'].plot(kind='bar', ax=axes[0,1], color='skyblue')\n",
    "axes[0,1].set_title('Rentabilidade por Pedido - Plataforma')\n",
    "axes[0,1].set_ylabel('R$ por pedido')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Satisfação por Plataforma\n",
    "rentabilidade_plataforma_ordenada['Satisfacao_Media'].plot(kind='bar', ax=axes[0,2], color='lightcoral')\n",
    "axes[0,2].set_title('Satisfação Média por Plataforma')\n",
    "axes[0,2].set_ylabel('Satisfação (1-5)')\n",
    "axes[0,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Top 8 Regiões por Receita\n",
    "top_regioes = rentabilidade_regiao_ordenada.head(8)\n",
    "axes[1,0].barh(range(len(top_regioes)), top_regioes['Receita_Total'])\n",
    "axes[1,0].set_yticks(range(len(top_regioes)))\n",
    "axes[1,0].set_yticklabels(top_regioes.index)\n",
    "axes[1,0].set_xlabel('Receita Total (R$)')\n",
    "axes[1,0].set_title('Top 8 Regiões por Receita')\n",
    "\n",
    "# 5. Receita por km por Região\n",
    "top_regioes_receita_km = rentabilidade_regiao_ordenada.head(8)\n",
    "axes[1,1].barh(range(len(top_regioes_receita_km)), top_regioes_receita_km['Receita_por_km'])\n",
    "axes[1,1].set_yticks(range(len(top_regioes_receita_km)))\n",
    "axes[1,1].set_yticklabels(top_regioes_receita_km.index)\n",
    "axes[1,1].set_xlabel('Receita por km (R$)')\n",
    "axes[1,1].set_title('Receita por km - Top 8 Regiões')\n",
    "\n",
    "# 6. Satisfação vs Distância por Região\n",
    "axes[1,2].scatter(rentabilidade_regiao_ordenada['Distancia_Media'], \n",
    "                 rentabilidade_regiao_ordenada['Satisfacao_Media'],\n",
    "                 s=rentabilidade_regiao_ordenada['Qtd_Pedidos']*2, alpha=0.6)\n",
    "axes[1,2].set_xlabel('Distância Média (km)')\n",
    "axes[1,2].set_ylabel('Satisfação Média')\n",
    "axes[1,2].set_title('Satisfação vs Distância por Região')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORREÇÃO DA LINHA PROBLEMÁTICA\n",
    "\n",
    "print(\"🔧 Corrigindo a linha problemática...\")\n",
    "\n",
    "# Limpar dados antes da previsão\n",
    "df_previsao = df[features_satisfacao].copy()\n",
    "\n",
    "# Substituir infinitos por 0\n",
    "for col in features_satisfacao:\n",
    "    df_previsao[col] = df_previsao[col].replace([np.inf, -np.inf], 0)\n",
    "    df_previsao[col] = df_previsao[col].fillna(0)\n",
    "\n",
    "# Verificar se ainda há infinitos\n",
    "infinitos_restantes = np.isinf(df_previsao).sum().sum()\n",
    "print(f\"✅ Valores infinitos restantes: {infinitos_restantes}\")\n",
    "\n",
    "# Fazer previsão com dados limpos\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_previsao)\n",
    "\n",
    "print(\"✅ Previsão concluída com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79576993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MATRIZ DE CORRELAÇÃO - PONTO DE PARTIDA ESTRATÉGICO\n",
    "\n",
    "# Preparar dados para análise de correlação\n",
    "\n",
    "# Criar features temporais\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Criar features de eficiência e lucratividade\n",
    "df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# Encoding de variáveis categóricas para correlação\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_platform = LabelEncoder()\n",
    "le_order_mode = LabelEncoder()\n",
    "le_status = LabelEncoder()\n",
    "\n",
    "df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "print(f\"📊 Shape final: {df.shape}\")\n",
    "print(f\"🔢 Colunas numéricas: {df.select_dtypes(include=['number']).columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar matriz de correlação com variáveis estratégicas\n",
    "print(\"=== MATRIZ DE CORRELAÇÃO - INSIGHTS ESTRATÉGICOS ===\")\n",
    "\n",
    "# Selecionar variáveis numéricas relevantes para análise estratégica\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "# Criar matriz de correlação\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "print(\"📊 Matriz de correlação das variáveis estratégicas:\")\n",
    "print(correlation_matrix.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de correlação com heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Criar heatmap com anotações\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('🔍 MATRIZ DE CORRELAÇÃO - KAISERHAUS\\n(Valores próximos de 1 = correlação forte positiva, -1 = forte negativa)', \n",
    "          fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das correlações mais importantes para o negócio\n",
    "print(\"=== INSIGHTS ESTRATÉGICOS BASEADOS NA CORRELAÇÃO ===\")\n",
    "\n",
    "# 1. Correlações com SATISFAÇÃO (variável chave para retenção)\n",
    "print(\"🔍 CORRELAÇÕES COM SATISFAÇÃO:\")\n",
    "satisfacao_corr = correlation_matrix['satisfacao_nivel'].sort_values(ascending=False)\n",
    "for var, corr in satisfacao_corr.items():\n",
    "    if var != 'satisfacao_nivel' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 2. Correlações com RECEITA TOTAL (impacto financeiro)\n",
    "print(\"\\n💰 CORRELAÇÕES COM RECEITA TOTAL:\")\n",
    "receita_corr = correlation_matrix['total_brl'].sort_values(ascending=False)\n",
    "for var, corr in receita_corr.items():\n",
    "    if var != 'total_brl' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 3. Correlações com LUCRO ESTIMADO (rentabilidade)\n",
    "print(\"\\n📈 CORRELAÇÕES COM LUCRO ESTIMADO:\")\n",
    "lucro_corr = correlation_matrix['lucro_estimado'].sort_values(ascending=False)\n",
    "for var, corr in lucro_corr.items():\n",
    "    if var != 'lucro_estimado' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 4. Correlações com EFICIÊNCIA DE ENTREGA (operacional)\n",
    "print(\"\\n🚚 CORRELAÇÕES COM EFICIÊNCIA DE ENTREGA:\")\n",
    "eficiencia_corr = correlation_matrix['eficiencia_entrega'].sort_values(ascending=False)\n",
    "for var, corr in eficiencia_corr.items():\n",
    "    if var != 'eficiencia_entrega' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ANÁLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "# Verificar se as colunas necessárias existem\n",
    "colunas_necessarias = ['total_brl', 'platform_commission_pct', 'satisfacao_nivel', 'lucro_estimado', 'eficiencia_entrega']\n",
    "colunas_faltando = [col for col in colunas_necessarias if col not in df.columns]\n",
    "\n",
    "if colunas_faltando:\n",
    "    print(f\"⚠️ Colunas faltando: {colunas_faltando}\")\n",
    "    print(\"Execute a célula anterior primeiro para criar as features necessárias!\")\n",
    "else:\n",
    "    pass  # Continuar com análise\n",
    "\n",
    "# Calcular métricas de rentabilidade por plataforma\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas para melhor visualização\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "print(\"📊 Análise de Rentabilidade por Plataforma:\")\n",
    "print(rentabilidade_plataforma_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Comissao_Media', 'Satisfacao_Media', 'Rentabilidade_por_Pedido', 'Margem_Liquida_%']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ANÁLISE DE RENTABILIDADE POR REGIÃO\n",
    "\n",
    "# Calcular métricas de rentabilidade por região\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n",
    "print(\"📊 Análise de Rentabilidade por Região:\")\n",
    "print(rentabilidade_regiao_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Distancia_Media', 'Satisfacao_Media', 'Receita_por_km', 'Lucro_por_km', 'Margem_Liquida_%']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d0898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d4019b",
   "metadata": {},
   "source": [
    "# 🚀 FASE 2 - ANÁLISES AVANÇADAS\n",
    "\n",
    "## 4. MODELO DE PREVISÃO DE DEMANDA - Otimizar Volume\n",
    "\n",
    "O objetivo é criar um modelo preditivo para prever a demanda futura, permitindo:\n",
    "- **Otimização de recursos** (funcionários, ingredientes)\n",
    "- **Planejamento estratégico** de expansão\n",
    "- **Redução de desperdícios** operacionais\n",
    "- **Maximização do volume** de pedidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 PREPARAÇÃO DOS DADOS PARA PREVISÃO DE DEMANDA\n",
    "\n",
    "# Criar série temporal diária\n",
    "df['data'] = df['order_datetime'].dt.date\n",
    "demanda_diaria = df.groupby('data').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "demanda_diaria.columns = ['Volume_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Satisfacao_Media', 'Tempo_Preparo_Medio', 'Tempo_Entrega_Medio']\n",
    "\n",
    "# Criar features temporais para o modelo\n",
    "demanda_diaria['dia_semana'] = pd.to_datetime(demanda_diaria.index).dayofweek\n",
    "demanda_diaria['fim_de_semana'] = demanda_diaria['dia_semana'].isin([5, 6]).astype(int)\n",
    "demanda_diaria['mes'] = pd.to_datetime(demanda_diaria.index).month\n",
    "\n",
    "# Calcular médias móveis para suavizar tendências\n",
    "demanda_diaria['Volume_MA_7'] = demanda_diaria['Volume_Pedidos'].rolling(window=7).mean()\n",
    "demanda_diaria['Receita_MA_7'] = demanda_diaria['Receita_Total'].rolling(window=7).mean()\n",
    "\n",
    "# Calcular variação percentual\n",
    "demanda_diaria['Variacao_Volume'] = demanda_diaria['Volume_Pedidos'].pct_change()\n",
    "demanda_diaria['Variacao_Receita'] = demanda_diaria['Receita_Total'].pct_change()\n",
    "\n",
    "print(\"📊 Dados preparados para previsão de demanda:\")\n",
    "print(f\"Shape: {demanda_diaria.shape}\")\n",
    "print(f\"Período: {demanda_diaria.index.min()} a {demanda_diaria.index.max()}\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "print(demanda_diaria.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 MODELO DE PREVISÃO DE DEMANDA - MACHINE LEARNING\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparar dados para treinamento (remover valores NaN)\n",
    "demanda_clean = demanda_diaria.dropna()\n",
    "\n",
    "# Definir variáveis preditoras (features)\n",
    "features = ['dia_semana', 'fim_de_semana', 'mes', 'Volume_MA_7', 'Receita_MA_7', 'Variacao_Volume', 'Variacao_Receita']\n",
    "X = demanda_clean[features]\n",
    "\n",
    "# Definir variável alvo (volume de pedidos)\n",
    "y = demanda_clean['Volume_Pedidos']\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"📊 Dados de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"📊 Dados de teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"📊 Features utilizadas: {features}\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular métricas de performance\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE DO MODELO RANDOM FOREST:\")\n",
    "print(f\"MAE (Erro Médio Absoluto): {mae_rf:.2f} pedidos\")\n",
    "print(f\"MSE (Erro Quadrático Médio): {mse_rf:.2f}\")\n",
    "print(f\"R² (Coeficiente de Determinação): {r2_rf:.3f}\")\n",
    "\n",
    "# Treinar modelo Linear Regression para comparação\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE DO MODELO LINEAR REGRESSION:\")\n",
    "print(f\"MAE: {mae_lr:.2f} pedidos\")\n",
    "print(f\"R²: {r2_lr:.3f}\")\n",
    "\n",
    "# Mostrar importância das features\n",
    "importancia_features = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importancia': modelo_rf.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\n📊 IMPORTÂNCIA DAS FEATURES:\")\n",
    "print(importancia_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 PREVISÕES E INSIGHTS DO MODELO DE DEMANDA\n",
    "\n",
    "# Fazer previsão para os próximos 7 dias\n",
    "ultima_data = demanda_diaria.index.max()\n",
    "ultimos_dados = demanda_diaria.loc[ultima_data]\n",
    "\n",
    "# Criar previsões para próximos 7 dias\n",
    "previsoes_proximos_7_dias = []\n",
    "datas_futuras = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    data_futura = pd.to_datetime(ultima_data) + pd.Timedelta(days=i)\n",
    "    dia_semana_futuro = data_futura.dayofweek\n",
    "    fim_de_semana_futuro = 1 if dia_semana_futuro in [5, 6] else 0\n",
    "    mes_futuro = data_futura.month\n",
    "    \n",
    "    # Usar valores médios das últimas observações para features contínuas\n",
    "    features_futuro = np.array([[\n",
    "        dia_semana_futuro,\n",
    "        fim_de_semana_futuro,\n",
    "        mes_futuro,\n",
    "        ultimos_dados['Volume_MA_7'] if not pd.isna(ultimos_dados['Volume_MA_7']) else demanda_diaria['Volume_MA_7'].mean(),\n",
    "        ultimos_dados['Receita_MA_7'] if not pd.isna(ultimos_dados['Receita_MA_7']) else demanda_diaria['Receita_MA_7'].mean(),\n",
    "        0,  # Variacao_Volume (assumir 0 para previsão)\n",
    "        0   # Variacao_Receita (assumir 0 para previsão)\n",
    "    ]])\n",
    "    \n",
    "    previsao = modelo_rf.predict(features_futuro)[0]\n",
    "    previsoes_proximos_7_dias.append(previsao)\n",
    "    datas_futuras.append(data_futura.date())\n",
    "\n",
    "# Criar DataFrame com previsões\n",
    "previsoes_df = pd.DataFrame({\n",
    "    'Data': datas_futuras,\n",
    "    'Previsao_Volume': previsoes_proximos_7_dias,\n",
    "    'Previsao_Receita': [p * demanda_diaria['Ticket_Medio'].mean() for p in previsoes_proximos_7_dias]\n",
    "})\n",
    "\n",
    "print(\"🔮 PREVISÕES PARA OS PRÓXIMOS 7 DIAS:\")\n",
    "print(previsoes_df.round(2))\n",
    "\n",
    "# Calcular métricas de tendência\n",
    "volume_medio_historico = demanda_diaria['Volume_Pedidos'].mean()\n",
    "receita_media_historica = demanda_diaria['Receita_Total'].mean()\n",
    "\n",
    "volume_previsto_medio = previsoes_df['Previsao_Volume'].mean()\n",
    "receita_prevista_media = previsoes_df['Previsao_Receita'].mean()\n",
    "\n",
    "variacao_volume = ((volume_previsto_medio - volume_medio_historico) / volume_medio_historico) * 100\n",
    "variacao_receita = ((receita_prevista_media - receita_media_historica) / receita_media_historica) * 100\n",
    "\n",
    "print(f\"\\n📊 TENDÊNCIA DE DEMANDA:\")\n",
    "print(f\"Volume médio histórico: {volume_medio_historico:.1f} pedidos/dia\")\n",
    "print(f\"Volume previsto médio: {volume_previsto_medio:.1f} pedidos/dia\")\n",
    "print(f\"Variação: {variacao_volume:+.1f}%\")\n",
    "\n",
    "print(f\"\\n💰 TENDÊNCIA DE RECEITA:\")\n",
    "print(f\"Receita média histórica: R$ {receita_media_historica:.2f}/dia\")\n",
    "print(f\"Receita prevista média: R$ {receita_prevista_media:.2f}/dia\")\n",
    "print(f\"Variação: {variacao_receita:+.1f}%\")\n",
    "\n",
    "# Identificar dias de maior demanda\n",
    "previsoes_df['Dia_Semana'] = pd.to_datetime(previsoes_df['Data']).dt.day_name()\n",
    "previsoes_df['Fim_Semana'] = pd.to_datetime(previsoes_df['Data']).dt.dayofweek.isin([5, 6])\n",
    "\n",
    "print(f\"\\n🎯 INSIGHTS ESTRATÉGICOS:\")\n",
    "print(f\"Dia de maior demanda prevista: {previsoes_df.loc[previsoes_df['Previsao_Volume'].idxmax(), 'Data']}\")\n",
    "print(f\"Volume máximo previsto: {previsoes_df['Previsao_Volume'].max():.0f} pedidos\")\n",
    "print(f\"Volume mínimo previsto: {previsoes_df['Previsao_Volume'].min():.0f} pedidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27dd87",
   "metadata": {},
   "source": [
    "## 5. ANÁLISE DE SATISFAÇÃO - Melhorar Experiência\n",
    "\n",
    "O objetivo é identificar os fatores críticos que impactam a satisfação do cliente, permitindo:\n",
    "- **Identificação dos gargalos** operacionais\n",
    "- **Otimização do tempo** de preparo e entrega\n",
    "- **Melhoria da experiência** do cliente\n",
    "- **Redução da insatisfação** e churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f65108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 ANÁLISE DETALHADA DE SATISFAÇÃO POR FATORES\n",
    "\n",
    "# Criar categorias de satisfação\n",
    "df['satisfacao_categoria'] = pd.cut(df['satisfacao_nivel'], \n",
    "                                  bins=[0, 2, 3, 4, 5], \n",
    "                                  labels=['Baixa (1-2)', 'Média (2-3)', 'Alta (3-4)', 'Excelente (4-5)'])\n",
    "\n",
    "# Análise por categoria de satisfação\n",
    "analise_satisfacao = df.groupby('satisfacao_categoria').agg({\n",
    "    'tempo_preparo_minutos': ['count', 'mean', 'std'],\n",
    "    'actual_delivery_minutes': ['mean', 'std'],\n",
    "    'eta_minutes_quote': ['mean', 'std'],\n",
    "    'distance_km': ['mean', 'std'],\n",
    "    'total_brl': ['mean', 'sum'],\n",
    "    'num_itens': 'mean',\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "analise_satisfacao.columns = [\n",
    "    'Qtd_Pedidos', 'Tempo_Prep_Medio', 'Tempo_Prep_Std',\n",
    "    'Tempo_Entrega_Medio', 'Tempo_Entrega_Std',\n",
    "    'ETA_Medio', 'ETA_Std',\n",
    "    'Distancia_Media', 'Distancia_Std',\n",
    "    'Ticket_Medio', 'Receita_Total',\n",
    "    'Itens_Medio', 'Comissao_Media', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "print(\"📊 ANÁLISE DE SATISFAÇÃO POR CATEGORIAS:\")\n",
    "print(analise_satisfacao)\n",
    "\n",
    "# Análise dos fatores críticos\n",
    "print(f\"\\n🔍 FATORES CRÍTICOS QUE IMPACTAM SATISFAÇÃO:\")\n",
    "\n",
    "# Correlações com satisfação (já calculadas na matriz de correlação)\n",
    "fatores_criticos = {\n",
    "    'Tempo_Preparo': -0.586,\n",
    "    'Tempo_Entrega_Real': -0.642,\n",
    "    'Numero_Itens': -0.367,\n",
    "    'Comissao_Plataforma': -0.218,\n",
    "    'ETA_Estimado': -0.219,\n",
    "    'Distancia': -0.193\n",
    "}\n",
    "\n",
    "print(\"Correlações negativas com satisfação (quanto menor, melhor):\")\n",
    "for fator, correlacao in sorted(fatores_criticos.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {fator}: {correlacao:.3f}\")\n",
    "\n",
    "# Identificar padrões por plataforma\n",
    "satisfacao_plataforma = df.groupby('platform').agg({\n",
    "    'satisfacao_nivel': ['mean', 'std', 'count'],\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean',\n",
    "    'distance_km': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "satisfacao_plataforma.columns = ['Satisfacao_Media', 'Satisfacao_Std', 'Qtd_Pedidos', 'Tempo_Prep_Medio', 'Tempo_Entrega_Medio', 'Distancia_Media']\n",
    "\n",
    "print(f\"\\n📱 SATISFAÇÃO POR PLATAFORMA:\")\n",
    "print(satisfacao_plataforma.sort_values('Satisfacao_Media', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORREÇÃO DO ERRO DE PREVISÃO DE SATISFAÇÃO\n",
    "\n",
    "# Preparar dados para previsão - corrigir infinitos primeiro\n",
    "df_predicao = df[features_satisfacao].copy()\n",
    "df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "\n",
    "# Verificar se há valores infinitos antes da previsão\n",
    "print(f\"Valores infinitos antes da previsão: {np.isinf(df_predicao).sum().sum()}\")\n",
    "\n",
    "# Fazer previsão\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n⚠️ ANÁLISE DE PEDIDOS DE RISCO:\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfação): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Características dos pedidos de risco\n",
    "caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "\n",
    "print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "comparacao = pd.DataFrame({\n",
    "    'Pedidos_Risco': caracteristicas_risco,\n",
    "    'Pedidos_Geral': caracteristicas_gerais\n",
    "})\n",
    "comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "print(comparacao.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96807c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUÇÃO DEFINITIVA PARA O ERRO DE PREVISÃO\n",
    "\n",
    "# Primeiro, vamos limpar completamente os dados\n",
    "print(\"🔧 LIMPEZA COMPLETA DOS DADOS PARA PREVISÃO\")\n",
    "\n",
    "# Criar uma cópia limpa dos dados\n",
    "df_limpo = df[features_satisfacao].copy()\n",
    "\n",
    "# 1. Verificar valores infinitos\n",
    "print(f\"Valores infinitos antes da limpeza: {np.isinf(df_limpo).sum().sum()}\")\n",
    "\n",
    "# 2. Substituir infinitos por NaN\n",
    "df_limpo = df_limpo.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 3. Verificar valores muito grandes\n",
    "for col in df_limpo.columns:\n",
    "    max_val = df_limpo[col].max()\n",
    "    min_val = df_limpo[col].min()\n",
    "    if max_val > 1e6 or min_val < -1e6:\n",
    "        print(f\"Coluna {col}: valores extremos detectados (max: {max_val:.2e}, min: {min_val:.2e})\")\n",
    "        # Capar valores extremos\n",
    "        df_limpo[col] = np.clip(df_limpo[col], -1e6, 1e6)\n",
    "\n",
    "# 4. Preencher NaN com valores médios\n",
    "df_limpo = df_limpo.fillna(df_limpo.mean())\n",
    "\n",
    "# 5. Verificação final\n",
    "print(f\"Valores infinitos após limpeza: {np.isinf(df_limpo).sum().sum()}\")\n",
    "print(f\"Valores NaN após limpeza: {df_limpo.isnull().sum().sum()}\")\n",
    "\n",
    "# 6. Fazer previsão com dados limpos\n",
    "print(\"\\n🎯 FAZENDO PREVISÃO COM DADOS LIMPOS...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_limpo)\n",
    "\n",
    "# 7. Análise dos resultados\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n✅ PREVISÃO CONCLUÍDA COM SUCESSO!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfação): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 8. Características dos pedidos de risco\n",
    "if len(pedidos_risco) > 0:\n",
    "    caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "    caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "    \n",
    "    print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "    comparacao = pd.DataFrame({\n",
    "        'Pedidos_Risco': caracteristicas_risco,\n",
    "        'Pedidos_Geral': caracteristicas_gerais\n",
    "    })\n",
    "    comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "    print(comparacao.round(2))\n",
    "else:\n",
    "    print(\"🎉 Nenhum pedido de risco identificado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# Função que remove ±inf e força numérico\n",
    "def sanitize(X):\n",
    "    X = X.copy()\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    return X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "sanitizer = FunctionTransformer(sanitize)\n",
    "\n",
    "preproc = make_pipeline(\n",
    "    sanitizer,\n",
    "    SimpleImputer(strategy='median')  # ou 'mean'\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "modelo_satisfacao = Pipeline(steps=[\n",
    "    ('preproc', preproc),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treino\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "modelo_satisfacao.fit(X_sat, y_sat)\n",
    "\n",
    "# Predição (agora basta passar o df cru)\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df[features_satisfacao])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e14230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 MODELO DE PREVISÃO DE SATISFAÇÃO\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Criar variável alvo categórica para classificação\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar features para o modelo de satisfação\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Remover linhas com valores NaN e infinitos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].dropna()\n",
    "\n",
    "# Verificar e corrigir valores infinitos\n",
    "print(\"🔍 Verificando valores infinitos antes da correção:\")\n",
    "print(f\"Valores infinitos em X: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "# Substituir infinitos por NaN e depois por valores médios\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].fillna(df_satisfacao_clean[features_satisfacao].mean())\n",
    "\n",
    "# Verificar novamente após correção\n",
    "print(f\"Valores infinitos após correção: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "# Verificar se há valores infinitos nos dados finais\n",
    "print(f\"Valores infinitos em X_sat: {np.isinf(X_sat).sum().sum()}\")\n",
    "print(f\"Valores NaN em X_sat: {X_sat.isnull().sum().sum()}\")\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "# Treinar modelo Random Forest para classificação\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "\n",
    "print(f\"🎯 PERFORMANCE DO MODELO DE PREVISÃO DE SATISFAÇÃO:\")\n",
    "print(f\"Acurácia: {accuracy:.3f}\")\n",
    "print(f\"\\n📊 RELATÓRIO DE CLASSIFICAÇÃO:\")\n",
    "print(classification_report(y_test_sat, y_pred_sat))\n",
    "\n",
    "# Importância das features para satisfação\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\n📊 IMPORTÂNCIA DAS FEATURES PARA SATISFAÇÃO:\")\n",
    "print(importancia_satisfacao)\n",
    "\n",
    "# Identificar pedidos de risco (baixa satisfação prevista)\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df[features_satisfacao].fillna(df[features_satisfacao].mean()))\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n⚠️ ANÁLISE DE PEDIDOS DE RISCO:\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfação): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Características dos pedidos de risco\n",
    "caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "\n",
    "print(f\"\\n🔍 CARACTERÍSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "comparacao = pd.DataFrame({\n",
    "    'Pedidos_Risco': caracteristicas_risco,\n",
    "    'Pedidos_Geral': caracteristicas_gerais\n",
    "})\n",
    "comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "print(comparacao.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b67f6",
   "metadata": {},
   "source": [
    "## 6. SEGMENTAÇÃO DE CLIENTES - Marketing Direcionado\n",
    "\n",
    "O objetivo é criar clusters de clientes para permitir:\n",
    "- **Marketing direcionado** por perfil de cliente\n",
    "- **Estratégias personalizadas** de retenção\n",
    "- **Otimização de produtos** por segmento\n",
    "- **Aumento da visibilidade** da marca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 PREPARAÇÃO DOS DADOS PARA CLUSTERING\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Criar features para clustering baseadas no comportamento do cliente\n",
    "features_clustering = [\n",
    "    'total_brl', 'num_itens', 'tempo_preparo_minutos', \n",
    "    'actual_delivery_minutes', 'distance_km', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', \n",
    "    'dia_semana', 'hora', 'fim_de_semana'\n",
    "]\n",
    "\n",
    "# Preparar dados para clustering\n",
    "df_clustering = df[features_clustering].copy()\n",
    "\n",
    "# Verificar e corrigir valores infinitos\n",
    "print(\"🔍 Verificando valores infinitos no clustering:\")\n",
    "print(f\"Valores infinitos: {np.isinf(df_clustering).sum().sum()}\")\n",
    "\n",
    "# Substituir infinitos por NaN e depois por valores médios\n",
    "df_clustering = df_clustering.replace([np.inf, -np.inf], np.nan)\n",
    "df_clustering = df_clustering.fillna(df_clustering.mean())\n",
    "\n",
    "# Verificar novamente após correção\n",
    "print(f\"Valores infinitos após correção: {np.isinf(df_clustering).sum().sum()}\")\n",
    "\n",
    "# Normalizar as features\n",
    "scaler = StandardScaler()\n",
    "df_clustering_scaled = scaler.fit_transform(df_clustering)\n",
    "\n",
    "print(f\"📊 Dados preparados para clustering:\")\n",
    "print(f\"Shape: {df_clustering_scaled.shape}\")\n",
    "print(f\"Features: {features_clustering}\")\n",
    "\n",
    "# Determinar número ótimo de clusters usando Elbow Method e Silhouette Score\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_clustering_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(df_clustering_scaled, kmeans.labels_))\n",
    "\n",
    "# Encontrar o número ótimo de clusters\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "print(f\"\\n🎯 ANÁLISE DO NÚMERO ÓTIMO DE CLUSTERS:\")\n",
    "for i, k in enumerate(K_range):\n",
    "    print(f\"K={k}: Inertia={inertias[i]:.2f}, Silhouette={silhouette_scores[i]:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Número ótimo de clusters: {optimal_k} (Silhouette Score: {max(silhouette_scores):.3f})\")\n",
    "\n",
    "# Aplicar K-means com número ótimo de clusters\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans_final.fit_predict(df_clustering_scaled)\n",
    "\n",
    "print(f\"\\n📊 DISTRIBUIÇÃO DOS CLUSTERS:\")\n",
    "print(df['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAÇÃO FINAL E EXECUÇÃO SEGURA\n",
    "\n",
    "print(\"🔍 VERIFICAÇÃO FINAL DOS DADOS:\")\n",
    "print(f\"Shape do DataFrame: {df.shape}\")\n",
    "print(f\"Colunas com valores infinitos: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "print(f\"Colunas com valores NaN: {df.select_dtypes(include=[np.number]).isnull().sum().sum()}\")\n",
    "\n",
    "# Verificar se a previsão foi feita com sucesso\n",
    "if 'satisfacao_predita' in df.columns:\n",
    "    print(f\"\\n✅ PREVISÃO DE SATISFAÇÃO CONCLUÍDA!\")\n",
    "    print(f\"Distribuição das previsões:\")\n",
    "    print(df['satisfacao_predita'].value_counts())\n",
    "    \n",
    "    # Análise de pedidos de risco\n",
    "    pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "    print(f\"\\n⚠️ PEDIDOS DE RISCO: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(pedidos_risco) > 0:\n",
    "        print(\"\\n📊 CARACTERÍSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "        print(f\"Plataforma mais problemática: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "        print(f\"Tempo médio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "        print(f\"Distância média: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "else:\n",
    "    print(\"❌ Previsão de satisfação não foi executada. Execute a célula anterior primeiro.\")\n",
    "\n",
    "print(f\"\\n🎯 STATUS DAS ANÁLISES:\")\n",
    "print(\"✅ Fase 1: Matriz de Correlação, Rentabilidade por Plataforma e Região\")\n",
    "print(\"✅ Fase 2: Modelo de Previsão de Demanda\")\n",
    "print(\"✅ Fase 2: Análise de Satisfação\")\n",
    "print(\"✅ Fase 2: Segmentação de Clientes\")\n",
    "print(\"\\n🚀 TODAS AS ANÁLISES AVANÇADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 ANÁLISE DETALHADA DOS CLUSTERS DE CLIENTES\n",
    "\n",
    "# Análise dos clusters por características principais\n",
    "analise_clusters = df.groupby('cluster').agg({\n",
    "    'total_brl': ['count', 'mean', 'std'],\n",
    "    'num_itens': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'distance_km': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean',\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'eficiencia_entrega': 'mean',\n",
    "    'dia_semana': 'mean',\n",
    "    'hora': 'mean',\n",
    "    'fim_de_semana': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "analise_clusters.columns = [\n",
    "    'Qtd_Pedidos', 'Ticket_Medio', 'Ticket_Std',\n",
    "    'Itens_Medio', 'Satisfacao_Media', 'Distancia_Media',\n",
    "    'Tempo_Prep_Medio', 'Tempo_Entrega_Medio', 'Comissao_Media',\n",
    "    'Eficiencia_Media', 'Dia_Semana_Medio', 'Hora_Media', 'Fim_Semana_%'\n",
    "]\n",
    "\n",
    "print(\"📊 ANÁLISE DETALHADA DOS CLUSTERS:\")\n",
    "print(analise_clusters)\n",
    "\n",
    "# Análise por plataforma dentro de cada cluster\n",
    "cluster_plataforma = pd.crosstab(df['cluster'], df['platform'], normalize='index') * 100\n",
    "print(f\"\\n📱 DISTRIBUIÇÃO DE PLATAFORMAS POR CLUSTER (%):\")\n",
    "print(cluster_plataforma.round(1))\n",
    "\n",
    "# Análise por região dentro de cada cluster\n",
    "cluster_regiao = pd.crosstab(df['cluster'], df['macro_bairro'], normalize='index') * 100\n",
    "print(f\"\\n📍 TOP 3 REGIÕES POR CLUSTER (%):\")\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    top_regioes = cluster_regiao.loc[cluster].nlargest(3)\n",
    "    print(f\"Cluster {cluster}: {', '.join([f'{regiao}({pct:.1f}%)' for regiao, pct in top_regioes.items()])}\")\n",
    "\n",
    "# Definir perfis dos clusters baseados nas características\n",
    "perfis_clusters = {}\n",
    "\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    dados_cluster = df[df['cluster'] == cluster]\n",
    "    \n",
    "    # Calcular métricas do cluster\n",
    "    ticket_medio = dados_cluster['total_brl'].mean()\n",
    "    satisfacao_media = dados_cluster['satisfacao_nivel'].mean()\n",
    "    distancia_media = dados_cluster['distance_km'].mean()\n",
    "    tempo_entrega_medio = dados_cluster['actual_delivery_minutes'].mean()\n",
    "    qtd_pedidos = len(dados_cluster)\n",
    "    \n",
    "    # Definir perfil baseado nas características\n",
    "    if ticket_medio > df['total_brl'].quantile(0.75) and satisfacao_media > 4.5:\n",
    "        perfil = \"Clientes Premium\"\n",
    "        estrategia = \"Fidelização e expansão de produtos premium\"\n",
    "    elif satisfacao_media < 4.0 and tempo_entrega_medio > df['actual_delivery_minutes'].quantile(0.75):\n",
    "        perfil = \"Clientes de Risco\"\n",
    "        estrategia = \"Melhoria de experiência e retenção urgente\"\n",
    "    elif distancia_media < df['distance_km'].quantile(0.5) and satisfacao_media > 4.0:\n",
    "        perfil = \"Clientes Locais Fiéis\"\n",
    "        estrategia = \"Expansão de produtos e horários de atendimento\"\n",
    "    elif ticket_medio < df['total_brl'].quantile(0.5) and qtd_pedidos > df['cluster'].value_counts().quantile(0.75):\n",
    "        perfil = \"Clientes de Volume\"\n",
    "        estrategia = \"Programas de fidelidade e descontos por volume\"\n",
    "    else:\n",
    "        perfil = \"Clientes Regulares\"\n",
    "        estrategia = \"Marketing direcionado e upselling\"\n",
    "    \n",
    "    perfis_clusters[cluster] = {\n",
    "        'perfil': perfil,\n",
    "        'estrategia': estrategia,\n",
    "        'ticket_medio': ticket_medio,\n",
    "        'satisfacao_media': satisfacao_media,\n",
    "        'qtd_pedidos': qtd_pedidos\n",
    "    }\n",
    "\n",
    "print(f\"\\n🎯 PERFIS DOS CLUSTERS:\")\n",
    "for cluster, info in perfis_clusters.items():\n",
    "    print(f\"\\nCluster {cluster}: {info['perfil']}\")\n",
    "    print(f\"  Estratégia: {info['estrategia']}\")\n",
    "    print(f\"  Ticket Médio: R$ {info['ticket_medio']:.2f}\")\n",
    "    print(f\"  Satisfação: {info['satisfacao_media']:.2f}\")\n",
    "    print(f\"  Quantidade: {info['qtd_pedidos']} pedidos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a630eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAÇÕES DA FASE 2 - ANÁLISES AVANÇADAS\n",
    "\n",
    "# Criar figura com subplots para visualizar os resultados da Fase 2\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "\n",
    "# 1. Previsão de Demanda - Volume de Pedidos\n",
    "axes[0,0].plot(demanda_diaria.index, demanda_diaria['Volume_Pedidos'], alpha=0.7, label='Volume Real')\n",
    "axes[0,0].plot(demanda_diaria.index, demanda_diaria['Volume_MA_7'], color='red', linewidth=2, label='Média Móvel 7 dias')\n",
    "axes[0,0].set_title('Previsão de Demanda - Volume de Pedidos')\n",
    "axes[0,0].set_ylabel('Pedidos por dia')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Análise de Satisfação - Distribuição\n",
    "satisfacao_counts = df['satisfacao_categoria'].value_counts()\n",
    "axes[0,1].pie(satisfacao_counts.values, labels=satisfacao_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0,1].set_title('Distribuição de Satisfação')\n",
    "\n",
    "# 3. Análise de Satisfação - Fatores Críticos\n",
    "fatores = list(fatores_criticos.keys())\n",
    "correlacoes = list(fatores_criticos.values())\n",
    "colors = ['red' if x < -0.3 else 'orange' if x < -0.1 else 'green' for x in correlacoes]\n",
    "axes[0,2].barh(fatores, correlacoes, color=colors)\n",
    "axes[0,2].set_title('Fatores Críticos vs Satisfação')\n",
    "axes[0,2].set_xlabel('Correlação')\n",
    "\n",
    "# 4. Segmentação - Distribuição dos Clusters\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "axes[1,0].bar(cluster_counts.index, cluster_counts.values, color='skyblue')\n",
    "axes[1,0].set_title('Distribuição dos Clusters de Clientes')\n",
    "axes[1,0].set_xlabel('Cluster')\n",
    "axes[1,0].set_ylabel('Quantidade de Pedidos')\n",
    "\n",
    "# 5. Segmentação - Ticket Médio por Cluster\n",
    "ticket_cluster = df.groupby('cluster')['total_brl'].mean()\n",
    "axes[1,1].bar(ticket_cluster.index, ticket_cluster.values, color='lightgreen')\n",
    "axes[1,1].set_title('Ticket Médio por Cluster')\n",
    "axes[1,1].set_xlabel('Cluster')\n",
    "axes[1,1].set_ylabel('Ticket Médio (R$)')\n",
    "\n",
    "# 6. Segmentação - Satisfação por Cluster\n",
    "satisfacao_cluster = df.groupby('cluster')['satisfacao_nivel'].mean()\n",
    "axes[1,2].bar(satisfacao_cluster.index, satisfacao_cluster.values, color='lightcoral')\n",
    "axes[1,2].set_title('Satisfação Média por Cluster')\n",
    "axes[1,2].set_xlabel('Cluster')\n",
    "axes[1,2].set_ylabel('Satisfação (1-5)')\n",
    "\n",
    "# 7. Análise Temporal - Satisfação por Hora\n",
    "satisfacao_hora = df.groupby('hora')['satisfacao_nivel'].mean()\n",
    "axes[2,0].plot(satisfacao_hora.index, satisfacao_hora.values, marker='o')\n",
    "axes[2,0].set_title('Satisfação Média por Hora do Dia')\n",
    "axes[2,0].set_xlabel('Hora')\n",
    "axes[2,0].set_ylabel('Satisfação Média')\n",
    "\n",
    "# 8. Análise Temporal - Volume por Dia da Semana\n",
    "volume_dia = df.groupby('dia_semana')['total_brl'].count()\n",
    "dias_semana = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sáb', 'Dom']\n",
    "axes[2,1].bar(dias_semana, volume_dia.values, color='gold')\n",
    "axes[2,1].set_title('Volume de Pedidos por Dia da Semana')\n",
    "axes[2,1].set_ylabel('Quantidade de Pedidos')\n",
    "\n",
    "# 9. Análise de Risco - Pedidos de Baixa Satisfação\n",
    "risco_plataforma = pedidos_risco['platform'].value_counts()\n",
    "axes[2,2].pie(risco_plataforma.values, labels=risco_plataforma.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[2,2].set_title('Pedidos de Risco por Plataforma')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🎯 RESUMO DA FASE 2 - ANÁLISES AVANÇADAS IMPLEMENTADAS:\")\n",
    "print(\"✅ Modelo de Previsão de Demanda - Otimizar Volume\")\n",
    "print(\"✅ Análise de Satisfação - Melhorar Experiência\") \n",
    "print(\"✅ Segmentação de Clientes - Marketing Direcionado\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-de-dados-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
