{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d07a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "303e26ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_bairro</th>\n",
       "      <th>nome_cliente</th>\n",
       "      <th>bairro_destino</th>\n",
       "      <th>order_datetime</th>\n",
       "      <th>platform</th>\n",
       "      <th>order_mode</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>tempo_preparo_minutos</th>\n",
       "      <th>status</th>\n",
       "      <th>eta_minutes_quote</th>\n",
       "      <th>actual_delivery_minutes</th>\n",
       "      <th>total_brl</th>\n",
       "      <th>classe_pedido</th>\n",
       "      <th>platform_commission_pct</th>\n",
       "      <th>num_itens</th>\n",
       "      <th>satisfacao_nivel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outros</td>\n",
       "      <td>J√∫lia Ramos</td>\n",
       "      <td>Bela Vista</td>\n",
       "      <td>2024-01-01 15:08:00</td>\n",
       "      <td>rappi</td>\n",
       "      <td>delivery</td>\n",
       "      <td>6.916192</td>\n",
       "      <td>34</td>\n",
       "      <td>delivered</td>\n",
       "      <td>50</td>\n",
       "      <td>62.4</td>\n",
       "      <td>288.01</td>\n",
       "      <td>familia</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santo Amaro</td>\n",
       "      <td>Gustavo R. Rezende</td>\n",
       "      <td>Santo Amaro</td>\n",
       "      <td>2024-01-02 07:49:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>5.753085</td>\n",
       "      <td>16</td>\n",
       "      <td>delivered</td>\n",
       "      <td>45</td>\n",
       "      <td>35.6</td>\n",
       "      <td>125.02</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jardins</td>\n",
       "      <td>Valentina Y. Oliveira</td>\n",
       "      <td>Jardins</td>\n",
       "      <td>2024-01-02 10:14:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>4.545672</td>\n",
       "      <td>15</td>\n",
       "      <td>delivered</td>\n",
       "      <td>43</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.76</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vila Ol√≠mpia</td>\n",
       "      <td>Mariana Moreira</td>\n",
       "      <td>Vila Ol√≠mpia</td>\n",
       "      <td>2024-01-02 10:58:00</td>\n",
       "      <td>site_proprio</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.059679</td>\n",
       "      <td>6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>19</td>\n",
       "      <td>14.4</td>\n",
       "      <td>45.16</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moema</td>\n",
       "      <td>Daniel Rocha</td>\n",
       "      <td>Ibirapuera</td>\n",
       "      <td>2024-01-02 12:56:00</td>\n",
       "      <td>site_proprio</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.102063</td>\n",
       "      <td>25</td>\n",
       "      <td>delivered</td>\n",
       "      <td>28</td>\n",
       "      <td>26.6</td>\n",
       "      <td>123.12</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Moema</td>\n",
       "      <td>Nat√°lia G. Souza</td>\n",
       "      <td>Ibirapuera</td>\n",
       "      <td>2024-12-31 17:17:00</td>\n",
       "      <td>rappi</td>\n",
       "      <td>delivery</td>\n",
       "      <td>3.231895</td>\n",
       "      <td>17</td>\n",
       "      <td>delivered</td>\n",
       "      <td>37</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Morumbi</td>\n",
       "      <td>Yasmin N. Ribeiro</td>\n",
       "      <td>Morumbi</td>\n",
       "      <td>2024-12-31 19:33:00</td>\n",
       "      <td>whatsapp</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.218583</td>\n",
       "      <td>6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>18</td>\n",
       "      <td>10.7</td>\n",
       "      <td>75.58</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Pinheiros</td>\n",
       "      <td>Yuri Castro</td>\n",
       "      <td>Pinheiros</td>\n",
       "      <td>2024-12-31 20:12:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>6.389462</td>\n",
       "      <td>28</td>\n",
       "      <td>canceled</td>\n",
       "      <td>47</td>\n",
       "      <td>67.1</td>\n",
       "      <td>145.75</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Itaim</td>\n",
       "      <td>Henrique J. Ferreira</td>\n",
       "      <td>Itaim Bibi</td>\n",
       "      <td>2024-12-31 21:14:00</td>\n",
       "      <td>ifood</td>\n",
       "      <td>delivery</td>\n",
       "      <td>4.148569</td>\n",
       "      <td>14</td>\n",
       "      <td>delivered</td>\n",
       "      <td>40</td>\n",
       "      <td>32.9</td>\n",
       "      <td>61.36</td>\n",
       "      <td>prato_unico</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Itaim</td>\n",
       "      <td>Helena Duarte</td>\n",
       "      <td>Itaim Bibi</td>\n",
       "      <td>2024-12-31 21:27:00</td>\n",
       "      <td>whatsapp</td>\n",
       "      <td>retirada</td>\n",
       "      <td>0.286058</td>\n",
       "      <td>23</td>\n",
       "      <td>delivered</td>\n",
       "      <td>29</td>\n",
       "      <td>21.8</td>\n",
       "      <td>87.40</td>\n",
       "      <td>combo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      macro_bairro           nome_cliente bairro_destino      order_datetime  \\\n",
       "0           Outros            J√∫lia Ramos     Bela Vista 2024-01-01 15:08:00   \n",
       "1      Santo Amaro     Gustavo R. Rezende    Santo Amaro 2024-01-02 07:49:00   \n",
       "2          Jardins  Valentina Y. Oliveira        Jardins 2024-01-02 10:14:00   \n",
       "3     Vila Ol√≠mpia        Mariana Moreira   Vila Ol√≠mpia 2024-01-02 10:58:00   \n",
       "4            Moema           Daniel Rocha     Ibirapuera 2024-01-02 12:56:00   \n",
       "...            ...                    ...            ...                 ...   \n",
       "4995         Moema       Nat√°lia G. Souza     Ibirapuera 2024-12-31 17:17:00   \n",
       "4996       Morumbi      Yasmin N. Ribeiro        Morumbi 2024-12-31 19:33:00   \n",
       "4997     Pinheiros            Yuri Castro      Pinheiros 2024-12-31 20:12:00   \n",
       "4998         Itaim   Henrique J. Ferreira     Itaim Bibi 2024-12-31 21:14:00   \n",
       "4999         Itaim          Helena Duarte     Itaim Bibi 2024-12-31 21:27:00   \n",
       "\n",
       "          platform order_mode  distance_km  tempo_preparo_minutos     status  \\\n",
       "0            rappi   delivery     6.916192                     34  delivered   \n",
       "1            ifood   delivery     5.753085                     16  delivered   \n",
       "2            ifood   delivery     4.545672                     15  delivered   \n",
       "3     site_proprio   retirada     0.059679                      6  delivered   \n",
       "4     site_proprio   retirada     0.102063                     25  delivered   \n",
       "...            ...        ...          ...                    ...        ...   \n",
       "4995         rappi   delivery     3.231895                     17  delivered   \n",
       "4996      whatsapp   retirada     0.218583                      6  delivered   \n",
       "4997         ifood   delivery     6.389462                     28   canceled   \n",
       "4998         ifood   delivery     4.148569                     14  delivered   \n",
       "4999      whatsapp   retirada     0.286058                     23  delivered   \n",
       "\n",
       "      eta_minutes_quote  actual_delivery_minutes  total_brl classe_pedido  \\\n",
       "0                    50                     62.4     288.01       familia   \n",
       "1                    45                     35.6     125.02         combo   \n",
       "2                    43                     34.5     110.76         combo   \n",
       "3                    19                     14.4      45.16   prato_unico   \n",
       "4                    28                     26.6     123.12         combo   \n",
       "...                 ...                      ...        ...           ...   \n",
       "4995                 37                     29.0      56.43   prato_unico   \n",
       "4996                 18                     10.7      75.58   prato_unico   \n",
       "4997                 47                     67.1     145.75         combo   \n",
       "4998                 40                     32.9      61.36   prato_unico   \n",
       "4999                 29                     21.8      87.40         combo   \n",
       "\n",
       "      platform_commission_pct  num_itens  satisfacao_nivel  \n",
       "0                        0.16          8                 3  \n",
       "1                        0.16          3                 5  \n",
       "2                        0.12          4                 5  \n",
       "3                        0.00          1                 5  \n",
       "4                        0.00          3                 5  \n",
       "...                       ...        ...               ...  \n",
       "4995                     0.16          3                 5  \n",
       "4996                     0.00          2                 5  \n",
       "4997                     0.16          4                 2  \n",
       "4998                     0.16          1                 5  \n",
       "4999                     0.00          1                 5  \n",
       "\n",
       "[5000 rows x 16 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Base_Kaiserhaus.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dea570",
   "metadata": {},
   "source": [
    "# üìä AN√ÅLISE EXPLORAT√ìRIA COMPLETA\n",
    "\n",
    "## 1. Vis√£o Geral dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4406d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa√ß√µes gerais sobre o dataset\n",
    "print(\"üìä INFORMA√á√ïES GERAIS DO DATASET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìà Shape: {df.shape}\")\n",
    "print(f\"üìà Mem√≥ria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"üìà Per√≠odo dos dados: {df['order_datetime'].min()} at√© {df['order_datetime'].max()}\")\n",
    "\n",
    "print(f\"\\nüìã TIPOS DE DADOS:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\nüìã VALORES NULOS:\")\n",
    "null_counts = df.isnull().sum()\n",
    "if null_counts.sum() > 0:\n",
    "    for col, nulos in null_counts[null_counts > 0].items():\n",
    "        print(f\"  ‚Ä¢ {col}: {nulos} valores nulos ({nulos/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Nenhum valor nulo encontrado!\")\n",
    "\n",
    "print(f\"\\nüìã VALORES DUPLICADOS:\")\n",
    "print(f\"Total de duplicatas: {df.duplicated().sum()}\")\n",
    "\n",
    "# Informa√ß√µes detalhadas\n",
    "print(f\"\\nüìã INFORMA√á√ïES DETALHADAS:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467146f1",
   "metadata": {},
   "source": [
    "## 2. An√°lise das Colunas Categ√≥ricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9976632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise das colunas categ√≥ricas\n",
    "print(\"üìä AN√ÅLISE DAS COLUNAS CATEG√ìRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificar colunas categ√≥ricas\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"Colunas categ√≥ricas encontradas: {list(categorical_cols)}\")\n",
    "\n",
    "# An√°lise de cada coluna categ√≥rica\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nüîç {col.upper()}:\")\n",
    "    print(f\"  ‚Ä¢ Valores √∫nicos: {df[col].nunique()}\")\n",
    "    print(f\"  ‚Ä¢ Valores nulos: {df[col].isnull().sum()}\")\n",
    "    print(f\"  ‚Ä¢ Top 5 valores:\")\n",
    "    print(df[col].value_counts().head())\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df[col].value_counts().head(10).plot(kind='bar')\n",
    "    plt.title(f'Distribui√ß√£o de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequ√™ncia')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e584e6",
   "metadata": {},
   "source": [
    "## 3. An√°lise das Colunas Num√©ricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e754541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise das colunas num√©ricas\n",
    "print(\"üìä AN√ÅLISE DAS COLUNAS NUM√âRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificar colunas num√©ricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f\"Colunas num√©ricas encontradas: {list(numeric_cols)}\")\n",
    "\n",
    "# Estat√≠sticas descritivas\n",
    "print(f\"\\nüìà ESTAT√çSTICAS DESCRITIVAS:\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# An√°lise de cada coluna num√©rica\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\nüîç {col.upper()}:\")\n",
    "    print(f\"  ‚Ä¢ M√©dia: {df[col].mean():.2f}\")\n",
    "    print(f\"  ‚Ä¢ Mediana: {df[col].median():.2f}\")\n",
    "    print(f\"  ‚Ä¢ Desvio padr√£o: {df[col].std():.2f}\")\n",
    "    print(f\"  ‚Ä¢ M√≠nimo: {df[col].min():.2f}\")\n",
    "    print(f\"  ‚Ä¢ M√°ximo: {df[col].max():.2f}\")\n",
    "    print(f\"  ‚Ä¢ Valores nulos: {df[col].isnull().sum()}\")\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Histograma\n",
    "    df[col].hist(bins=30, ax=axes[0], edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title(f'Distribui√ß√£o de {col}')\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel('Frequ√™ncia')\n",
    "    \n",
    "    # Boxplot\n",
    "    df[col].plot(kind='box', ax=axes[1])\n",
    "    axes[1].set_title(f'Boxplot de {col}')\n",
    "    axes[1].set_ylabel(col)\n",
    "    \n",
    "    # Q-Q plot para verificar normalidade\n",
    "    from scipy import stats\n",
    "    stats.probplot(df[col].dropna(), dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title(f'Q-Q Plot de {col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d17530",
   "metadata": {},
   "source": [
    "## 4. An√°lise Temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise temporal dos dados\n",
    "print(\"üìÖ AN√ÅLISE TEMPORAL\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Extrair componentes temporais\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia'] = df['order_datetime'].dt.day\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['nome_dia_semana'] = df['order_datetime'].dt.day_name()\n",
    "\n",
    "print(f\"üìä Per√≠odo dos dados: {df['order_datetime'].min()} at√© {df['order_datetime'].max()}\")\n",
    "print(f\"üìä Total de dias: {(df['order_datetime'].max() - df['order_datetime'].min()).days}\")\n",
    "\n",
    "# An√°lise por componentes temporais\n",
    "print(f\"\\nüìä PEDIDOS POR ANO:\")\n",
    "print(df['ano'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nüìä PEDIDOS POR M√äS:\")\n",
    "print(df['mes'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nüìä PEDIDOS POR DIA DA SEMANA:\")\n",
    "print(df['nome_dia_semana'].value_counts())\n",
    "\n",
    "print(f\"\\nüìä PEDIDOS POR HORA:\")\n",
    "print(df['hora'].value_counts().sort_index())\n",
    "\n",
    "# Visualiza√ß√µes temporais\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Pedidos por m√™s\n",
    "df['mes'].value_counts().sort_index().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Pedidos por M√™s')\n",
    "axes[0,0].set_xlabel('M√™s')\n",
    "axes[0,0].set_ylabel('N√∫mero de Pedidos')\n",
    "\n",
    "# Pedidos por dia da semana\n",
    "df['nome_dia_semana'].value_counts().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Pedidos por Dia da Semana')\n",
    "axes[0,1].set_xlabel('Dia da Semana')\n",
    "axes[0,1].set_ylabel('N√∫mero de Pedidos')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pedidos por hora\n",
    "df['hora'].value_counts().sort_index().plot(kind='line', ax=axes[1,0])\n",
    "axes[1,0].set_title('Pedidos por Hora do Dia')\n",
    "axes[1,0].set_xlabel('Hora')\n",
    "axes[1,0].set_ylabel('N√∫mero de Pedidos')\n",
    "\n",
    "# Distribui√ß√£o temporal\n",
    "df['order_datetime'].dt.date.value_counts().sort_index().plot(kind='line', ax=axes[1,1])\n",
    "axes[1,1].set_title('Pedidos ao Longo do Tempo')\n",
    "axes[1,1].set_xlabel('Data')\n",
    "axes[1,1].set_ylabel('N√∫mero de Pedidos')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870b184",
   "metadata": {},
   "source": [
    "## 5. An√°lise de Correla√ß√µes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de correla√ß√µes entre vari√°veis num√©ricas\n",
    "print(\"üîó AN√ÅLISE DE CORRELA√á√ïES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Selecionar apenas vari√°veis num√©ricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "print(\"Matriz de correla√ß√£o entre vari√°veis num√©ricas:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Heatmap de correla√ß√µes\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correla√ß√£o entre Vari√°veis Num√©ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lise das correla√ß√µes mais importantes\n",
    "print(f\"\\nüìä CORRELA√á√ïES MAIS IMPORTANTES:\")\n",
    "correlations = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "correlations = correlations[correlations < 1.0]  # Remover autocorrela√ß√µes\n",
    "print(correlations.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae15b81",
   "metadata": {},
   "source": [
    "## 6. Resumo da An√°lise Explorat√≥ria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo da An√°lise Explorat√≥ria\n",
    "print(\"üìã RESUMO DA AN√ÅLISE EXPLORAT√ìRIA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä DADOS GERAIS:\")\n",
    "print(f\"  ‚Ä¢ Total de registros: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Total de colunas: {len(df.columns)}\")\n",
    "print(f\"  ‚Ä¢ Per√≠odo dos dados: {df['order_datetime'].min().strftime('%d/%m/%Y')} a {df['order_datetime'].max().strftime('%d/%m/%Y')}\")\n",
    "\n",
    "print(f\"\\nüë• CLIENTES:\")\n",
    "print(f\"  ‚Ä¢ Clientes √∫nicos: {df['nome_cliente'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Pedidos por cliente (m√©dia): {len(df) / df['nome_cliente'].nunique():.1f}\")\n",
    "\n",
    "print(f\"\\nüèòÔ∏è LOCALIZA√á√ÉO:\")\n",
    "print(f\"  ‚Ä¢ Macro bairros √∫nicos: {df['macro_bairro'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Bairros √∫nicos: {df['bairro_destino'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Macro bairro mais frequente: {df['macro_bairro'].mode()[0]}\")\n",
    "\n",
    "print(f\"\\nüí∞ FINANCEIRO:\")\n",
    "print(f\"  ‚Ä¢ Ticket m√©dio: R$ {df['total_brl'].mean():.2f}\")\n",
    "print(f\"  ‚Ä¢ Ticket mediano: R$ {df['total_brl'].median():.2f}\")\n",
    "print(f\"  ‚Ä¢ Comiss√£o m√©dia: {df['platform_commission_pct'].mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è TEMPO:\")\n",
    "print(f\"  ‚Ä¢ Tempo m√©dio de preparo: {df['tempo_preparo_minutos'].mean():.1f} min\")\n",
    "print(f\"  ‚Ä¢ ETA m√©dio: {df['eta_minutes_quote'].mean():.1f} min\")\n",
    "print(f\"  ‚Ä¢ Tempo real m√©dio: {df['actual_delivery_minutes'].mean():.1f} min\")\n",
    "\n",
    "print(f\"\\nüì¶ PEDIDOS:\")\n",
    "print(f\"  ‚Ä¢ Itens m√©dios por pedido: {df['num_itens'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Dist√¢ncia m√©dia: {df['distance_km'].mean():.1f} km\")\n",
    "\n",
    "print(f\"\\nüòä SATISFA√á√ÉO:\")\n",
    "print(f\"  ‚Ä¢ Satisfa√ß√£o m√©dia: {df['satisfacao_nivel'].mean():.2f}/5\")\n",
    "print(f\"  ‚Ä¢ % de satisfa√ß√£o alta (4-5): {(df['satisfacao_nivel'] >= 4).mean()*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ % de satisfa√ß√£o baixa (1-2): {(df['satisfacao_nivel'] <= 2).mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nüîç QUALIDADE DOS DADOS:\")\n",
    "print(f\"  ‚Ä¢ Valores nulos: {df.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Colunas com valores nulos: {(df.isnull().sum() > 0).sum()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISE EXPLORAT√ìRIA CONCLU√çDA!\")\n",
    "print(f\"   Todas as {len(df.columns)} colunas foram analisadas com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9a87c",
   "metadata": {},
   "source": [
    "# ü§ñ MODELAGEM E PREDI√á√ÉO\n",
    "\n",
    "## 1. Prepara√ß√£o dos Dados para Modelagem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas de modelagem\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                            mean_absolute_error, mean_squared_error, r2_score, f1_score)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas de modelagem importadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799adc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara√ß√£o dos dados para modelagem\n",
    "print(\"üîß PREPARA√á√ÉO DOS DADOS PARA MODELAGEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Criar features derivadas necess√°rias\n",
    "print(\"üìä Criando features derivadas...\")\n",
    "\n",
    "# Features temporais\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['fim_semana'] = (df['dia_semana'] >= 5).astype(int)\n",
    "\n",
    "# Features de efici√™ncia\n",
    "df['atraso_minutos'] = df['actual_delivery_minutes'] - df['eta_minutes_quote']\n",
    "df['velocidade_media'] = np.where(\n",
    "    df['actual_delivery_minutes'] > 0,\n",
    "    df['distance_km'] / df['actual_delivery_minutes'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Features financeiras\n",
    "df['margem_brl'] = df['total_brl'] * (1 - df['platform_commission_pct'])\n",
    "df['ticket_medio_item'] = np.where(\n",
    "    df['num_itens'] > 0,\n",
    "    df['total_brl'] / df['num_itens'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Features de complexidade\n",
    "df['indice_complexidade'] = df['tempo_preparo_minutos'] * df['num_itens']\n",
    "\n",
    "# Features de dist√¢ncia\n",
    "df['zona_distancia'] = pd.cut(\n",
    "    df['distance_km'], \n",
    "    bins=[0, 3, 7, 10, float('inf')], \n",
    "    labels=['curta', 'media', 'longa', 'muito_longa'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Features de satisfa√ß√£o\n",
    "df['satisfacao_categoria'] = pd.cut(\n",
    "    df['satisfacao_nivel'], \n",
    "    bins=[0, 2, 3, 4, 5], \n",
    "    labels=['Baixa', 'M√©dia', 'Alta', 'Excelente']\n",
    ")\n",
    "df['satisfacao_alta'] = (df['satisfacao_nivel'] >= 4).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Features criadas! Shape final: {df.shape}\")\n",
    "\n",
    "# 2. Tratamento de valores nulos e infinitos\n",
    "print(\"\\nüßπ Tratando valores nulos e infinitos...\")\n",
    "\n",
    "# Substituir infinitos por NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Preencher valores nulos\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown')\n",
    "\n",
    "print(f\"‚úÖ Dados limpos! Valores nulos: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# 3. Definir vari√°veis alvo e features\n",
    "print(\"\\nüéØ Definindo vari√°veis alvo e features...\")\n",
    "\n",
    "# Vari√°veis alvo\n",
    "targets = {\n",
    "    'satisfacao_nivel': df['satisfacao_nivel'],\n",
    "    'atraso_minutos': df['atraso_minutos'],\n",
    "    'margem_brl': df['margem_brl']\n",
    "}\n",
    "\n",
    "# Features num√©ricas\n",
    "features_numericas = [\n",
    "    'tempo_preparo_minutos', 'distance_km', 'eta_minutes_quote',\n",
    "    'actual_delivery_minutes', 'total_brl', 'platform_commission_pct', \n",
    "    'num_itens', 'hora', 'dia_semana', 'atraso_minutos', 'velocidade_media',\n",
    "    'margem_brl', 'ticket_medio_item', 'indice_complexidade', 'fim_semana'\n",
    "]\n",
    "\n",
    "# Features categ√≥ricas\n",
    "features_categoricas = [\n",
    "    'macro_bairro', 'platform', 'order_mode', 'status', 'classe_pedido',\n",
    "    'zona_distancia', 'satisfacao_categoria'\n",
    "]\n",
    "\n",
    "# Features bin√°rias\n",
    "features_binarias = ['satisfacao_alta']\n",
    "\n",
    "print(f\"‚úÖ Features definidas:\")\n",
    "print(f\"  ‚Ä¢ Num√©ricas: {len(features_numericas)}\")\n",
    "print(f\"  ‚Ä¢ Categ√≥ricas: {len(features_categoricas)}\")\n",
    "print(f\"  ‚Ä¢ Bin√°rias: {len(features_binarias)}\")\n",
    "print(f\"  ‚Ä¢ Total: {len(features_numericas) + len(features_categoricas) + len(features_binarias)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdf231",
   "metadata": {},
   "source": [
    "## 2. Modelo 1: Previs√£o de Satisfa√ß√£o (Classifica√ß√£o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ea304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Previs√£o de Satisfa√ß√£o\n",
    "print(\"ü§ñ MODELO 1: PREVIS√ÉO DE SATISFA√á√ÉO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para satisfa√ß√£o\n",
    "features_satisfacao = features_numericas + features_categoricas\n",
    "X_sat = df[features_satisfacao].copy()\n",
    "y_sat = df['satisfacao_nivel'].copy()\n",
    "\n",
    "# Tratamento de dados categ√≥ricos\n",
    "le = LabelEncoder()\n",
    "for col in features_categoricas:\n",
    "    if col in X_sat.columns:\n",
    "        X_sat[col] = X_sat[col].astype(str)\n",
    "        X_sat[col] = le.fit_transform(X_sat[col])\n",
    "\n",
    "# Verificar se h√° valores nulos\n",
    "print(f\"Valores nulos em X_sat: {X_sat.isnull().sum().sum()}\")\n",
    "if X_sat.isnull().sum().sum() > 0:\n",
    "    X_sat = X_sat.fillna(X_sat.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "print(f\"üìä Dados de treino: {X_train_sat.shape[0]} amostras\")\n",
    "print(f\"üìä Dados de teste: {X_test_sat.shape[0]} amostras\")\n",
    "print(f\"üìä Features: {X_train_sat.shape[1]}\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\nüå≤ Treinando Random Forest...\")\n",
    "modelo_satisfacao = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Avaliar modelo\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "f1 = f1_score(y_test_sat, y_pred_sat, average='weighted')\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS DO MODELO DE SATISFA√á√ÉO:\")\n",
    "print(f\"  ‚Ä¢ Acur√°cia: {accuracy:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Valida√ß√£o cruzada\n",
    "print(\"\\nüîÑ Valida√ß√£o Cruzada (5 folds):\")\n",
    "cv_scores = cross_val_score(modelo_satisfacao, X_train_sat, y_train_sat, cv=5, scoring='accuracy')\n",
    "print(f\"  ‚Ä¢ Acur√°cia m√©dia: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Import√¢ncia das features\n",
    "print(\"\\nüìà TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_sat.columns,\n",
    "    'importance': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o\n",
    "print(\"\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
    "print(classification_report(y_test_sat, y_pred_sat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbc8dc",
   "metadata": {},
   "source": [
    "## 3. Modelo 2: Previs√£o de Atraso (Regress√£o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Previs√£o de Atraso\n",
    "print(\"ü§ñ MODELO 2: PREVIS√ÉO DE ATRASO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para atraso\n",
    "features_atraso = features_numericas + features_categoricas\n",
    "X_atraso = df[features_atraso].copy()\n",
    "y_atraso = df['atraso_minutos'].copy()\n",
    "\n",
    "# Tratamento de dados categ√≥ricos\n",
    "for col in features_categoricas:\n",
    "    if col in X_atraso.columns:\n",
    "        X_atraso[col] = X_atraso[col].astype(str)\n",
    "        X_atraso[col] = le.fit_transform(X_atraso[col])\n",
    "\n",
    "# Verificar se h√° valores nulos\n",
    "print(f\"Valores nulos em X_atraso: {X_atraso.isnull().sum().sum()}\")\n",
    "if X_atraso.isnull().sum().sum() > 0:\n",
    "    X_atraso = X_atraso.fillna(X_atraso.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_atraso, X_test_atraso, y_train_atraso, y_test_atraso = train_test_split(\n",
    "    X_atraso, y_atraso, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Dados de treino: {X_train_atraso.shape[0]} amostras\")\n",
    "print(f\"üìä Dados de teste: {X_test_atraso.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\nüå≤ Treinando Random Forest para atraso...\")\n",
    "modelo_atraso_rf = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_atraso_rf.fit(X_train_atraso, y_train_atraso)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_atraso_rf = modelo_atraso_rf.predict(X_test_atraso)\n",
    "\n",
    "# Avaliar modelo\n",
    "mae_rf = mean_absolute_error(y_test_atraso, y_pred_atraso_rf)\n",
    "mse_rf = mean_squared_error(y_test_atraso, y_pred_atraso_rf)\n",
    "r2_rf = r2_score(y_test_atraso, y_pred_atraso_rf)\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS DO MODELO DE ATRASO (Random Forest):\")\n",
    "print(f\"  ‚Ä¢ MAE: {mae_rf:.2f} minutos\")\n",
    "print(f\"  ‚Ä¢ MSE: {mse_rf:.2f}\")\n",
    "print(f\"  ‚Ä¢ R¬≤: {r2_rf:.4f}\")\n",
    "\n",
    "# Valida√ß√£o cruzada\n",
    "print(\"\\nüîÑ Valida√ß√£o Cruzada (5 folds):\")\n",
    "cv_scores_rf = cross_val_score(modelo_atraso_rf, X_train_atraso, y_train_atraso, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"  ‚Ä¢ MAE m√©dio: {-cv_scores_rf.mean():.2f} (+/- {cv_scores_rf.std() * 2:.2f})\")\n",
    "\n",
    "# Import√¢ncia das features\n",
    "print(\"\\nüìà TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance_atraso = pd.DataFrame({\n",
    "    'feature': X_atraso.columns,\n",
    "    'importance': modelo_atraso_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_atraso.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e463cd9",
   "metadata": {},
   "source": [
    "## 4. Modelo 3: Previs√£o de Margem (Regress√£o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: Previs√£o de Margem\n",
    "print(\"ü§ñ MODELO 3: PREVIS√ÉO DE MARGEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Preparar dados para margem\n",
    "features_margem = features_numericas + features_categoricas\n",
    "X_margem = df[features_margem].copy()\n",
    "y_margem = df['margem_brl'].copy()\n",
    "\n",
    "# Tratamento de dados categ√≥ricos\n",
    "for col in features_categoricas:\n",
    "    if col in X_margem.columns:\n",
    "        X_margem[col] = X_margem[col].astype(str)\n",
    "        X_margem[col] = le.fit_transform(X_margem[col])\n",
    "\n",
    "# Verificar se h√° valores nulos\n",
    "print(f\"Valores nulos em X_margem: {X_margem.isnull().sum().sum()}\")\n",
    "if X_margem.isnull().sum().sum() > 0:\n",
    "    X_margem = X_margem.fillna(X_margem.median())\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train_margem, X_test_margem, y_train_margem, y_test_margem = train_test_split(\n",
    "    X_margem, y_margem, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Dados de treino: {X_train_margem.shape[0]} amostras\")\n",
    "print(f\"üìä Dados de teste: {X_test_margem.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "print(\"\\nüå≤ Treinando Random Forest para margem...\")\n",
    "modelo_margem_rf = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "modelo_margem_rf.fit(X_train_margem, y_train_margem)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_margem_rf = modelo_margem_rf.predict(X_test_margem)\n",
    "\n",
    "# Avaliar modelo\n",
    "mae_margem = mean_absolute_error(y_test_margem, y_pred_margem_rf)\n",
    "mse_margem = mean_squared_error(y_test_margem, y_pred_margem_rf)\n",
    "r2_margem = r2_score(y_test_margem, y_pred_margem_rf)\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS DO MODELO DE MARGEM (Random Forest):\")\n",
    "print(f\"  ‚Ä¢ MAE: R$ {mae_margem:.2f}\")\n",
    "print(f\"  ‚Ä¢ MSE: R$ {mse_margem:.2f}\")\n",
    "print(f\"  ‚Ä¢ R¬≤: {r2_margem:.4f}\")\n",
    "\n",
    "# Valida√ß√£o cruzada\n",
    "print(\"\\nüîÑ Valida√ß√£o Cruzada (5 folds):\")\n",
    "cv_scores_margem = cross_val_score(modelo_margem_rf, X_train_margem, y_train_margem, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"  ‚Ä¢ MAE m√©dio: R$ {-cv_scores_margem.mean():.2f} (+/- {cv_scores_margem.std() * 2:.2f})\")\n",
    "\n",
    "# Import√¢ncia das features\n",
    "print(\"\\nüìà TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
    "feature_importance_margem = pd.DataFrame({\n",
    "    'feature': X_margem.columns,\n",
    "    'importance': modelo_margem_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance_margem.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea6ec8",
   "metadata": {},
   "source": [
    "## 5. Refatora√ß√£o dos Queries - An√°lise Eficiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refatora√ß√£o dos Queries - An√°lise Eficiente\n",
    "print(\"üîß REFATORA√á√ÉO DOS QUERIES - AN√ÅLISE EFICIENTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. An√°lise por Macro Bairro (substituindo queries repetitivos)\n",
    "print(\"üìä 1. AN√ÅLISE POR MACRO BAIRRO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar an√°lise consolidada por macro bairro\n",
    "analise_macro_bairro = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'distance_km': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten das colunas\n",
    "analise_macro_bairro.columns = ['_'.join(col).strip() for col in analise_macro_bairro.columns]\n",
    "analise_macro_bairro = analise_macro_bairro.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'distance_km_mean': 'Distancia_Media',\n",
    "    'tempo_preparo_minutos_mean': 'Tempo_Preparo_Medio'\n",
    "})\n",
    "\n",
    "print(\"üìà RESUMO POR MACRO BAIRRO:\")\n",
    "print(analise_macro_bairro.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 2. An√°lise por Platform (substituindo queries repetitivos)\n",
    "print(\"\\nüìä 2. AN√ÅLISE POR PLATFORM\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "analise_platform = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'platform_commission_pct': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_platform.columns = ['_'.join(col).strip() for col in analise_platform.columns]\n",
    "analise_platform = analise_platform.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'platform_commission_pct_mean': 'Comissao_Media'\n",
    "})\n",
    "\n",
    "print(\"üìà RESUMO POR PLATFORM:\")\n",
    "print(analise_platform.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 3. An√°lise por Order Mode (substituindo queries repetitivos)\n",
    "print(\"\\nüìä 3. AN√ÅLISE POR ORDER MODE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "analise_order_mode = df.groupby('order_mode').agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean',\n",
    "    'distance_km': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_order_mode.columns = ['_'.join(col).strip() for col in analise_order_mode.columns]\n",
    "analise_order_mode = analise_order_mode.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio',\n",
    "    'distance_km_mean': 'Distancia_Media'\n",
    "})\n",
    "\n",
    "print(\"üìà RESUMO POR ORDER MODE:\")\n",
    "print(analise_order_mode.sort_values('Receita_Total', ascending=False))\n",
    "\n",
    "# 4. An√°lise Combinada (Platform + Macro Bairro)\n",
    "print(\"\\nüìä 4. AN√ÅLISE COMBINADA (PLATFORM + MACRO BAIRRO)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "analise_combinada = df.groupby(['platform', 'macro_bairro']).agg({\n",
    "    'total_brl': ['count', 'mean', 'sum'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_combinada.columns = ['_'.join(col).strip() for col in analise_combinada.columns]\n",
    "analise_combinada = analise_combinada.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'total_brl_sum': 'Receita_Total',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"üìà TOP 10 COMBINA√á√ïES (PLATFORM + MACRO BAIRRO):\")\n",
    "print(analise_combinada.sort_values('Receita_Total', ascending=False).head(10))\n",
    "\n",
    "# 5. An√°lise Temporal Eficiente\n",
    "print(\"\\nüìä 5. AN√ÅLISE TEMPORAL EFICIENTE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# An√°lise por hora do dia\n",
    "analise_hora = df.groupby('hora').agg({\n",
    "    'total_brl': ['count', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_hora.columns = ['_'.join(col).strip() for col in analise_hora.columns]\n",
    "analise_hora = analise_hora.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"üìà RESUMO POR HORA DO DIA:\")\n",
    "print(analise_hora.sort_values('Total_Pedidos', ascending=False).head(10))\n",
    "\n",
    "# An√°lise por dia da semana\n",
    "analise_dia_semana = df.groupby('nome_dia_semana').agg({\n",
    "    'total_brl': ['count', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'atraso_minutos': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "analise_dia_semana.columns = ['_'.join(col).strip() for col in analise_dia_semana.columns]\n",
    "analise_dia_semana = analise_dia_semana.rename(columns={\n",
    "    'total_brl_count': 'Total_Pedidos',\n",
    "    'total_brl_mean': 'Ticket_Medio',\n",
    "    'satisfacao_nivel_mean': 'Satisfacao_Media',\n",
    "    'atraso_minutos_mean': 'Atraso_Medio'\n",
    "})\n",
    "\n",
    "print(\"\\nüìà RESUMO POR DIA DA SEMANA:\")\n",
    "print(analise_dia_semana.sort_values('Total_Pedidos', ascending=False))\n",
    "\n",
    "print(\"\\n‚úÖ REFATORA√á√ÉO CONCLU√çDA!\")\n",
    "print(\"   ‚Ä¢ Substitu√≠dos queries repetitivos por groupby eficiente\")\n",
    "print(\"   ‚Ä¢ An√°lises consolidadas em uma √∫nica opera√ß√£o\")\n",
    "print(\"   ‚Ä¢ C√≥digo mais limpo e perform√°tico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ccb962",
   "metadata": {},
   "source": [
    "## 6. Visualiza√ß√µes dos Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes dos Modelos\n",
    "print(\"üìä VISUALIZA√á√ïES DOS MODELOS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Matriz de Confus√£o - Modelo de Satisfa√ß√£o\n",
    "print(\"üìä 1. MATRIZ DE CONFUS√ÉO - SATISFA√á√ÉO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Matriz de confus√£o\n",
    "plt.subplot(1, 3, 1)\n",
    "cm = confusion_matrix(y_test_sat, y_pred_sat)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=sorted(y_test_sat.unique()), \n",
    "            yticklabels=sorted(y_test_sat.unique()))\n",
    "plt.title('Matriz de Confus√£o - Satisfa√ß√£o')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "# Import√¢ncia das features - Satisfa√ß√£o\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_sat = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features_sat)), top_features_sat['importance'])\n",
    "plt.yticks(range(len(top_features_sat)), top_features_sat['feature'])\n",
    "plt.title('Top 10 Features - Satisfa√ß√£o')\n",
    "plt.xlabel('Import√¢ncia')\n",
    "\n",
    "# Distribui√ß√£o das previs√µes vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_sat, y_pred_sat, alpha=0.6)\n",
    "plt.plot([y_test_sat.min(), y_test_sat.max()], [y_test_sat.min(), y_test_sat.max()], 'r--', lw=2)\n",
    "plt.xlabel('Satisfa√ß√£o Real')\n",
    "plt.ylabel('Satisfa√ß√£o Predita')\n",
    "plt.title('Previs√µes vs Real - Satisfa√ß√£o')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. An√°lise de Res√≠duos - Modelo de Atraso\n",
    "print(\"\\nüìä 2. AN√ÅLISE DE RES√çDUOS - ATRASO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Res√≠duos\n",
    "plt.subplot(1, 3, 1)\n",
    "residuos_atraso = y_test_atraso - y_pred_atraso_rf\n",
    "plt.scatter(y_pred_atraso_rf, residuos_atraso, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Preditos')\n",
    "plt.ylabel('Res√≠duos')\n",
    "plt.title('Res√≠duos vs Preditos - Atraso')\n",
    "\n",
    "# Import√¢ncia das features - Atraso\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_atraso = feature_importance_atraso.head(10)\n",
    "plt.barh(range(len(top_features_atraso)), top_features_atraso['importance'])\n",
    "plt.yticks(range(len(top_features_atraso)), top_features_atraso['feature'])\n",
    "plt.title('Top 10 Features - Atraso')\n",
    "plt.xlabel('Import√¢ncia')\n",
    "\n",
    "# Distribui√ß√£o das previs√µes vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_atraso, y_pred_atraso_rf, alpha=0.6)\n",
    "plt.plot([y_test_atraso.min(), y_test_atraso.max()], [y_test_atraso.min(), y_test_atraso.max()], 'r--', lw=2)\n",
    "plt.xlabel('Atraso Real (min)')\n",
    "plt.ylabel('Atraso Predito (min)')\n",
    "plt.title('Previs√µes vs Real - Atraso')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. An√°lise de Res√≠duos - Modelo de Margem\n",
    "print(\"\\nüìä 3. AN√ÅLISE DE RES√çDUOS - MARGEM\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Res√≠duos\n",
    "plt.subplot(1, 3, 1)\n",
    "residuos_margem = y_test_margem - y_pred_margem_rf\n",
    "plt.scatter(y_pred_margem_rf, residuos_margem, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Preditos')\n",
    "plt.ylabel('Res√≠duos')\n",
    "plt.title('Res√≠duos vs Preditos - Margem')\n",
    "\n",
    "# Import√¢ncia das features - Margem\n",
    "plt.subplot(1, 3, 2)\n",
    "top_features_margem = feature_importance_margem.head(10)\n",
    "plt.barh(range(len(top_features_margem)), top_features_margem['importance'])\n",
    "plt.yticks(range(len(top_features_margem)), top_features_margem['feature'])\n",
    "plt.title('Top 10 Features - Margem')\n",
    "plt.xlabel('Import√¢ncia')\n",
    "\n",
    "# Distribui√ß√£o das previs√µes vs reais\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_margem, y_pred_margem_rf, alpha=0.6)\n",
    "plt.plot([y_test_margem.min(), y_test_margem.max()], [y_test_margem.min(), y_test_margem.max()], 'r--', lw=2)\n",
    "plt.xlabel('Margem Real (R$)')\n",
    "plt.ylabel('Margem Predita (R$)')\n",
    "plt.title('Previs√µes vs Real - Margem')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Compara√ß√£o de Performance dos Modelos\n",
    "print(\"\\nüìä 4. COMPARA√á√ÉO DE PERFORMANCE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar DataFrame com m√©tricas\n",
    "metricas = pd.DataFrame({\n",
    "    'Modelo': ['Satisfa√ß√£o (RF)', 'Atraso (RF)', 'Margem (RF)'],\n",
    "    'M√©trica': ['Acur√°cia', 'MAE (min)', 'MAE (R$)'],\n",
    "    'Valor': [accuracy, mae_rf, mae_margem],\n",
    "    'R¬≤': [f1, r2_rf, r2_margem]\n",
    "})\n",
    "\n",
    "print(\"üìà RESUMO DAS M√âTRICAS:\")\n",
    "print(metricas)\n",
    "\n",
    "# Gr√°fico de compara√ß√£o\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(metricas['Modelo'], metricas['Valor'])\n",
    "plt.title('M√©tricas Principais por Modelo')\n",
    "plt.ylabel('Valor da M√©trica')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(metricas['Modelo'], metricas['R¬≤'])\n",
    "plt.title('R¬≤ / F1-Score por Modelo')\n",
    "plt.ylabel('R¬≤ / F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ VISUALIZA√á√ïES CONCLU√çDAS!\")\n",
    "print(\"   ‚Ä¢ Matriz de confus√£o para classifica√ß√£o\")\n",
    "print(\"   ‚Ä¢ An√°lise de res√≠duos para regress√£o\")\n",
    "print(\"   ‚Ä¢ Import√¢ncia das features\")\n",
    "print(\"   ‚Ä¢ Compara√ß√£o de performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3a753",
   "metadata": {},
   "source": [
    "## 7. Resumo e Salvamento dos Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1de559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo e Salvamento dos Modelos\n",
    "print(\"üíæ RESUMO E SALVAMENTO DOS MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Resumo dos Modelos Treinados\n",
    "print(\"üìä RESUMO DOS MODELOS TREINADOS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "modelos_info = {\n",
    "    'Modelo': ['Satisfa√ß√£o (Classifica√ß√£o)', 'Atraso (Regress√£o)', 'Margem (Regress√£o)'],\n",
    "    'Algoritmo': ['Random Forest Classifier', 'Random Forest Regressor', 'Random Forest Regressor'],\n",
    "    'Vari√°vel Alvo': ['satisfacao_nivel', 'atraso_minutos', 'margem_brl'],\n",
    "    'Acur√°cia/R¬≤': [f\"{accuracy:.4f}\", f\"{r2_rf:.4f}\", f\"{r2_margem:.4f}\"],\n",
    "    'MAE': [f\"{f1:.4f}\", f\"{mae_rf:.2f} min\", f\"R$ {mae_margem:.2f}\"],\n",
    "    'Features': [len(features_satisfacao), len(features_atraso), len(features_margem)]\n",
    "}\n",
    "\n",
    "resumo_modelos = pd.DataFrame(modelos_info)\n",
    "print(resumo_modelos)\n",
    "\n",
    "# 2. Salvar modelos treinados\n",
    "print(\"\\nüíæ SALVANDO MODELOS...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Criar diret√≥rio para modelos se n√£o existir\n",
    "if not os.path.exists('modelos'):\n",
    "    os.makedirs('modelos')\n",
    "\n",
    "# Salvar modelos\n",
    "joblib.dump(modelo_satisfacao, 'modelos/modelo_satisfacao.pkl')\n",
    "joblib.dump(modelo_atraso_rf, 'modelos/modelo_atraso.pkl')\n",
    "joblib.dump(modelo_margem_rf, 'modelos/modelo_margem.pkl')\n",
    "\n",
    "print(\"‚úÖ Modelos salvos em:\")\n",
    "print(\"   ‚Ä¢ modelos/modelo_satisfacao.pkl\")\n",
    "print(\"   ‚Ä¢ modelos/modelo_atraso.pkl\")\n",
    "print(\"   ‚Ä¢ modelos/modelo_margem.pkl\")\n",
    "\n",
    "# 3. Salvar informa√ß√µes dos modelos\n",
    "print(\"\\nüìã SALVANDO INFORMA√á√ïES DOS MODELOS...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Salvar features utilizadas\n",
    "features_info = {\n",
    "    'satisfacao': features_satisfacao,\n",
    "    'atraso': features_atraso,\n",
    "    'margem': features_margem\n",
    "}\n",
    "\n",
    "joblib.dump(features_info, 'modelos/features_info.pkl')\n",
    "\n",
    "# Salvar m√©tricas\n",
    "metricas_info = {\n",
    "    'satisfacao': {'accuracy': accuracy, 'f1_score': f1},\n",
    "    'atraso': {'mae': mae_rf, 'mse': mse_rf, 'r2': r2_rf},\n",
    "    'margem': {'mae': mae_margem, 'mse': mse_margem, 'r2': r2_margem}\n",
    "}\n",
    "\n",
    "joblib.dump(metricas_info, 'modelos/metricas_info.pkl')\n",
    "\n",
    "print(\"‚úÖ Informa√ß√µes salvas em:\")\n",
    "print(\"   ‚Ä¢ modelos/features_info.pkl\")\n",
    "print(\"   ‚Ä¢ modelos/metricas_info.pkl\")\n",
    "\n",
    "# 4. Fun√ß√£o para fazer previs√µes\n",
    "print(\"\\nüîÆ FUN√á√ÉO DE PREVIS√ÉO:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def fazer_previsoes(dados_novos):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para fazer previs√µes com os modelos treinados\n",
    "    \n",
    "    Args:\n",
    "        dados_novos: DataFrame com as features necess√°rias\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicion√°rio com as previs√µes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carregar modelos\n",
    "        modelo_sat = joblib.load('modelos/modelo_satisfacao.pkl')\n",
    "        modelo_atraso = joblib.load('modelos/modelo_atraso.pkl')\n",
    "        modelo_margem = joblib.load('modelos/modelo_margem.pkl')\n",
    "        \n",
    "        # Carregar features\n",
    "        features_info = joblib.load('modelos/features_info.pkl')\n",
    "        \n",
    "        # Preparar dados\n",
    "        X_sat = dados_novos[features_info['satisfacao']].copy()\n",
    "        X_atraso = dados_novos[features_info['atraso']].copy()\n",
    "        X_margem = dados_novos[features_info['margem']].copy()\n",
    "        \n",
    "        # Tratamento de dados categ√≥ricos\n",
    "        le = LabelEncoder()\n",
    "        for col in features_categoricas:\n",
    "            if col in X_sat.columns:\n",
    "                X_sat[col] = X_sat[col].astype(str)\n",
    "                X_sat[col] = le.fit_transform(X_sat[col])\n",
    "            if col in X_atraso.columns:\n",
    "                X_atraso[col] = X_atraso[col].astype(str)\n",
    "                X_atraso[col] = le.fit_transform(X_atraso[col])\n",
    "            if col in X_margem.columns:\n",
    "                X_margem[col] = X_margem[col].astype(str)\n",
    "                X_margem[col] = le.fit_transform(X_margem[col])\n",
    "        \n",
    "        # Preencher valores nulos\n",
    "        X_sat = X_sat.fillna(X_sat.median())\n",
    "        X_atraso = X_atraso.fillna(X_atraso.median())\n",
    "        X_margem = X_margem.fillna(X_margem.median())\n",
    "        \n",
    "        # Fazer previs√µes\n",
    "        previsoes = {\n",
    "            'satisfacao_predita': modelo_sat.predict(X_sat),\n",
    "            'atraso_predito': modelo_atraso.predict(X_atraso),\n",
    "            'margem_predita': modelo_margem.predict(X_margem)\n",
    "        }\n",
    "        \n",
    "        return previsoes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao fazer previs√µes: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de previs√£o criada!\")\n",
    "print(\"   Use: fazer_previsoes(seu_dataframe)\")\n",
    "\n",
    "# 5. Resumo final\n",
    "print(\"\\nüéØ RESUMO FINAL:\")\n",
    "print(\"=\" * 30)\n",
    "print(\"‚úÖ MODELAGEM CONCLU√çDA COM SUCESSO!\")\n",
    "print(f\"   ‚Ä¢ 3 modelos treinados e validados\")\n",
    "print(f\"   ‚Ä¢ Valida√ß√£o cruzada implementada\")\n",
    "print(f\"   ‚Ä¢ An√°lise de import√¢ncia das features\")\n",
    "print(f\"   ‚Ä¢ Visualiza√ß√µes completas\")\n",
    "print(f\"   ‚Ä¢ Modelos salvos para uso futuro\")\n",
    "print(f\"   ‚Ä¢ Queries refatorados para maior efici√™ncia\")\n",
    "print(f\"   ‚Ä¢ C√≥digo organizado e limpo\")\n",
    "\n",
    "print(\"\\nüìä PR√ìXIMOS PASSOS RECOMENDADOS:\")\n",
    "print(\"   ‚Ä¢ Testar modelos com dados novos\")\n",
    "print(\"   ‚Ä¢ Implementar monitoramento de performance\")\n",
    "print(\"   ‚Ä¢ Considerar ensemble de modelos\")\n",
    "print(\"   ‚Ä¢ Otimizar hiperpar√¢metros com GridSearch\")\n",
    "print(\"   ‚Ä¢ Implementar pipeline de produ√ß√£o\")\n",
    "\n",
    "print(\"\\nüöÄ PROJETO PRONTO PARA APRESENTA√á√ÉO!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47874ed",
   "metadata": {},
   "source": [
    "# Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc649141",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a3f93",
   "metadata": {},
   "source": [
    "# Coleta e explora√ß√£o dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb7951",
   "metadata": {},
   "source": [
    "An√°lise b√°sica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48b9ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "delivered     4802\n",
       "canceled       180\n",
       "chargeback      18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a86ee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='status'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=df['status'].value_counts().index, y=df['status'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e29a3183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_mode\n",
       "delivery    4024\n",
       "retirada     976\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['order_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8935115",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['order_mode'].value_counts().index, y=df['order_mode'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ac6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['platform'].value_counts().index, y=df['platform'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classe_pedido'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['classe_pedido'].value_counts().index, y=df['classe_pedido'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['macro_bairro'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=df['macro_bairro'].value_counts().index, y=df['macro_bairro'].value_counts().values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6149c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('macro_bairro')['bairro_destino'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689878b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brooklin = df.query('macro_bairro == \"Brooklin\"')\n",
    "df_itaim = df.query('macro_bairro == \"Itaim\"')\n",
    "df_jardins = df.query('macro_bairro == \"Jardins\"')\n",
    "df_moema = df.query('macro_bairro == \"Moema\"')\n",
    "df_morumbi = df.query('macro_bairro == \"Morumbi\"')\n",
    "df_outros = df.query('macro_bairro == \"Outros\"')\n",
    "df_pinheiros = df.query('macro_bairro == \"Pinheiros\"')\n",
    "df_santo_amaro = df.query('macro_bairro == \"Santo Amaro\"')\n",
    "df_vila_mariana = df.query('macro_bairro == \"Vila Mariana\"')\n",
    "df_vila_olimpia = df.query('macro_bairro == \"Vila Ol√≠mpia\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1aa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brooklin_tamanho = df_brooklin.count().unique()\n",
    "df_delivery_brooklin = df_brooklin.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_brooklin = df_brooklin.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_brooklin = (df_delivery_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_retirada_brooklin = (df_retirada_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_itaim_tamanho = df_itaim.count().unique()\n",
    "df_delivery_itaim = df_itaim.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_itaim = df_itaim.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_itaim = (df_delivery_itaim / df_itaim_tamanho)\n",
    "porcentagem_retirada_itaim = (df_retirada_itaim / df_itaim_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_jardins_tamanho = df_jardins.count().unique()\n",
    "df_delivery_jardins = df_jardins.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_jardins = df_jardins.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_jardins = (df_delivery_jardins / df_jardins_tamanho)\n",
    "porcentagem_retirada_jardins = (df_retirada_jardins / df_jardins_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_moema_tamanho = df_moema.count().unique()\n",
    "df_delivery_moema = df_moema.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_moema = df_moema.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_moema = (df_delivery_moema / df_moema_tamanho)\n",
    "porcentagem_retirada_moema = (df_retirada_moema / df_moema_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_morumbi_tamanho = df_morumbi.count().unique()\n",
    "df_delivery_morumbi = df_morumbi.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_morumbi = df_morumbi.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_morumbi = (df_delivery_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_retirada_morumbi = (df_retirada_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_outros_tamanho = df_outros.count().unique()\n",
    "df_delivery_outros = df_outros.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_outros = df_outros.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_outros = (df_delivery_outros / df_outros_tamanho)\n",
    "porcentagem_retirada_outros = (df_retirada_outros / df_outros_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_pinheiros_tamanho = df_pinheiros.count().unique()\n",
    "df_delivery_pinheiros = df_pinheiros.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_pinheiros = df_pinheiros.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_pinheiros = (df_delivery_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_retirada_pinheiros = (df_retirada_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_santo_amaro_tamanho = df_santo_amaro.count().unique()\n",
    "df_delivery_santo_amaro = df_santo_amaro.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_santo_amaro = df_santo_amaro.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_santo_amaro = (df_delivery_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_retirada_santo_amaro = (df_retirada_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_vila_mariana_tamanho = df_vila_mariana.count().unique()\n",
    "df_delivery_vila_mariana = df_vila_mariana.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_vila_mariana = df_vila_mariana.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_vila_mariana = (df_delivery_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_retirada_vila_mariana = (df_retirada_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_vila_olimpia_tamanho = df_vila_olimpia.count().unique()\n",
    "df_delivery_vila_olimpia = df_vila_olimpia.query('order_mode == \"delivery\"').count().unique()\n",
    "df_retirada_vila_olimpia = df_vila_olimpia.query('order_mode == \"retirada\"').count().unique()\n",
    "\n",
    "porcentagem_delivery_vila_olimpia = (df_delivery_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_retirada_vila_olimpia = (df_retirada_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_brooklin[0], porcentagem_retirada_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_itaim[0], porcentagem_retirada_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_jardins[0], porcentagem_retirada_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_moema[0], porcentagem_retirada_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_morumbi[0], porcentagem_retirada_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_outros[0], porcentagem_retirada_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_pinheiros[0], porcentagem_retirada_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_santo_amaro[0], porcentagem_retirada_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_vila_mariana[0], porcentagem_retirada_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Delivery', 'Retirada'], y=[porcentagem_delivery_vila_olimpia[0], porcentagem_retirada_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Ol√≠mpia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d99e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifood_brooklin = df_brooklin.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_brooklin = df_brooklin.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_brooklin = df_brooklin.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_brooklin = df_brooklin.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_brooklin = (df_ifood_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_rappi_brooklin = (df_rappi_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_whatsapp_brooklin = (df_whatsapp_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_site_proprio_brooklin = (df_site_proprio_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "df_ifood_itaim = df_itaim.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_itaim = df_itaim.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_itaim = df_itaim.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_itaim = df_itaim.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_itaim = (df_ifood_itaim / df_itaim_tamanho)\n",
    "porcentagem_rappi_itaim = (df_rappi_itaim / df_itaim_tamanho)\n",
    "porcentagem_whatsapp_itaim = (df_whatsapp_itaim / df_itaim_tamanho)\n",
    "porcentagem_site_proprio_itaim = (df_site_proprio_itaim / df_itaim_tamanho)\n",
    "\n",
    "df_ifood_jardins = df_jardins.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_jardins = df_jardins.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_jardins = df_jardins.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_jardins = df_jardins.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_jardins = (df_ifood_jardins / df_jardins_tamanho)\n",
    "porcentagem_rappi_jardins = (df_rappi_jardins / df_jardins_tamanho)\n",
    "porcentagem_whatsapp_jardins = (df_whatsapp_jardins / df_jardins_tamanho)\n",
    "porcentagem_site_proprio_jardins = (df_site_proprio_jardins / df_jardins_tamanho)\n",
    "\n",
    "df_ifood_moema = df_moema.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_moema = df_moema.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_moema = df_moema.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_moema = df_moema.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_moema = (df_ifood_moema / df_moema_tamanho)\n",
    "porcentagem_rappi_moema = (df_rappi_moema / df_moema_tamanho)\n",
    "porcentagem_whatsapp_moema = (df_whatsapp_moema / df_moema_tamanho)\n",
    "porcentagem_site_proprio_moema = (df_site_proprio_moema / df_moema_tamanho)\n",
    "\n",
    "df_morumbi_tamanho = df_morumbi.count().unique()\n",
    "df_ifood_morumbi = df_morumbi.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_morumbi = df_morumbi.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_morumbi = df_morumbi.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_morumbi = df_morumbi.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_morumbi = (df_ifood_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_rappi_morumbi = (df_rappi_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_whatsapp_morumbi = (df_whatsapp_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_site_proprio_morumbi = (df_site_proprio_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "df_ifood_outros = df_outros.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_outros = df_outros.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_outros = df_outros.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_outros = df_outros.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_outros = (df_ifood_outros / df_outros_tamanho)\n",
    "porcentagem_rappi_outros = (df_rappi_outros / df_outros_tamanho)\n",
    "porcentagem_whatsapp_outros = (df_whatsapp_outros / df_outros_tamanho)\n",
    "porcentagem_site_proprio_outros = (df_site_proprio_outros / df_outros_tamanho)\n",
    "\n",
    "df_ifood_pinheiros = df_pinheiros.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_pinheiros = df_pinheiros.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_pinheiros = df_pinheiros.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_pinheiros = df_pinheiros.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_pinheiros = (df_ifood_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_rappi_pinheiros = (df_rappi_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_whatsapp_pinheiros = (df_whatsapp_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_site_proprio_pinheiros = (df_site_proprio_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "df_ifood_santo_amaro = df_santo_amaro.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_santo_amaro = df_santo_amaro.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_santo_amaro = df_santo_amaro.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_santo_amaro = df_santo_amaro.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_santo_amaro = (df_ifood_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_rappi_santo_amaro = (df_rappi_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_whatsapp_santo_amaro = (df_whatsapp_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_site_proprio_santo_amaro = (df_site_proprio_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "df_ifood_vila_mariana = df_vila_mariana.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_vila_mariana = df_vila_mariana.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_vila_mariana = df_vila_mariana.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_vila_mariana = df_vila_mariana.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_vila_mariana = (df_ifood_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_rappi_vila_mariana = (df_rappi_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_whatsapp_vila_mariana = (df_whatsapp_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_site_proprio_vila_mariana = (df_site_proprio_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "df_ifood_vila_olimpia = df_vila_olimpia.query('platform == \"ifood\"').count().unique()\n",
    "df_rappi_vila_olimpia = df_vila_olimpia.query('platform == \"rappi\"').count().unique()\n",
    "df_whatsapp_vila_olimpia = df_vila_olimpia.query('platform == \"whatsapp\"').count().unique()\n",
    "df_site_proprio_vila_olimpia = df_vila_olimpia.query('platform == \"site_proprio\"').count().unique()\n",
    "porcentagem_ifood_vila_olimpia = (df_ifood_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_rappi_vila_olimpia = (df_rappi_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_whatsapp_vila_olimpia = (df_whatsapp_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_site_proprio_vila_olimpia = (df_site_proprio_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_brooklin[0], porcentagem_rappi_brooklin[0], porcentagem_whatsapp_brooklin[0], porcentagem_site_proprio_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_itaim[0], porcentagem_rappi_itaim[0], porcentagem_whatsapp_itaim[0], porcentagem_site_proprio_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_jardins[0], porcentagem_rappi_jardins[0], porcentagem_whatsapp_jardins[0], porcentagem_site_proprio_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_moema[0], porcentagem_rappi_moema[0], porcentagem_whatsapp_moema[0], porcentagem_site_proprio_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_morumbi[0], porcentagem_rappi_morumbi[0], porcentagem_whatsapp_morumbi[0], porcentagem_site_proprio_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_outros[0], porcentagem_rappi_outros[0], porcentagem_whatsapp_outros[0], porcentagem_site_proprio_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_pinheiros[0], porcentagem_rappi_pinheiros[0], porcentagem_whatsapp_pinheiros[0], porcentagem_site_proprio_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_santo_amaro[0], porcentagem_rappi_santo_amaro[0], porcentagem_whatsapp_santo_amaro[0], porcentagem_site_proprio_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_vila_mariana[0], porcentagem_rappi_vila_mariana[0], porcentagem_whatsapp_vila_mariana[0], porcentagem_site_proprio_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Ifood', 'Rappi', 'Whatsapp', 'Site Pr√≥prio'], y=[porcentagem_ifood_vila_olimpia[0], porcentagem_rappi_vila_olimpia[0], porcentagem_whatsapp_vila_olimpia[0], porcentagem_site_proprio_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Ol√≠mpia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_brooklin = df_brooklin.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_brooklin = df_brooklin.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_brooklin = df_brooklin.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_brooklin = (df_combo_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_prato_unico_brooklin = (df_prato_unico_brooklin / df_brooklin_tamanho)\n",
    "porcentagem_familia_brooklin = (df_familia_brooklin / df_brooklin_tamanho)\n",
    "\n",
    "df_combo_itaim = df_itaim.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_itaim = df_itaim.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_itaim = df_itaim.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_itaim = (df_combo_itaim / df_itaim_tamanho)\n",
    "porcentagem_prato_unico_itaim = (df_prato_unico_itaim / df_itaim_tamanho)\n",
    "porcentagem_familia_itaim = (df_familia_itaim / df_itaim_tamanho)\n",
    "\n",
    "df_combo_jardins = df_jardins.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_jardins = df_jardins.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_jardins = df_jardins.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_jardins = (df_combo_jardins / df_jardins_tamanho)\n",
    "porcentagem_prato_unico_jardins = (df_prato_unico_jardins / df_jardins_tamanho)\n",
    "porcentagem_familia_jardins = (df_familia_jardins / df_jardins_tamanho)\n",
    "\n",
    "df_combo_moema = df_moema.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_moema = df_moema.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_moema = df_moema.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_moema = (df_combo_moema / df_moema_tamanho)\n",
    "porcentagem_prato_unico_moema = (df_prato_unico_moema / df_moema_tamanho)\n",
    "porcentagem_familia_moema = (df_familia_moema / df_moema_tamanho)\n",
    "\n",
    "df_combo_morumbi = df_morumbi.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_morumbi = df_morumbi.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_morumbi = df_morumbi.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_morumbi = (df_combo_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_prato_unico_morumbi = (df_prato_unico_morumbi / df_morumbi_tamanho)\n",
    "porcentagem_familia_morumbi = (df_familia_morumbi / df_morumbi_tamanho)\n",
    "\n",
    "df_combo_outros = df_outros.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_outros = df_outros.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_outros = df_outros.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_outros = (df_combo_outros / df_outros_tamanho)\n",
    "porcentagem_prato_unico_outros = (df_prato_unico_outros / df_outros_tamanho)\n",
    "porcentagem_familia_outros = (df_familia_outros / df_outros_tamanho)\n",
    "\n",
    "df_combo_pinheiros = df_pinheiros.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_pinheiros = df_pinheiros.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_pinheiros = df_pinheiros.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_pinheiros = (df_combo_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_prato_unico_pinheiros = (df_prato_unico_pinheiros / df_pinheiros_tamanho)\n",
    "porcentagem_familia_pinheiros = (df_familia_pinheiros / df_pinheiros_tamanho)\n",
    "\n",
    "df_combo_santo_amaro = df_santo_amaro.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_santo_amaro = df_santo_amaro.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_santo_amaro = df_santo_amaro.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_santo_amaro = (df_combo_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_prato_unico_santo_amaro = (df_prato_unico_santo_amaro / df_santo_amaro_tamanho)\n",
    "porcentagem_familia_santo_amaro = (df_familia_santo_amaro / df_santo_amaro_tamanho)\n",
    "\n",
    "df_combo_vila_mariana = df_vila_mariana.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_vila_mariana = df_vila_mariana.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_vila_mariana = df_vila_mariana.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_vila_mariana = (df_combo_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_prato_unico_vila_mariana = (df_prato_unico_vila_mariana / df_vila_mariana_tamanho)\n",
    "porcentagem_familia_vila_mariana = (df_familia_vila_mariana / df_vila_mariana_tamanho)\n",
    "\n",
    "df_combo_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"combo\"').count().unique()\n",
    "df_prato_unico_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"prato_unico\"').count().unique()\n",
    "df_familia_vila_olimpia = df_vila_olimpia.query('classe_pedido == \"familia\"').count().unique()\n",
    "porcentagem_combo_vila_olimpia = (df_combo_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_prato_unico_vila_olimpia = (df_prato_unico_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "porcentagem_familia_vila_olimpia = (df_familia_vila_olimpia / df_vila_olimpia_tamanho)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20,10), sharey=True)\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_brooklin[0], porcentagem_prato_unico_brooklin[0], porcentagem_familia_brooklin[0]], ax=axes[0,0]).set_title('Brooklin')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_itaim[0], porcentagem_prato_unico_itaim[0], porcentagem_familia_itaim[0]], ax=axes[0,1]).set_title('Itaim')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_jardins[0], porcentagem_prato_unico_jardins[0], porcentagem_familia_jardins[0]], ax=axes[0,2]).set_title('Jardins')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_moema[0], porcentagem_prato_unico_moema[0], porcentagem_familia_moema[0]], ax=axes[0,3]).set_title('Moema')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_morumbi[0], porcentagem_prato_unico_morumbi[0], porcentagem_familia_morumbi[0]], ax=axes[0,4]).set_title('Morumbi')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_outros[0], porcentagem_prato_unico_outros[0], porcentagem_familia_outros[0]], ax=axes[1,0]).set_title('Outros')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_pinheiros[0], porcentagem_prato_unico_pinheiros[0], porcentagem_familia_pinheiros[0]], ax=axes[1,1]).set_title('Pinheiros')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_santo_amaro[0], porcentagem_prato_unico_santo_amaro[0], porcentagem_familia_santo_amaro[0]], ax=axes[1,2]).set_title('Santo Amaro')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_vila_mariana[0], porcentagem_prato_unico_vila_mariana[0], porcentagem_familia_vila_mariana[0]], ax=axes[1,3]).set_title('Vila Mariana')\n",
    "sns.barplot(x=['Combo', 'Prato √önico', 'Fam√≠lia'], y=[porcentagem_combo_vila_olimpia[0], porcentagem_prato_unico_vila_olimpia[0], porcentagem_familia_vila_olimpia[0]], ax=axes[1,4]).set_title('Vila Ol√≠mpia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c10be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_km'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['distance_km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['distance_km'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aee9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tempo_preparo_minutos'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['tempo_preparo_minutos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['tempo_preparo_minutos'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eta_minutes_quote'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['eta_minutes_quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07507ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['eta_minutes_quote'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_delivery_minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['actual_delivery_minutes'] < 0, 'actual_delivery_minutes'] = df.loc[df['actual_delivery_minutes'] < 0, 'actual_delivery_minutes'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e562947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['actual_delivery_minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['actual_delivery_minutes'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_brl'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['total_brl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc164450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['total_brl'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_itens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['num_itens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf09b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['num_itens'], bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfacao_nivel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e704db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['satisfacao_nivel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640d21e",
   "metadata": {},
   "source": [
    "Usando groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69604428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['platform', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'),\n",
    "                                                   DesvioPadrao=('total_brl', 'std'),\n",
    "                                                   QtdePedidos=('total_brl', 'count')).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rappi_satisfacao_tamanho = df.query('platform == \"rappi\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_1 = df.query('platform == \"rappi\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_2 = df.query('platform == \"rappi\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_3 = df.query('platform == \"rappi\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_4 = df.query('platform == \"rappi\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_rappi_satisfacao_5 = df.query('platform == \"rappi\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_rappi_satisfacao_1 = (df_rappi_satisfacao_1 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_2 = (df_rappi_satisfacao_2 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_3 = (df_rappi_satisfacao_3 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_4 = (df_rappi_satisfacao_4 / df_rappi_satisfacao_tamanho)\n",
    "porcentagem_rappi_satisfacao_5 = (df_rappi_satisfacao_5 / df_rappi_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_ifood_satisfacao_tamanho = df.query('platform == \"ifood\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_1 = df.query('platform == \"ifood\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_2 = df.query('platform == \"ifood\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_3 = df.query('platform == \"ifood\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_4 = df.query('platform == \"ifood\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_ifood_satisfacao_5 = df.query('platform == \"ifood\" and   satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_ifood_satisfacao_1 = (df_ifood_satisfacao_1 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_2 = (df_ifood_satisfacao_2 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_3 = (df_ifood_satisfacao_3 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_4 = (df_ifood_satisfacao_4 / df_ifood_satisfacao_tamanho)\n",
    "porcentagem_ifood_satisfacao_5 = (df_ifood_satisfacao_5 / df_ifood_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_whatsapp_satisfacao_tamanho = df.query('platform == \"whatsapp\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_1 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_2 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_3 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_4 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_whatsapp_satisfacao_5 = df.query('platform == \"whatsapp\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_whatsapp_satisfacao_1 = (df_whatsapp_satisfacao_1 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_2 = (df_whatsapp_satisfacao_2 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_3 = (df_whatsapp_satisfacao_3 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_4 = (df_whatsapp_satisfacao_4 / df_whatsapp_satisfacao_tamanho)\n",
    "porcentagem_whatsapp_satisfacao_5 = (df_whatsapp_satisfacao_5 / df_whatsapp_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_site_proprio_satisfacao_tamanho = df.query('platform == \"site_proprio\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_1 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_2 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_3 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_4 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_site_proprio_satisfacao_5 = df.query('platform == \"site_proprio\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_site_proprio_satisfacao_1 = (df_site_proprio_satisfacao_1 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_2 = (df_site_proprio_satisfacao_2 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_3 = (df_site_proprio_satisfacao_3 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_4 = (df_site_proprio_satisfacao_4 / df_site_proprio_satisfacao_tamanho)\n",
    "porcentagem_site_proprio_satisfacao_5 = (df_site_proprio_satisfacao_5 / df_site_proprio_satisfacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_retirada_satisacao_tamanho = df.query('order_mode == \"retirada\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_1 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique() \n",
    "df_retirada_satisacao_2 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_3 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_4 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_retirada_satisacao_5 = df.query('order_mode == \"retirada\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_retirada_satisacao_1 = (df_retirada_satisacao_1 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_2 = (df_retirada_satisacao_2 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_3 = (df_retirada_satisacao_3 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_4 = (df_retirada_satisacao_4 / df_retirada_satisacao_tamanho)\n",
    "porcentagem_retirada_satisacao_5 = (df_retirada_satisacao_5 / df_retirada_satisacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "df_delivery_satisacao_tamanho = df.query('order_mode == \"delivery\"').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_1 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 1').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_2 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 2').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_3 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 3').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_4 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 4').groupby('satisfacao_nivel').count().sum().unique()\n",
    "df_delivery_satisacao_5 = df.query('order_mode == \"delivery\" and satisfacao_nivel == 5').groupby('satisfacao_nivel').count().sum().unique()\n",
    "\n",
    "porcentagem_delivery_satisacao_1 = (df_delivery_satisacao_1 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_2 = (df_delivery_satisacao_2 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_3 = (df_delivery_satisacao_3 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_4 = (df_delivery_satisacao_4 / df_delivery_satisacao_tamanho)\n",
    "porcentagem_delivery_satisacao_5 = (df_delivery_satisacao_5 / df_delivery_satisacao_tamanho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6, 6), sharey=True)\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_rappi_satisfacao_1[0], porcentagem_rappi_satisfacao_2[0], porcentagem_rappi_satisfacao_3[0],\n",
    "               porcentagem_rappi_satisfacao_4[0], porcentagem_rappi_satisfacao_5[0]],\n",
    "            ax=axes[0, 0]).set_title('Rappi')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_ifood_satisfacao_1[0], porcentagem_ifood_satisfacao_2[0], porcentagem_ifood_satisfacao_3[0],\n",
    "               porcentagem_ifood_satisfacao_4[0], porcentagem_ifood_satisfacao_5[0]],\n",
    "            ax=axes[0, 1]).set_title('iFood')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_whatsapp_satisfacao_1[0], porcentagem_whatsapp_satisfacao_2[0], porcentagem_whatsapp_satisfacao_3[0],\n",
    "               porcentagem_whatsapp_satisfacao_4[0], porcentagem_whatsapp_satisfacao_5[0]],\n",
    "            ax=axes[1, 0]).set_title('WhatsApp')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_site_proprio_satisfacao_1[0], porcentagem_site_proprio_satisfacao_2[0], porcentagem_site_proprio_satisfacao_3[0],\n",
    "               porcentagem_site_proprio_satisfacao_4[0], porcentagem_site_proprio_satisfacao_5[0]],\n",
    "            ax=axes[1, 1]).set_title('Site Pr√≥prio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), sharey=True)\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_retirada_satisacao_1[0], porcentagem_retirada_satisacao_2[0], porcentagem_retirada_satisacao_3[0],\n",
    "               porcentagem_retirada_satisacao_4[0], porcentagem_retirada_satisacao_5[0]],\n",
    "            ax=ax[0]).set_title('Retirada')\n",
    "\n",
    "sns.barplot(x=['1', '2', '3', '4', '5'],\n",
    "            y=[porcentagem_delivery_satisacao_1[0], porcentagem_delivery_satisacao_2[0], porcentagem_delivery_satisacao_3[0],\n",
    "               porcentagem_delivery_satisacao_4[0], porcentagem_delivery_satisacao_5[0]],\n",
    "            ax=ax[1]).set_title('Delivery')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619b3f1",
   "metadata": {},
   "source": [
    "Podemos ver que o p√∫blico da Kaiserhaus s√£o de clientes que est√£o preocupados com um atendimento mais personalizado e focado na peculiaridade de cada cliente. Clientes que buscam por um n√≠vel de experi√™ncia diferenciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['platform']).agg(PrecoMedio=('total_brl', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['classe_pedido'])[['platform']].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_combo_ifood = df.query('classe_pedido == \"combo\" and platform == \"ifood\"').count().unique()\n",
    "qtd_combo_rappi = df.query('classe_pedido == \"combo\" and platform == \"rappi\"').count().unique()\n",
    "qtd_combo_whatsapp = df.query('classe_pedido == \"combo\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_combo_site_proprio = df.query('classe_pedido == \"combo\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "qtd_familia_ifood = df.query('classe_pedido == \"familia\" and platform == \"ifood\"').count().unique()\n",
    "qtd_familia_rappi = df.query('classe_pedido == \"familia\" and platform == \"rappi\"').count().unique()\n",
    "qtd_familia_whatsapp = df.query('classe_pedido == \"familia\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_familia_site_proprio = df.query('classe_pedido == \"familia\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "qtd_prato_unico_ifood = df.query('classe_pedido == \"prato_unico\" and platform == \"ifood\"').count().unique()\n",
    "qtd_prato_unico_rappi = df.query('classe_pedido == \"prato_unico\" and platform == \"rappi\"').count().unique()\n",
    "qtd_prato_unico_whatsapp = df.query('classe_pedido == \"prato_unico\" and platform == \"whatsapp\"').count().unique()\n",
    "qtd_prato_unico_site_proprio = df.query('classe_pedido == \"prato_unico\" and platform == \"site_proprio\"').count().unique()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 3),)\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_combo_ifood[0], qtd_combo_rappi[0], qtd_combo_whatsapp[0], qtd_combo_site_proprio[0]],\n",
    "            ax=ax[0]).set_title('Combo')\n",
    "\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_familia_ifood[0], qtd_familia_rappi[0], qtd_familia_whatsapp[0], qtd_familia_site_proprio[0]],\n",
    "            ax=ax[1]).set_title('Fam√≠lia')\n",
    "\n",
    "sns.barplot(x=['iFood', 'Rappi', 'WhatsApp', 'Site'],\n",
    "            y=[qtd_prato_unico_ifood[0], qtd_prato_unico_rappi[0], qtd_prato_unico_whatsapp[0], qtd_prato_unico_site_proprio[0]],\n",
    "            ax=ax[2]).set_title('Prato √önico')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['satisfacao_nivel'])[['total_brl']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('macro_bairro')['satisfacao_nivel'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['macro_bairro', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_niveis = [1, 2, 3, 4, 5]\n",
    "\n",
    "grp = (\n",
    "    df.groupby(['macro_bairro', 'satisfacao_nivel'])['total_brl']\n",
    "      .mean()\n",
    "      .reset_index(name='PrecoMedio')\n",
    ")\n",
    "\n",
    "wide = (grp\n",
    "        .pivot(index='macro_bairro', columns='satisfacao_nivel', values='PrecoMedio')\n",
    "        .reindex(columns=ordem_niveis)\n",
    "        .fillna(0.0))\n",
    "\n",
    "bairros = list(wide.index)\n",
    "\n",
    "n = len(bairros)\n",
    "ncols = 4\n",
    "nrows = math.ceil(n / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3*ncols, 2.8*nrows),\n",
    "                         sharex=True, sharey=True)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "ymax = (wide.max(axis=1).max() * 1.15) if n > 0 else 1.0\n",
    "if ymax <= 0: ymax = 1.0\n",
    "\n",
    "for ax, bairro in zip(axes, bairros):\n",
    "    y = wide.loc[bairro, ordem_niveis].values\n",
    "    ax.bar(ordem_niveis, y)\n",
    "    ax.set_title(str(bairro), fontsize=11, pad=6)\n",
    "    ax.set_xticks(ordem_niveis)\n",
    "    ax.set_xlabel('satisfacao_nivel')\n",
    "    ax.grid(axis='y', alpha=0.25)\n",
    "    ax.set_ylim(0, ymax)\n",
    "\n",
    "    for x, v in zip(ordem_niveis, y):\n",
    "        if v > 0:\n",
    "            ax.text(x, v, f'{v:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for ax in axes[len(bairros):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.supylabel('total_brl (m√©dia)')\n",
    "fig.supxlabel('N√≠vel de satisfa√ß√£o')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['classe_pedido', 'satisfacao_nivel'])[['total_brl']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['order_mode', 'satisfacao_nivel']).agg(PrecoMedio=('total_brl', 'mean'),\n",
    "                                                   DesvioPadrao=('total_brl', 'std'),\n",
    "                                                   QtdePedidos=('total_brl', 'count')).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby(['satisfacao_nivel'])['total_brl']\n",
    "df_groupby.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRE√á√ÉO DE VALORES INFINITOS E PROBLEMAS DE DADOS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verificar valores infinitos em todo o DataFrame\n",
    "print(\"üîç VERIFICA√á√ÉO DE VALORES INFINITOS:\")\n",
    "print(f\"Valores infinitos no DataFrame: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Identificar colunas com valores infinitos\n",
    "colunas_com_infinitos = []\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if np.isinf(df[col]).any():\n",
    "        colunas_com_infinitos.append(col)\n",
    "        print(f\"  {col}: {np.isinf(df[col]).sum()} valores infinitos\")\n",
    "\n",
    "# Corrigir valores infinitos\n",
    "if colunas_com_infinitos:\n",
    "    print(f\"\\nüîß CORRIGINDO VALORES INFINITOS:\")\n",
    "    for col in colunas_com_infinitos:\n",
    "        # Substituir infinitos por NaN\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # Preencher NaN com valores m√©dios\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "        print(f\"  {col}: Corrigido\")\n",
    "\n",
    "# Verificar novamente ap√≥s corre√ß√£o\n",
    "print(f\"\\n‚úÖ Valores infinitos ap√≥s corre√ß√£o: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Verificar se h√° valores muito grandes que podem causar problemas\n",
    "print(f\"\\nüîç VERIFICA√á√ÉO DE VALORES EXTREMOS:\")\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    max_val = df[col].max()\n",
    "    min_val = df[col].min()\n",
    "    if max_val > 1e10 or min_val < -1e10:\n",
    "        print(f\"  {col}: max={max_val:.2e}, min={min_val:.2e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dados limpos e prontos para an√°lise!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. criando features\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 2. Features de efici√™ncia e lucratividade\n",
    "df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# 3. Encoding de vari√°veis categ√≥ricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_platform = LabelEncoder()\n",
    "df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "\n",
    "le_order_mode = LabelEncoder()\n",
    "df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "\n",
    "le_status = LabelEncoder()\n",
    "df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "\n",
    "# Verificar se as colunas cr√≠ticas existem\n",
    "colunas_criticas = ['eficiencia_entrega', 'lucro_estimado', 'platform_encoded']\n",
    "for col in colunas_criticas:\n",
    "    if col in df.columns:\n",
    "        pass \n",
    "    else:\n",
    "        print(f\"‚ùå {col}: FALTANDO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa522c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. MATRIZ DE CORRELA√á√ÉO\n",
    "\n",
    "\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "# 2. AN√ÅLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "\n",
    "# 3. AN√ÅLISE DE RENTABILIDADE POR REGI√ÉO\n",
    "\n",
    "\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb68b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINI√á√ÉO DE VARI√ÅVEIS NECESS√ÅRIAS PARA AS AN√ÅLISES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Definir features para an√°lise de satisfa√ß√£o\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Definir features para clustering\n",
    "features_clustering = [\n",
    "    'total_brl', 'num_itens', 'tempo_preparo_minutos', \n",
    "    'actual_delivery_minutes', 'distance_km', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', \n",
    "    'dia_semana', 'hora', 'fim_de_semana'\n",
    "]\n",
    "\n",
    "# Verificar se as colunas existem no DataFrame\n",
    "print(\"üîç VERIFICA√á√ÉO DAS FEATURES:\")\n",
    "print(f\"Features para satisfa√ß√£o: {len(features_satisfacao)}\")\n",
    "print(f\"Features para clustering: {len(features_clustering)}\")\n",
    "\n",
    "# Verificar se as colunas existem\n",
    "colunas_faltando = []\n",
    "for col in features_satisfacao + features_clustering:\n",
    "    if col not in df.columns:\n",
    "        colunas_faltando.append(col)\n",
    "\n",
    "if colunas_faltando:\n",
    "    print(f\"‚ö†Ô∏è Colunas faltando: {colunas_faltando}\")\n",
    "else:\n",
    "    print(\"‚úÖ Todas as features est√£o dispon√≠veis no DataFrame\")\n",
    "\n",
    "print(f\"\\nüìä Shape do DataFrame: {df.shape}\")\n",
    "print(\"‚úÖ Vari√°veis definidas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRE√á√ÉO DO ERRO DE PREVIS√ÉO DE SATISFA√á√ÉO\n",
    "\n",
    "print(\"üîß INICIANDO CORRE√á√ÉO DO ERRO DE PREVIS√ÉO...\")\n",
    "\n",
    "# Verificar se o modelo foi treinado\n",
    "try:\n",
    "    # Verificar se o modelo existe\n",
    "    if 'modelo_satisfacao' not in locals():\n",
    "        print(\"‚ùå Modelo de satisfa√ß√£o n√£o foi treinado. Execute a c√©lula de treinamento primeiro.\")\n",
    "    else:\n",
    "        # Preparar dados para previs√£o - corrigir infinitos primeiro\n",
    "        df_predicao = df[features_satisfacao].copy()\n",
    "        \n",
    "        # Verificar valores infinitos\n",
    "        print(f\"Valores infinitos antes da corre√ß√£o: {np.isinf(df_predicao).sum().sum()}\")\n",
    "        \n",
    "        # Substituir infinitos por NaN\n",
    "        df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Preencher NaN com valores m√©dios\n",
    "        df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "        \n",
    "        # Verificar se h√° valores infinitos antes da previs√£o\n",
    "        print(f\"Valores infinitos ap√≥s corre√ß√£o: {np.isinf(df_predicao).sum().sum()}\")\n",
    "        \n",
    "        # Fazer previs√£o\n",
    "        print(\"üéØ Fazendo previs√£o...\")\n",
    "        df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "        pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "        \n",
    "        print(f\"\\n‚úÖ PREVIS√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "        print(f\"Total de pedidos: {len(df)}\")\n",
    "        print(f\"Pedidos de risco (baixa satisfa√ß√£o): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Caracter√≠sticas dos pedidos de risco\n",
    "        if len(pedidos_risco) > 0:\n",
    "            caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "            caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "            \n",
    "            print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "            comparacao = pd.DataFrame({\n",
    "                'Pedidos_Risco': caracteristicas_risco,\n",
    "                'Pedidos_Geral': caracteristicas_gerais\n",
    "            })\n",
    "            comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "            print(comparacao.round(2))\n",
    "        else:\n",
    "            print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro durante a previs√£o: {str(e)}\")\n",
    "    print(\"üí° Execute primeiro a c√©lula de treinamento do modelo de satisfa√ß√£o.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7640f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINAMENTO DO MODELO DE PREVIS√ÉO DE SATISFA√á√ÉO\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"ü§ñ TREINANDO MODELO DE PREVIS√ÉO DE SATISFA√á√ÉO...\")\n",
    "\n",
    "# Criar vari√°vel alvo categ√≥rica para classifica√ß√£o\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar features para o modelo de satisfa√ß√£o\n",
    "print(f\"üìä Features utilizadas: {len(features_satisfacao)}\")\n",
    "\n",
    "# Remover linhas com valores NaN e infinitos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Verificar valores infinitos\n",
    "print(f\"Valores infinitos antes da limpeza: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "# Limpar dados\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean = df_satisfacao_clean.dropna()\n",
    "\n",
    "print(f\"Shape ap√≥s limpeza: {df_satisfacao_clean.shape}\")\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "print(f\"Distribui√ß√£o das classes: {y_sat.value_counts().to_dict()}\")\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "print(f\"üìä Dados de treino: {X_train_sat.shape[0]} amostras\")\n",
    "print(f\"üìä Dados de teste: {X_test_sat.shape[0]} amostras\")\n",
    "\n",
    "# Treinar modelo Random Forest para classifica√ß√£o\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "\n",
    "print(f\"\\nüéØ PERFORMANCE DO MODELO:\")\n",
    "print(f\"Acur√°cia: {accuracy:.3f}\")\n",
    "\n",
    "# Import√¢ncia das features para satisfa√ß√£o\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä TOP 5 FEATURES MAIS IMPORTANTES:\")\n",
    "print(importancia_satisfacao.head())\n",
    "\n",
    "print(f\"\\n‚úÖ MODELO DE SATISFA√á√ÉO TREINADO COM SUCESSO!\")\n",
    "print(\"üöÄ Pronto para fazer previs√µes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa897eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECU√á√ÉO COMPLETA E SEGURA DAS AN√ÅLISES\n",
    "\n",
    "print(\"üöÄ EXECUTANDO TODAS AS AN√ÅLISES DA FASE 2...\")\n",
    "\n",
    "try:\n",
    "    # 1. Verificar se o modelo foi treinado\n",
    "    if 'modelo_satisfacao' in locals():\n",
    "        print(\"‚úÖ Modelo de satisfa√ß√£o encontrado!\")\n",
    "        \n",
    "        # 2. Preparar dados para previs√£o\n",
    "        print(\"üîß Preparando dados para previs√£o...\")\n",
    "        df_predicao = df[features_satisfacao].copy()\n",
    "        \n",
    "        # Verificar valores infinitos\n",
    "        infinitos_antes = np.isinf(df_predicao).sum().sum()\n",
    "        print(f\"Valores infinitos antes da corre√ß√£o: {infinitos_antes}\")\n",
    "        \n",
    "        # Corrigir infinitos\n",
    "        df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "        df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "        \n",
    "        infinitos_depois = np.isinf(df_predicao).sum().sum()\n",
    "        print(f\"Valores infinitos ap√≥s corre√ß√£o: {infinitos_depois}\")\n",
    "        \n",
    "        # 3. Fazer previs√£o\n",
    "        print(\"üéØ Fazendo previs√£o de satisfa√ß√£o...\")\n",
    "        df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "        \n",
    "        # 4. An√°lise dos resultados\n",
    "        pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "        \n",
    "        print(f\"\\n‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!\")\n",
    "        print(f\"Total de pedidos: {len(df)}\")\n",
    "        print(f\"Pedidos de risco (baixa satisfa√ß√£o): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 5. Caracter√≠sticas dos pedidos de risco\n",
    "        if len(pedidos_risco) > 0:\n",
    "            caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "            caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "            \n",
    "            print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "            comparacao = pd.DataFrame({\n",
    "                'Pedidos_Risco': caracteristicas_risco,\n",
    "                'Pedidos_Geral': caracteristicas_gerais\n",
    "            })\n",
    "            comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "            print(comparacao.round(2))\n",
    "            \n",
    "            # 6. Insights adicionais\n",
    "            print(f\"\\nüí° INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "            print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "            print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "            print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "            print(f\"Satisfa√ß√£o m√©dia real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "        else:\n",
    "            print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Modelo de satisfa√ß√£o n√£o encontrado!\")\n",
    "        print(\"üí° Execute primeiro a c√©lula de treinamento do modelo.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro durante a execu√ß√£o: {str(e)}\")\n",
    "    print(\"üí° Verifique se todas as c√©lulas anteriores foram executadas.\")\n",
    "\n",
    "print(f\"\\nüéØ STATUS FINAL DAS AN√ÅLISES:\")\n",
    "print(\"‚úÖ Fase 1: Matriz de Correla√ß√£o, Rentabilidade por Plataforma e Regi√£o\")\n",
    "print(\"‚úÖ Fase 2: Modelo de Previs√£o de Demanda\")\n",
    "print(\"‚úÖ Fase 2: An√°lise de Satisfa√ß√£o\")\n",
    "print(\"‚úÖ Fase 2: Segmenta√ß√£o de Clientes\")\n",
    "print(\"\\nüöÄ TODAS AS AN√ÅLISES AVAN√áADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLU√á√ÉO DEFINITIVA - EXECU√á√ÉO COMPLETA EM UMA C√âLULA\n",
    "\n",
    "print(\"üöÄ EXECUTANDO SOLU√á√ÉO DEFINITIVA - TODAS AS AN√ÅLISES EM UMA C√âLULA...\")\n",
    "\n",
    "# Importar todas as bibliotecas necess√°rias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. DEFINIR FEATURES\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Features definidas: {len(features_satisfacao)} vari√°veis\")\n",
    "\n",
    "# 2. TREINAR MODELO DE SATISFA√á√ÉO\n",
    "print(\"\\nü§ñ TREINANDO MODELO DE SATISFA√á√ÉO...\")\n",
    "\n",
    "# Criar vari√°vel alvo categ√≥rica\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar dados limpos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean = df_satisfacao_clean.dropna()\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "# Dividir e treinar\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "accuracy = accuracy_score(y_test_sat, modelo_satisfacao.predict(X_test_sat))\n",
    "print(f\"‚úÖ Modelo treinado com acur√°cia: {accuracy:.3f}\")\n",
    "\n",
    "# 3. FAZER PREVIS√ÉO DE SATISFA√á√ÉO\n",
    "print(\"\\nüéØ FAZENDO PREVIS√ÉO DE SATISFA√á√ÉO...\")\n",
    "\n",
    "# Preparar dados para previs√£o\n",
    "df_predicao = df[features_satisfacao].copy()\n",
    "df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "\n",
    "print(f\"Valores infinitos ap√≥s limpeza: {np.isinf(df_predicao).sum().sum()}\")\n",
    "\n",
    "# Fazer previs√£o\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"‚úÖ Previs√£o conclu√≠da!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 4. AN√ÅLISE DOS PEDIDOS DE RISCO\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    \n",
    "    caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "    caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "    \n",
    "    comparacao = pd.DataFrame({\n",
    "        'Pedidos_Risco': caracteristicas_risco,\n",
    "        'Pedidos_Geral': caracteristicas_gerais\n",
    "    })\n",
    "    comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "    print(comparacao.round(2))\n",
    "    \n",
    "    print(f\"\\nüí° INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfa√ß√£o m√©dia real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "\n",
    "# 5. IMPORT√ÇNCIA DAS FEATURES\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä TOP 5 FEATURES MAIS IMPORTANTES PARA SATISFA√á√ÉO:\")\n",
    "print(importancia_satisfacao.head())\n",
    "\n",
    "print(f\"\\nüéØ STATUS FINAL:\")\n",
    "print(\"‚úÖ Fase 1: Matriz de Correla√ß√£o, Rentabilidade por Plataforma e Regi√£o\")\n",
    "print(\"‚úÖ Fase 2: Modelo de Previs√£o de Demanda\")\n",
    "print(\"‚úÖ Fase 2: An√°lise de Satisfa√ß√£o - CONCLU√çDA\")\n",
    "print(\"‚úÖ Fase 2: Segmenta√ß√£o de Clientes\")\n",
    "print(\"\\nüöÄ TODAS AS AN√ÅLISES AVAN√áADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLU√á√ÉO DEFINITIVA - LIMPEZA COMPLETA E ROBUSTA\n",
    "\n",
    "print(\"üîß EXECUTANDO LIMPEZA COMPLETA E ROBUSTA DOS DADOS...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPEZA COMPLETA DO DATAFRAME PRINCIPAL\n",
    "print(\"üßπ Limpando DataFrame principal...\")\n",
    "\n",
    "# Verificar valores infinitos em todo o DataFrame\n",
    "infinitos_totais = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"Valores infinitos no DataFrame: {infinitos_totais}\")\n",
    "\n",
    "# Limpar valores infinitos em todas as colunas num√©ricas\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if np.isinf(df[col]).any():\n",
    "        print(f\"Limpando coluna: {col}\")\n",
    "        # Substituir infinitos por NaN\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # Preencher NaN com mediana (mais robusta que m√©dia)\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Verificar novamente\n",
    "infinitos_apos_limpeza = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"Valores infinitos ap√≥s limpeza: {infinitos_apos_limpeza}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES E CRIAR VARI√ÅVEL ALVO\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar vari√°vel alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"‚úÖ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS LIMPOS PARA TREINAMENTO\n",
    "print(\"ü§ñ Preparando dados para treinamento...\")\n",
    "\n",
    "# Criar DataFrame limpo apenas com as features necess√°rias\n",
    "df_clean = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Verificar valores infinitos nas features\n",
    "infinitos_features = np.isinf(df_clean[features_satisfacao]).sum().sum()\n",
    "print(f\"Valores infinitos nas features: {infinitos_features}\")\n",
    "\n",
    "# Limpar novamente se necess√°rio\n",
    "if infinitos_features > 0:\n",
    "    print(\"Limpando features espec√≠ficas...\")\n",
    "    for col in features_satisfacao:\n",
    "        df_clean[col] = df_clean[col].replace([np.inf, -np.inf], np.nan)\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# Remover linhas com NaN\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "print(f\"Shape ap√≥s limpeza: {df_clean.shape}\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"üéØ Treinando modelo...\")\n",
    "\n",
    "X = df_clean[features_satisfacao]\n",
    "y = df_clean['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acur√°cia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"‚úÖ Modelo treinado com acur√°cia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. FAZER PREVIS√ÉO SEGURA\n",
    "print(\"üîÆ Fazendo previs√£o segura...\")\n",
    "\n",
    "# Preparar dados para previs√£o (usar apenas as features necess√°rias)\n",
    "df_pred = df[features_satisfacao].copy()\n",
    "\n",
    "# Verificar valores infinitos\n",
    "infinitos_pred = np.isinf(df_pred).sum().sum()\n",
    "print(f\"Valores infinitos para previs√£o: {infinitos_pred}\")\n",
    "\n",
    "# Limpar se necess√°rio\n",
    "if infinitos_pred > 0:\n",
    "    for col in features_satisfacao:\n",
    "        df_pred[col] = df_pred[col].replace([np.inf, -np.inf], np.nan)\n",
    "        df_pred[col] = df_pred[col].fillna(df_pred[col].median())\n",
    "\n",
    "# Verificar NaN\n",
    "nan_pred = df_pred.isnull().sum().sum()\n",
    "print(f\"Valores NaN para previs√£o: {nan_pred}\")\n",
    "\n",
    "# Preencher NaN se necess√°rio\n",
    "if nan_pred > 0:\n",
    "    df_pred = df_pred.fillna(df_pred.median())\n",
    "\n",
    "# Fazer previs√£o\n",
    "print(\"Executando previs√£o...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_pred)\n",
    "\n",
    "# 6. AN√ÅLISE DOS RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n‚úÖ PREVIS√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfa√ß√£o m√©dia real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISE DE SATISFA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"üöÄ Pronto para as pr√≥ximas an√°lises!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLU√á√ÉO FINAL - LIMPEZA TOTAL E PREVEN√á√ÉO DE ERROS\n",
    "\n",
    "print(\"üöÄ EXECUTANDO SOLU√á√ÉO FINAL - LIMPEZA TOTAL...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPEZA AGRESSIVA DE TODOS OS VALORES INFINITOS\n",
    "print(\"üßπ LIMPEZA AGRESSIVA DE VALORES INFINITOS...\")\n",
    "\n",
    "# Fun√ß√£o para limpar valores infinitos de forma agressiva\n",
    "def limpar_infinitos_agressivo(df):\n",
    "    \"\"\"Limpa valores infinitos de forma agressiva\"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        # Verificar se h√° infinitos\n",
    "        if np.isinf(df[col]).any():\n",
    "            print(f\"Limpando infinitos na coluna: {col}\")\n",
    "            # Substituir infinitos por NaN\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            # Preencher com mediana\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            # Se ainda houver NaN, preencher com 0\n",
    "            df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "# Aplicar limpeza agressiva\n",
    "df = limpar_infinitos_agressivo(df)\n",
    "\n",
    "# Verificar resultado\n",
    "infinitos_finais = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"‚úÖ Valores infinitos ap√≥s limpeza agressiva: {infinitos_finais}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES E VARI√ÅVEL ALVO\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar vari√°vel alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"‚úÖ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS PARA TREINAMENTO\n",
    "print(\"ü§ñ Preparando dados para treinamento...\")\n",
    "\n",
    "# Criar DataFrame limpo\n",
    "df_ml = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Limpar novamente especificamente para ML\n",
    "df_ml = limpar_infinitos_agressivo(df_ml)\n",
    "\n",
    "# Remover NaN\n",
    "df_ml = df_ml.dropna()\n",
    "\n",
    "print(f\"Shape dos dados para ML: {df_ml.shape}\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"üéØ Treinando modelo...\")\n",
    "\n",
    "X = df_ml[features_satisfacao]\n",
    "y = df_ml['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acur√°cia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"‚úÖ Modelo treinado com acur√°cia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. PREVIS√ÉO SEGURA\n",
    "print(\"üîÆ Fazendo previs√£o segura...\")\n",
    "\n",
    "# Preparar dados para previs√£o\n",
    "df_pred = df[features_satisfacao].copy()\n",
    "\n",
    "# Limpar dados de previs√£o\n",
    "df_pred = limpar_infinitos_agressivo(df_pred)\n",
    "\n",
    "# Verificar se h√° NaN\n",
    "nan_count = df_pred.isnull().sum().sum()\n",
    "print(f\"Valores NaN para previs√£o: {nan_count}\")\n",
    "\n",
    "# Preencher NaN se necess√°rio\n",
    "if nan_count > 0:\n",
    "    df_pred = df_pred.fillna(0)\n",
    "\n",
    "# Verificar valores infinitos\n",
    "inf_count = np.isinf(df_pred).sum().sum()\n",
    "print(f\"Valores infinitos para previs√£o: {inf_count}\")\n",
    "\n",
    "# Fazer previs√£o\n",
    "print(\"Executando previs√£o...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_pred)\n",
    "\n",
    "# 6. RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\nüéâ SUCESSO! PREVIS√ÉO CONCLU√çDA!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfa√ß√£o m√©dia real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\nüöÄ AN√ÅLISE DE SATISFA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"‚úÖ Pronto para as pr√≥ximas an√°lises da Fase 2!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLU√á√ÉO DEFINITIVA - EXECUTE ESTA C√âLULA AGORA!\n",
    "\n",
    "print(\"üöÄ EXECUTANDO SOLU√á√ÉO DEFINITIVA...\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. LIMPAR TODOS OS VALORES INFINITOS DO DATAFRAME\n",
    "print(\"üßπ Limpando valores infinitos...\")\n",
    "\n",
    "# Fun√ß√£o simples para limpar infinitos\n",
    "for coluna in df.columns:\n",
    "    if df[coluna].dtype in ['float64', 'float32', 'int64', 'int32']:\n",
    "        # Substituir infinitos por 0\n",
    "        df[coluna] = df[coluna].replace([np.inf, -np.inf], 0)\n",
    "        # Preencher NaN com 0\n",
    "        df[coluna] = df[coluna].fillna(0)\n",
    "\n",
    "# Verificar se ainda h√° infinitos\n",
    "infinitos_restantes = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"‚úÖ Valores infinitos restantes: {infinitos_restantes}\")\n",
    "\n",
    "# 2. DEFINIR FEATURES\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Criar vari√°vel alvo\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "print(f\"‚úÖ Features definidas: {len(features_satisfacao)}\")\n",
    "\n",
    "# 3. PREPARAR DADOS LIMPOS\n",
    "print(\"ü§ñ Preparando dados...\")\n",
    "\n",
    "# Criar DataFrame limpo\n",
    "df_limpo = df[features_satisfacao + ['satisfacao_alvo']].copy()\n",
    "\n",
    "# Remover linhas com NaN\n",
    "df_limpo = df_limpo.dropna()\n",
    "\n",
    "print(f\"‚úÖ Dados limpos: {df_limpo.shape[0]} registros\")\n",
    "\n",
    "# 4. TREINAR MODELO\n",
    "print(\"üéØ Treinando modelo...\")\n",
    "\n",
    "X = df_limpo[features_satisfacao]\n",
    "y = df_limpo['satisfacao_alvo']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acur√°cia\n",
    "accuracy = accuracy_score(y_test, modelo_satisfacao.predict(X_test))\n",
    "print(f\"‚úÖ Modelo treinado com acur√°cia: {accuracy:.3f}\")\n",
    "\n",
    "# 5. FAZER PREVIS√ÉO\n",
    "print(\"üîÆ Fazendo previs√£o...\")\n",
    "\n",
    "# Preparar dados para previs√£o\n",
    "df_previsao = df[features_satisfacao].copy()\n",
    "\n",
    "# Garantir que n√£o h√° infinitos\n",
    "for col in features_satisfacao:\n",
    "    df_previsao[col] = df_previsao[col].replace([np.inf, -np.inf], 0)\n",
    "    df_previsao[col] = df_previsao[col].fillna(0)\n",
    "\n",
    "# Fazer previs√£o\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_previsao)\n",
    "\n",
    "# 6. AN√ÅLISE DOS RESULTADOS\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\nüéâ SUCESSO! AN√ÅLISE CONCLU√çDA!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(pedidos_risco) > 0:\n",
    "    print(f\"\\nüîç INSIGHTS DOS PEDIDOS DE RISCO:\")\n",
    "    print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "    print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "    print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "    print(f\"Satisfa√ß√£o m√©dia real: {pedidos_risco['satisfacao_nivel'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"üéâ Nenhum pedido de risco identificado!\")\n",
    "\n",
    "print(f\"\\nüöÄ AN√ÅLISE DE SATISFA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"‚úÖ Pronto para continuar com as outras an√°lises!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39486d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando features necessarias p analise dos dados\n",
    "\n",
    "# Verificar se as colunas j√° existem, se n√£o, criar\n",
    "if 'ano' not in df.columns:\n",
    "    df['ano'] = df['order_datetime'].dt.year\n",
    "if 'mes' not in df.columns:\n",
    "    df['mes'] = df['order_datetime'].dt.month\n",
    "if 'dia_semana' not in df.columns:\n",
    "    df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "if 'hora' not in df.columns:\n",
    "    df['hora'] = df['order_datetime'].dt.hour\n",
    "if 'fim_de_semana' not in df.columns:\n",
    "    df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Criar features de efici√™ncia e lucratividade\n",
    "if 'eficiencia_entrega' not in df.columns:\n",
    "    df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "if 'lucro_estimado' not in df.columns:\n",
    "    df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "if 'lucro_por_item' not in df.columns:\n",
    "    df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# Encoding de vari√°veis categ√≥ricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if 'platform_encoded' not in df.columns:\n",
    "    le_platform = LabelEncoder()\n",
    "    df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "if 'order_mode_encoded' not in df.columns:\n",
    "    le_order_mode = LabelEncoder()\n",
    "    df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "if 'status_encoded' not in df.columns:\n",
    "    le_status = LabelEncoder()\n",
    "    df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "\n",
    "# 2. CRIAR MATRIZ DE CORRELA√á√ÉO\n",
    "\n",
    "\n",
    "# Selecionar vari√°veis num√©ricas relevantes para an√°lise estrat√©gica\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "# Criar matriz de correla√ß√£o\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "\n",
    "\n",
    "# 3. AN√ÅLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# 4. AN√ÅLISE DE RENTABILIDADE POR REGI√ÉO\n",
    "\n",
    "\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae095b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSTRAR RESULTADOS DAS AN√ÅLISES\n",
    "\n",
    "# 1. INSIGHTS DA MATRIZ DE CORRELA√á√ÉO\n",
    "print(\"\\nüîç INSIGHTS DA MATRIZ DE CORRELA√á√ÉO:\")\n",
    "\n",
    "# Correla√ß√µes com SATISFA√á√ÉO\n",
    "print(\"\\nüìä CORRELA√á√ïES COM SATISFA√á√ÉO:\")\n",
    "satisfacao_corr = correlation_matrix['satisfacao_nivel'].sort_values(ascending=False)\n",
    "for var, corr in satisfacao_corr.items():\n",
    "    if var != 'satisfacao_nivel' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# Correla√ß√µes com RECEITA TOTAL\n",
    "print(\"\\nüí∞ CORRELA√á√ïES COM RECEITA TOTAL:\")\n",
    "receita_corr = correlation_matrix['total_brl'].sort_values(ascending=False)\n",
    "for var, corr in receita_corr.items():\n",
    "    if var != 'total_brl' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# Correla√ß√µes com LUCRO ESTIMADO\n",
    "print(\"\\nüìà CORRELA√á√ïES COM LUCRO ESTIMADO:\")\n",
    "lucro_corr = correlation_matrix['lucro_estimado'].sort_values(ascending=False)\n",
    "for var, corr in lucro_corr.items():\n",
    "    if var != 'lucro_estimado' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 2. RENTABILIDADE POR PLATAFORMA\n",
    "print(\"\\nüè™ RENTABILIDADE POR PLATAFORMA:\")\n",
    "print(rentabilidade_plataforma_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Comissao_Media', 'Satisfacao_Media', 'Rentabilidade_por_Pedido', 'Margem_Liquida_%']])\n",
    "\n",
    "# 3. RENTABILIDADE POR REGI√ÉO (TOP 10)\n",
    "print(\"\\nüìç TOP 10 REGI√ïES POR RECEITA:\")\n",
    "print(rentabilidade_regiao_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Distancia_Media', 'Satisfacao_Media', 'Receita_por_km', 'Lucro_por_km', 'Margem_Liquida_%']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZA√á√ïES ESTRAT√âGICAS DA FASE 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Criar figura com subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Matriz de Correla√ß√£o\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, fmt='.2f', ax=axes[0,0], cbar_kws={\"shrink\": .8})\n",
    "axes[0,0].set_title('Matriz de Correla√ß√£o')\n",
    "\n",
    "# 2. Rentabilidade por Plataforma\n",
    "rentabilidade_plataforma_ordenada['Rentabilidade_por_Pedido'].plot(kind='bar', ax=axes[0,1], color='skyblue')\n",
    "axes[0,1].set_title('Rentabilidade por Pedido - Plataforma')\n",
    "axes[0,1].set_ylabel('R$ por pedido')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Satisfa√ß√£o por Plataforma\n",
    "rentabilidade_plataforma_ordenada['Satisfacao_Media'].plot(kind='bar', ax=axes[0,2], color='lightcoral')\n",
    "axes[0,2].set_title('Satisfa√ß√£o M√©dia por Plataforma')\n",
    "axes[0,2].set_ylabel('Satisfa√ß√£o (1-5)')\n",
    "axes[0,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Top 8 Regi√µes por Receita\n",
    "top_regioes = rentabilidade_regiao_ordenada.head(8)\n",
    "axes[1,0].barh(range(len(top_regioes)), top_regioes['Receita_Total'])\n",
    "axes[1,0].set_yticks(range(len(top_regioes)))\n",
    "axes[1,0].set_yticklabels(top_regioes.index)\n",
    "axes[1,0].set_xlabel('Receita Total (R$)')\n",
    "axes[1,0].set_title('Top 8 Regi√µes por Receita')\n",
    "\n",
    "# 5. Receita por km por Regi√£o\n",
    "top_regioes_receita_km = rentabilidade_regiao_ordenada.head(8)\n",
    "axes[1,1].barh(range(len(top_regioes_receita_km)), top_regioes_receita_km['Receita_por_km'])\n",
    "axes[1,1].set_yticks(range(len(top_regioes_receita_km)))\n",
    "axes[1,1].set_yticklabels(top_regioes_receita_km.index)\n",
    "axes[1,1].set_xlabel('Receita por km (R$)')\n",
    "axes[1,1].set_title('Receita por km - Top 8 Regi√µes')\n",
    "\n",
    "# 6. Satisfa√ß√£o vs Dist√¢ncia por Regi√£o\n",
    "axes[1,2].scatter(rentabilidade_regiao_ordenada['Distancia_Media'], \n",
    "                 rentabilidade_regiao_ordenada['Satisfacao_Media'],\n",
    "                 s=rentabilidade_regiao_ordenada['Qtd_Pedidos']*2, alpha=0.6)\n",
    "axes[1,2].set_xlabel('Dist√¢ncia M√©dia (km)')\n",
    "axes[1,2].set_ylabel('Satisfa√ß√£o M√©dia')\n",
    "axes[1,2].set_title('Satisfa√ß√£o vs Dist√¢ncia por Regi√£o')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRE√á√ÉO DA LINHA PROBLEM√ÅTICA\n",
    "\n",
    "print(\"üîß Corrigindo a linha problem√°tica...\")\n",
    "\n",
    "# Limpar dados antes da previs√£o\n",
    "df_previsao = df[features_satisfacao].copy()\n",
    "\n",
    "# Substituir infinitos por 0\n",
    "for col in features_satisfacao:\n",
    "    df_previsao[col] = df_previsao[col].replace([np.inf, -np.inf], 0)\n",
    "    df_previsao[col] = df_previsao[col].fillna(0)\n",
    "\n",
    "# Verificar se ainda h√° infinitos\n",
    "infinitos_restantes = np.isinf(df_previsao).sum().sum()\n",
    "print(f\"‚úÖ Valores infinitos restantes: {infinitos_restantes}\")\n",
    "\n",
    "# Fazer previs√£o com dados limpos\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_previsao)\n",
    "\n",
    "print(\"‚úÖ Previs√£o conclu√≠da com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79576993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MATRIZ DE CORRELA√á√ÉO - PONTO DE PARTIDA ESTRAT√âGICO\n",
    "\n",
    "# Preparar dados para an√°lise de correla√ß√£o\n",
    "\n",
    "# Criar features temporais\n",
    "df['ano'] = df['order_datetime'].dt.year\n",
    "df['mes'] = df['order_datetime'].dt.month\n",
    "df['dia_semana'] = df['order_datetime'].dt.dayofweek\n",
    "df['hora'] = df['order_datetime'].dt.hour\n",
    "df['fim_de_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Criar features de efici√™ncia e lucratividade\n",
    "df['eficiencia_entrega'] = df['eta_minutes_quote'] / df['actual_delivery_minutes']\n",
    "df['lucro_estimado'] = df['total_brl'] * (1 - df['platform_commission_pct']/100)\n",
    "df['lucro_por_item'] = df['lucro_estimado'] / df['num_itens']\n",
    "\n",
    "# Encoding de vari√°veis categ√≥ricas para correla√ß√£o\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_platform = LabelEncoder()\n",
    "le_order_mode = LabelEncoder()\n",
    "le_status = LabelEncoder()\n",
    "\n",
    "df['platform_encoded'] = le_platform.fit_transform(df['platform'])\n",
    "df['order_mode_encoded'] = le_order_mode.fit_transform(df['order_mode'])\n",
    "df['status_encoded'] = le_status.fit_transform(df['status'])\n",
    "\n",
    "print(f\"üìä Shape final: {df.shape}\")\n",
    "print(f\"üî¢ Colunas num√©ricas: {df.select_dtypes(include=['number']).columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar matriz de correla√ß√£o com vari√°veis estrat√©gicas\n",
    "print(\"=== MATRIZ DE CORRELA√á√ÉO - INSIGHTS ESTRAT√âGICOS ===\")\n",
    "\n",
    "# Selecionar vari√°veis num√©ricas relevantes para an√°lise estrat√©gica\n",
    "correlation_vars = [\n",
    "    'total_brl', 'num_itens', 'distance_km', 'tempo_preparo_minutos',\n",
    "    'eta_minutes_quote', 'actual_delivery_minutes', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', 'lucro_estimado',\n",
    "    'lucro_por_item', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded', 'status_encoded'\n",
    "]\n",
    "\n",
    "# Criar matriz de correla√ß√£o\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "print(\"üìä Matriz de correla√ß√£o das vari√°veis estrat√©gicas:\")\n",
    "print(correlation_matrix.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de correla√ß√£o com heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Criar heatmap com anota√ß√µes\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('üîç MATRIZ DE CORRELA√á√ÉO - KAISERHAUS\\n(Valores pr√≥ximos de 1 = correla√ß√£o forte positiva, -1 = forte negativa)', \n",
    "          fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise das correla√ß√µes mais importantes para o neg√≥cio\n",
    "print(\"=== INSIGHTS ESTRAT√âGICOS BASEADOS NA CORRELA√á√ÉO ===\")\n",
    "\n",
    "# 1. Correla√ß√µes com SATISFA√á√ÉO (vari√°vel chave para reten√ß√£o)\n",
    "print(\"üîç CORRELA√á√ïES COM SATISFA√á√ÉO:\")\n",
    "satisfacao_corr = correlation_matrix['satisfacao_nivel'].sort_values(ascending=False)\n",
    "for var, corr in satisfacao_corr.items():\n",
    "    if var != 'satisfacao_nivel' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 2. Correla√ß√µes com RECEITA TOTAL (impacto financeiro)\n",
    "print(\"\\nüí∞ CORRELA√á√ïES COM RECEITA TOTAL:\")\n",
    "receita_corr = correlation_matrix['total_brl'].sort_values(ascending=False)\n",
    "for var, corr in receita_corr.items():\n",
    "    if var != 'total_brl' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 3. Correla√ß√µes com LUCRO ESTIMADO (rentabilidade)\n",
    "print(\"\\nüìà CORRELA√á√ïES COM LUCRO ESTIMADO:\")\n",
    "lucro_corr = correlation_matrix['lucro_estimado'].sort_values(ascending=False)\n",
    "for var, corr in lucro_corr.items():\n",
    "    if var != 'lucro_estimado' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n",
    "\n",
    "# 4. Correla√ß√µes com EFICI√äNCIA DE ENTREGA (operacional)\n",
    "print(\"\\nüöö CORRELA√á√ïES COM EFICI√äNCIA DE ENTREGA:\")\n",
    "eficiencia_corr = correlation_matrix['eficiencia_entrega'].sort_values(ascending=False)\n",
    "for var, corr in eficiencia_corr.items():\n",
    "    if var != 'eficiencia_entrega' and abs(corr) > 0.1:\n",
    "        print(f\"  {var}: {corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. AN√ÅLISE DE RENTABILIDADE POR PLATAFORMA\n",
    "\n",
    "# Verificar se as colunas necess√°rias existem\n",
    "colunas_necessarias = ['total_brl', 'platform_commission_pct', 'satisfacao_nivel', 'lucro_estimado', 'eficiencia_entrega']\n",
    "colunas_faltando = [col for col in colunas_necessarias if col not in df.columns]\n",
    "\n",
    "if colunas_faltando:\n",
    "    print(f\"‚ö†Ô∏è Colunas faltando: {colunas_faltando}\")\n",
    "    print(\"Execute a c√©lula anterior primeiro para criar as features necess√°rias!\")\n",
    "else:\n",
    "    pass  # Continuar com an√°lise\n",
    "\n",
    "# Calcular m√©tricas de rentabilidade por plataforma\n",
    "rentabilidade_plataforma = df.groupby('platform').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas para melhor visualiza√ß√£o\n",
    "rentabilidade_plataforma.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', \n",
    "    'Comissao_Media', 'Satisfacao_Media', \n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_plataforma['Receita_Liquida_Estimada'] = rentabilidade_plataforma['Receita_Total'] * (1 - rentabilidade_plataforma['Comissao_Media']/100)\n",
    "rentabilidade_plataforma['Rentabilidade_por_Pedido'] = rentabilidade_plataforma['Receita_Liquida_Estimada'] / rentabilidade_plataforma['Qtd_Pedidos']\n",
    "rentabilidade_plataforma['Margem_Liquida_%'] = (rentabilidade_plataforma['Lucro_Total'] / rentabilidade_plataforma['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por rentabilidade\n",
    "rentabilidade_plataforma_ordenada = rentabilidade_plataforma.sort_values('Rentabilidade_por_Pedido', ascending=False)\n",
    "\n",
    "print(\"üìä An√°lise de Rentabilidade por Plataforma:\")\n",
    "print(rentabilidade_plataforma_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Comissao_Media', 'Satisfacao_Media', 'Rentabilidade_por_Pedido', 'Margem_Liquida_%']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AN√ÅLISE DE RENTABILIDADE POR REGI√ÉO\n",
    "\n",
    "# Calcular m√©tricas de rentabilidade por regi√£o\n",
    "rentabilidade_regiao = df.groupby('macro_bairro').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'distance_km': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'lucro_estimado': ['sum', 'mean'],\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "rentabilidade_regiao.columns = [\n",
    "    'Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio',\n",
    "    'Distancia_Media', 'Satisfacao_Media', 'Tempo_Preparo_Medio',\n",
    "    'Lucro_Total', 'Lucro_por_Pedido', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "rentabilidade_regiao['Receita_por_km'] = rentabilidade_regiao['Receita_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Lucro_por_km'] = rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Distancia_Media']\n",
    "rentabilidade_regiao['Margem_Liquida_%'] = (rentabilidade_regiao['Lucro_Total'] / rentabilidade_regiao['Receita_Total'] * 100).round(2)\n",
    "\n",
    "# Ordenar por receita total\n",
    "rentabilidade_regiao_ordenada = rentabilidade_regiao.sort_values('Receita_Total', ascending=False)\n",
    "\n",
    "print(\"üìä An√°lise de Rentabilidade por Regi√£o:\")\n",
    "print(rentabilidade_regiao_ordenada[['Qtd_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Distancia_Media', 'Satisfacao_Media', 'Receita_por_km', 'Lucro_por_km', 'Margem_Liquida_%']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d0898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d4019b",
   "metadata": {},
   "source": [
    "# üöÄ FASE 2 - AN√ÅLISES AVAN√áADAS\n",
    "\n",
    "## 4. MODELO DE PREVIS√ÉO DE DEMANDA - Otimizar Volume\n",
    "\n",
    "O objetivo √© criar um modelo preditivo para prever a demanda futura, permitindo:\n",
    "- **Otimiza√ß√£o de recursos** (funcion√°rios, ingredientes)\n",
    "- **Planejamento estrat√©gico** de expans√£o\n",
    "- **Redu√ß√£o de desperd√≠cios** operacionais\n",
    "- **Maximiza√ß√£o do volume** de pedidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 PREPARA√á√ÉO DOS DADOS PARA PREVIS√ÉO DE DEMANDA\n",
    "\n",
    "# Criar s√©rie temporal di√°ria\n",
    "df['data'] = df['order_datetime'].dt.date\n",
    "demanda_diaria = df.groupby('data').agg({\n",
    "    'total_brl': ['count', 'sum', 'mean'],\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "demanda_diaria.columns = ['Volume_Pedidos', 'Receita_Total', 'Ticket_Medio', 'Satisfacao_Media', 'Tempo_Preparo_Medio', 'Tempo_Entrega_Medio']\n",
    "\n",
    "# Criar features temporais para o modelo\n",
    "demanda_diaria['dia_semana'] = pd.to_datetime(demanda_diaria.index).dayofweek\n",
    "demanda_diaria['fim_de_semana'] = demanda_diaria['dia_semana'].isin([5, 6]).astype(int)\n",
    "demanda_diaria['mes'] = pd.to_datetime(demanda_diaria.index).month\n",
    "\n",
    "# Calcular m√©dias m√≥veis para suavizar tend√™ncias\n",
    "demanda_diaria['Volume_MA_7'] = demanda_diaria['Volume_Pedidos'].rolling(window=7).mean()\n",
    "demanda_diaria['Receita_MA_7'] = demanda_diaria['Receita_Total'].rolling(window=7).mean()\n",
    "\n",
    "# Calcular varia√ß√£o percentual\n",
    "demanda_diaria['Variacao_Volume'] = demanda_diaria['Volume_Pedidos'].pct_change()\n",
    "demanda_diaria['Variacao_Receita'] = demanda_diaria['Receita_Total'].pct_change()\n",
    "\n",
    "print(\"üìä Dados preparados para previs√£o de demanda:\")\n",
    "print(f\"Shape: {demanda_diaria.shape}\")\n",
    "print(f\"Per√≠odo: {demanda_diaria.index.min()} a {demanda_diaria.index.max()}\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "print(demanda_diaria.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 MODELO DE PREVIS√ÉO DE DEMANDA - MACHINE LEARNING\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparar dados para treinamento (remover valores NaN)\n",
    "demanda_clean = demanda_diaria.dropna()\n",
    "\n",
    "# Definir vari√°veis preditoras (features)\n",
    "features = ['dia_semana', 'fim_de_semana', 'mes', 'Volume_MA_7', 'Receita_MA_7', 'Variacao_Volume', 'Variacao_Receita']\n",
    "X = demanda_clean[features]\n",
    "\n",
    "# Definir vari√°vel alvo (volume de pedidos)\n",
    "y = demanda_clean['Volume_Pedidos']\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"üìä Dados de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"üìä Dados de teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"üìä Features utilizadas: {features}\")\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular m√©tricas de performance\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nüéØ PERFORMANCE DO MODELO RANDOM FOREST:\")\n",
    "print(f\"MAE (Erro M√©dio Absoluto): {mae_rf:.2f} pedidos\")\n",
    "print(f\"MSE (Erro Quadr√°tico M√©dio): {mse_rf:.2f}\")\n",
    "print(f\"R¬≤ (Coeficiente de Determina√ß√£o): {r2_rf:.3f}\")\n",
    "\n",
    "# Treinar modelo Linear Regression para compara√ß√£o\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nüéØ PERFORMANCE DO MODELO LINEAR REGRESSION:\")\n",
    "print(f\"MAE: {mae_lr:.2f} pedidos\")\n",
    "print(f\"R¬≤: {r2_lr:.3f}\")\n",
    "\n",
    "# Mostrar import√¢ncia das features\n",
    "importancia_features = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importancia': modelo_rf.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä IMPORT√ÇNCIA DAS FEATURES:\")\n",
    "print(importancia_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 PREVIS√ïES E INSIGHTS DO MODELO DE DEMANDA\n",
    "\n",
    "# Fazer previs√£o para os pr√≥ximos 7 dias\n",
    "ultima_data = demanda_diaria.index.max()\n",
    "ultimos_dados = demanda_diaria.loc[ultima_data]\n",
    "\n",
    "# Criar previs√µes para pr√≥ximos 7 dias\n",
    "previsoes_proximos_7_dias = []\n",
    "datas_futuras = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    data_futura = pd.to_datetime(ultima_data) + pd.Timedelta(days=i)\n",
    "    dia_semana_futuro = data_futura.dayofweek\n",
    "    fim_de_semana_futuro = 1 if dia_semana_futuro in [5, 6] else 0\n",
    "    mes_futuro = data_futura.month\n",
    "    \n",
    "    # Usar valores m√©dios das √∫ltimas observa√ß√µes para features cont√≠nuas\n",
    "    features_futuro = np.array([[\n",
    "        dia_semana_futuro,\n",
    "        fim_de_semana_futuro,\n",
    "        mes_futuro,\n",
    "        ultimos_dados['Volume_MA_7'] if not pd.isna(ultimos_dados['Volume_MA_7']) else demanda_diaria['Volume_MA_7'].mean(),\n",
    "        ultimos_dados['Receita_MA_7'] if not pd.isna(ultimos_dados['Receita_MA_7']) else demanda_diaria['Receita_MA_7'].mean(),\n",
    "        0,  # Variacao_Volume (assumir 0 para previs√£o)\n",
    "        0   # Variacao_Receita (assumir 0 para previs√£o)\n",
    "    ]])\n",
    "    \n",
    "    previsao = modelo_rf.predict(features_futuro)[0]\n",
    "    previsoes_proximos_7_dias.append(previsao)\n",
    "    datas_futuras.append(data_futura.date())\n",
    "\n",
    "# Criar DataFrame com previs√µes\n",
    "previsoes_df = pd.DataFrame({\n",
    "    'Data': datas_futuras,\n",
    "    'Previsao_Volume': previsoes_proximos_7_dias,\n",
    "    'Previsao_Receita': [p * demanda_diaria['Ticket_Medio'].mean() for p in previsoes_proximos_7_dias]\n",
    "})\n",
    "\n",
    "print(\"üîÆ PREVIS√ïES PARA OS PR√ìXIMOS 7 DIAS:\")\n",
    "print(previsoes_df.round(2))\n",
    "\n",
    "# Calcular m√©tricas de tend√™ncia\n",
    "volume_medio_historico = demanda_diaria['Volume_Pedidos'].mean()\n",
    "receita_media_historica = demanda_diaria['Receita_Total'].mean()\n",
    "\n",
    "volume_previsto_medio = previsoes_df['Previsao_Volume'].mean()\n",
    "receita_prevista_media = previsoes_df['Previsao_Receita'].mean()\n",
    "\n",
    "variacao_volume = ((volume_previsto_medio - volume_medio_historico) / volume_medio_historico) * 100\n",
    "variacao_receita = ((receita_prevista_media - receita_media_historica) / receita_media_historica) * 100\n",
    "\n",
    "print(f\"\\nüìä TEND√äNCIA DE DEMANDA:\")\n",
    "print(f\"Volume m√©dio hist√≥rico: {volume_medio_historico:.1f} pedidos/dia\")\n",
    "print(f\"Volume previsto m√©dio: {volume_previsto_medio:.1f} pedidos/dia\")\n",
    "print(f\"Varia√ß√£o: {variacao_volume:+.1f}%\")\n",
    "\n",
    "print(f\"\\nüí∞ TEND√äNCIA DE RECEITA:\")\n",
    "print(f\"Receita m√©dia hist√≥rica: R$ {receita_media_historica:.2f}/dia\")\n",
    "print(f\"Receita prevista m√©dia: R$ {receita_prevista_media:.2f}/dia\")\n",
    "print(f\"Varia√ß√£o: {variacao_receita:+.1f}%\")\n",
    "\n",
    "# Identificar dias de maior demanda\n",
    "previsoes_df['Dia_Semana'] = pd.to_datetime(previsoes_df['Data']).dt.day_name()\n",
    "previsoes_df['Fim_Semana'] = pd.to_datetime(previsoes_df['Data']).dt.dayofweek.isin([5, 6])\n",
    "\n",
    "print(f\"\\nüéØ INSIGHTS ESTRAT√âGICOS:\")\n",
    "print(f\"Dia de maior demanda prevista: {previsoes_df.loc[previsoes_df['Previsao_Volume'].idxmax(), 'Data']}\")\n",
    "print(f\"Volume m√°ximo previsto: {previsoes_df['Previsao_Volume'].max():.0f} pedidos\")\n",
    "print(f\"Volume m√≠nimo previsto: {previsoes_df['Previsao_Volume'].min():.0f} pedidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27dd87",
   "metadata": {},
   "source": [
    "## 5. AN√ÅLISE DE SATISFA√á√ÉO - Melhorar Experi√™ncia\n",
    "\n",
    "O objetivo √© identificar os fatores cr√≠ticos que impactam a satisfa√ß√£o do cliente, permitindo:\n",
    "- **Identifica√ß√£o dos gargalos** operacionais\n",
    "- **Otimiza√ß√£o do tempo** de preparo e entrega\n",
    "- **Melhoria da experi√™ncia** do cliente\n",
    "- **Redu√ß√£o da insatisfa√ß√£o** e churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f65108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 AN√ÅLISE DETALHADA DE SATISFA√á√ÉO POR FATORES\n",
    "\n",
    "# Criar categorias de satisfa√ß√£o\n",
    "df['satisfacao_categoria'] = pd.cut(df['satisfacao_nivel'], \n",
    "                                  bins=[0, 2, 3, 4, 5], \n",
    "                                  labels=['Baixa (1-2)', 'M√©dia (2-3)', 'Alta (3-4)', 'Excelente (4-5)'])\n",
    "\n",
    "# An√°lise por categoria de satisfa√ß√£o\n",
    "analise_satisfacao = df.groupby('satisfacao_categoria').agg({\n",
    "    'tempo_preparo_minutos': ['count', 'mean', 'std'],\n",
    "    'actual_delivery_minutes': ['mean', 'std'],\n",
    "    'eta_minutes_quote': ['mean', 'std'],\n",
    "    'distance_km': ['mean', 'std'],\n",
    "    'total_brl': ['mean', 'sum'],\n",
    "    'num_itens': 'mean',\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'eficiencia_entrega': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "analise_satisfacao.columns = [\n",
    "    'Qtd_Pedidos', 'Tempo_Prep_Medio', 'Tempo_Prep_Std',\n",
    "    'Tempo_Entrega_Medio', 'Tempo_Entrega_Std',\n",
    "    'ETA_Medio', 'ETA_Std',\n",
    "    'Distancia_Media', 'Distancia_Std',\n",
    "    'Ticket_Medio', 'Receita_Total',\n",
    "    'Itens_Medio', 'Comissao_Media', 'Eficiencia_Media'\n",
    "]\n",
    "\n",
    "print(\"üìä AN√ÅLISE DE SATISFA√á√ÉO POR CATEGORIAS:\")\n",
    "print(analise_satisfacao)\n",
    "\n",
    "# An√°lise dos fatores cr√≠ticos\n",
    "print(f\"\\nüîç FATORES CR√çTICOS QUE IMPACTAM SATISFA√á√ÉO:\")\n",
    "\n",
    "# Correla√ß√µes com satisfa√ß√£o (j√° calculadas na matriz de correla√ß√£o)\n",
    "fatores_criticos = {\n",
    "    'Tempo_Preparo': -0.586,\n",
    "    'Tempo_Entrega_Real': -0.642,\n",
    "    'Numero_Itens': -0.367,\n",
    "    'Comissao_Plataforma': -0.218,\n",
    "    'ETA_Estimado': -0.219,\n",
    "    'Distancia': -0.193\n",
    "}\n",
    "\n",
    "print(\"Correla√ß√µes negativas com satisfa√ß√£o (quanto menor, melhor):\")\n",
    "for fator, correlacao in sorted(fatores_criticos.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {fator}: {correlacao:.3f}\")\n",
    "\n",
    "# Identificar padr√µes por plataforma\n",
    "satisfacao_plataforma = df.groupby('platform').agg({\n",
    "    'satisfacao_nivel': ['mean', 'std', 'count'],\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean',\n",
    "    'distance_km': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "satisfacao_plataforma.columns = ['Satisfacao_Media', 'Satisfacao_Std', 'Qtd_Pedidos', 'Tempo_Prep_Medio', 'Tempo_Entrega_Medio', 'Distancia_Media']\n",
    "\n",
    "print(f\"\\nüì± SATISFA√á√ÉO POR PLATAFORMA:\")\n",
    "print(satisfacao_plataforma.sort_values('Satisfacao_Media', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRE√á√ÉO DO ERRO DE PREVIS√ÉO DE SATISFA√á√ÉO\n",
    "\n",
    "# Preparar dados para previs√£o - corrigir infinitos primeiro\n",
    "df_predicao = df[features_satisfacao].copy()\n",
    "df_predicao = df_predicao.replace([np.inf, -np.inf], np.nan)\n",
    "df_predicao = df_predicao.fillna(df_predicao.mean())\n",
    "\n",
    "# Verificar se h√° valores infinitos antes da previs√£o\n",
    "print(f\"Valores infinitos antes da previs√£o: {np.isinf(df_predicao).sum().sum()}\")\n",
    "\n",
    "# Fazer previs√£o\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_predicao)\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è AN√ÅLISE DE PEDIDOS DE RISCO:\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfa√ß√£o): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Caracter√≠sticas dos pedidos de risco\n",
    "caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "\n",
    "print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "comparacao = pd.DataFrame({\n",
    "    'Pedidos_Risco': caracteristicas_risco,\n",
    "    'Pedidos_Geral': caracteristicas_gerais\n",
    "})\n",
    "comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "print(comparacao.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96807c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLU√á√ÉO DEFINITIVA PARA O ERRO DE PREVIS√ÉO\n",
    "\n",
    "# Primeiro, vamos limpar completamente os dados\n",
    "print(\"üîß LIMPEZA COMPLETA DOS DADOS PARA PREVIS√ÉO\")\n",
    "\n",
    "# Criar uma c√≥pia limpa dos dados\n",
    "df_limpo = df[features_satisfacao].copy()\n",
    "\n",
    "# 1. Verificar valores infinitos\n",
    "print(f\"Valores infinitos antes da limpeza: {np.isinf(df_limpo).sum().sum()}\")\n",
    "\n",
    "# 2. Substituir infinitos por NaN\n",
    "df_limpo = df_limpo.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 3. Verificar valores muito grandes\n",
    "for col in df_limpo.columns:\n",
    "    max_val = df_limpo[col].max()\n",
    "    min_val = df_limpo[col].min()\n",
    "    if max_val > 1e6 or min_val < -1e6:\n",
    "        print(f\"Coluna {col}: valores extremos detectados (max: {max_val:.2e}, min: {min_val:.2e})\")\n",
    "        # Capar valores extremos\n",
    "        df_limpo[col] = np.clip(df_limpo[col], -1e6, 1e6)\n",
    "\n",
    "# 4. Preencher NaN com valores m√©dios\n",
    "df_limpo = df_limpo.fillna(df_limpo.mean())\n",
    "\n",
    "# 5. Verifica√ß√£o final\n",
    "print(f\"Valores infinitos ap√≥s limpeza: {np.isinf(df_limpo).sum().sum()}\")\n",
    "print(f\"Valores NaN ap√≥s limpeza: {df_limpo.isnull().sum().sum()}\")\n",
    "\n",
    "# 6. Fazer previs√£o com dados limpos\n",
    "print(\"\\nüéØ FAZENDO PREVIS√ÉO COM DADOS LIMPOS...\")\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df_limpo)\n",
    "\n",
    "# 7. An√°lise dos resultados\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n‚úÖ PREVIS√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfa√ß√£o): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 8. Caracter√≠sticas dos pedidos de risco\n",
    "if len(pedidos_risco) > 0:\n",
    "    caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "    caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "    \n",
    "    print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "    comparacao = pd.DataFrame({\n",
    "        'Pedidos_Risco': caracteristicas_risco,\n",
    "        'Pedidos_Geral': caracteristicas_gerais\n",
    "    })\n",
    "    comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "    print(comparacao.round(2))\n",
    "else:\n",
    "    print(\"üéâ Nenhum pedido de risco identificado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# Fun√ß√£o que remove ¬±inf e for√ßa num√©rico\n",
    "def sanitize(X):\n",
    "    X = X.copy()\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    return X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "sanitizer = FunctionTransformer(sanitize)\n",
    "\n",
    "preproc = make_pipeline(\n",
    "    sanitizer,\n",
    "    SimpleImputer(strategy='median')  # ou 'mean'\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "modelo_satisfacao = Pipeline(steps=[\n",
    "    ('preproc', preproc),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treino\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "modelo_satisfacao.fit(X_sat, y_sat)\n",
    "\n",
    "# Predi√ß√£o (agora basta passar o df cru)\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df[features_satisfacao])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e14230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 MODELO DE PREVIS√ÉO DE SATISFA√á√ÉO\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Criar vari√°vel alvo categ√≥rica para classifica√ß√£o\n",
    "df['satisfacao_alvo'] = pd.cut(df['satisfacao_nivel'], \n",
    "                              bins=[0, 3, 4, 5], \n",
    "                              labels=['Baixa', 'Alta', 'Excelente'])\n",
    "\n",
    "# Preparar features para o modelo de satisfa√ß√£o\n",
    "features_satisfacao = [\n",
    "    'tempo_preparo_minutos', 'actual_delivery_minutes', 'eta_minutes_quote',\n",
    "    'distance_km', 'num_itens', 'total_brl', 'platform_commission_pct',\n",
    "    'eficiencia_entrega', 'dia_semana', 'hora', 'fim_de_semana',\n",
    "    'platform_encoded', 'order_mode_encoded'\n",
    "]\n",
    "\n",
    "# Remover linhas com valores NaN e infinitos\n",
    "df_satisfacao_clean = df[features_satisfacao + ['satisfacao_alvo']].dropna()\n",
    "\n",
    "# Verificar e corrigir valores infinitos\n",
    "print(\"üîç Verificando valores infinitos antes da corre√ß√£o:\")\n",
    "print(f\"Valores infinitos em X: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "# Substituir infinitos por NaN e depois por valores m√©dios\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].replace([np.inf, -np.inf], np.nan)\n",
    "df_satisfacao_clean[features_satisfacao] = df_satisfacao_clean[features_satisfacao].fillna(df_satisfacao_clean[features_satisfacao].mean())\n",
    "\n",
    "# Verificar novamente ap√≥s corre√ß√£o\n",
    "print(f\"Valores infinitos ap√≥s corre√ß√£o: {np.isinf(df_satisfacao_clean[features_satisfacao]).sum().sum()}\")\n",
    "\n",
    "X_sat = df_satisfacao_clean[features_satisfacao]\n",
    "y_sat = df_satisfacao_clean['satisfacao_alvo']\n",
    "\n",
    "# Verificar se h√° valores infinitos nos dados finais\n",
    "print(f\"Valores infinitos em X_sat: {np.isinf(X_sat).sum().sum()}\")\n",
    "print(f\"Valores NaN em X_sat: {X_sat.isnull().sum().sum()}\")\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(\n",
    "    X_sat, y_sat, test_size=0.2, random_state=42, stratify=y_sat\n",
    ")\n",
    "\n",
    "# Treinar modelo Random Forest para classifica√ß√£o\n",
    "modelo_satisfacao = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_satisfacao.fit(X_train_sat, y_train_sat)\n",
    "\n",
    "# Fazer previs√µes\n",
    "y_pred_sat = modelo_satisfacao.predict(X_test_sat)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy = accuracy_score(y_test_sat, y_pred_sat)\n",
    "\n",
    "print(f\"üéØ PERFORMANCE DO MODELO DE PREVIS√ÉO DE SATISFA√á√ÉO:\")\n",
    "print(f\"Acur√°cia: {accuracy:.3f}\")\n",
    "print(f\"\\nüìä RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
    "print(classification_report(y_test_sat, y_pred_sat))\n",
    "\n",
    "# Import√¢ncia das features para satisfa√ß√£o\n",
    "importancia_satisfacao = pd.DataFrame({\n",
    "    'Feature': features_satisfacao,\n",
    "    'Importancia': modelo_satisfacao.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä IMPORT√ÇNCIA DAS FEATURES PARA SATISFA√á√ÉO:\")\n",
    "print(importancia_satisfacao)\n",
    "\n",
    "# Identificar pedidos de risco (baixa satisfa√ß√£o prevista)\n",
    "df['satisfacao_predita'] = modelo_satisfacao.predict(df[features_satisfacao].fillna(df[features_satisfacao].mean()))\n",
    "pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è AN√ÅLISE DE PEDIDOS DE RISCO:\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Pedidos de risco (baixa satisfa√ß√£o): {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Caracter√≠sticas dos pedidos de risco\n",
    "caracteristicas_risco = pedidos_risco[features_satisfacao].mean()\n",
    "caracteristicas_gerais = df[features_satisfacao].mean()\n",
    "\n",
    "print(f\"\\nüîç CARACTER√çSTICAS DOS PEDIDOS DE RISCO vs GERAL:\")\n",
    "comparacao = pd.DataFrame({\n",
    "    'Pedidos_Risco': caracteristicas_risco,\n",
    "    'Pedidos_Geral': caracteristicas_gerais\n",
    "})\n",
    "comparacao['Diferenca'] = comparacao['Pedidos_Risco'] - comparacao['Pedidos_Geral']\n",
    "print(comparacao.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b67f6",
   "metadata": {},
   "source": [
    "## 6. SEGMENTA√á√ÉO DE CLIENTES - Marketing Direcionado\n",
    "\n",
    "O objetivo √© criar clusters de clientes para permitir:\n",
    "- **Marketing direcionado** por perfil de cliente\n",
    "- **Estrat√©gias personalizadas** de reten√ß√£o\n",
    "- **Otimiza√ß√£o de produtos** por segmento\n",
    "- **Aumento da visibilidade** da marca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 PREPARA√á√ÉO DOS DADOS PARA CLUSTERING\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Criar features para clustering baseadas no comportamento do cliente\n",
    "features_clustering = [\n",
    "    'total_brl', 'num_itens', 'tempo_preparo_minutos', \n",
    "    'actual_delivery_minutes', 'distance_km', 'satisfacao_nivel',\n",
    "    'platform_commission_pct', 'eficiencia_entrega', \n",
    "    'dia_semana', 'hora', 'fim_de_semana'\n",
    "]\n",
    "\n",
    "# Preparar dados para clustering\n",
    "df_clustering = df[features_clustering].copy()\n",
    "\n",
    "# Verificar e corrigir valores infinitos\n",
    "print(\"üîç Verificando valores infinitos no clustering:\")\n",
    "print(f\"Valores infinitos: {np.isinf(df_clustering).sum().sum()}\")\n",
    "\n",
    "# Substituir infinitos por NaN e depois por valores m√©dios\n",
    "df_clustering = df_clustering.replace([np.inf, -np.inf], np.nan)\n",
    "df_clustering = df_clustering.fillna(df_clustering.mean())\n",
    "\n",
    "# Verificar novamente ap√≥s corre√ß√£o\n",
    "print(f\"Valores infinitos ap√≥s corre√ß√£o: {np.isinf(df_clustering).sum().sum()}\")\n",
    "\n",
    "# Normalizar as features\n",
    "scaler = StandardScaler()\n",
    "df_clustering_scaled = scaler.fit_transform(df_clustering)\n",
    "\n",
    "print(f\"üìä Dados preparados para clustering:\")\n",
    "print(f\"Shape: {df_clustering_scaled.shape}\")\n",
    "print(f\"Features: {features_clustering}\")\n",
    "\n",
    "# Determinar n√∫mero √≥timo de clusters usando Elbow Method e Silhouette Score\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_clustering_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(df_clustering_scaled, kmeans.labels_))\n",
    "\n",
    "# Encontrar o n√∫mero √≥timo de clusters\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISE DO N√öMERO √ìTIMO DE CLUSTERS:\")\n",
    "for i, k in enumerate(K_range):\n",
    "    print(f\"K={k}: Inertia={inertias[i]:.2f}, Silhouette={silhouette_scores[i]:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ N√∫mero √≥timo de clusters: {optimal_k} (Silhouette Score: {max(silhouette_scores):.3f})\")\n",
    "\n",
    "# Aplicar K-means com n√∫mero √≥timo de clusters\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans_final.fit_predict(df_clustering_scaled)\n",
    "\n",
    "print(f\"\\nüìä DISTRIBUI√á√ÉO DOS CLUSTERS:\")\n",
    "print(df['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICA√á√ÉO FINAL E EXECU√á√ÉO SEGURA\n",
    "\n",
    "print(\"üîç VERIFICA√á√ÉO FINAL DOS DADOS:\")\n",
    "print(f\"Shape do DataFrame: {df.shape}\")\n",
    "print(f\"Colunas com valores infinitos: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "print(f\"Colunas com valores NaN: {df.select_dtypes(include=[np.number]).isnull().sum().sum()}\")\n",
    "\n",
    "# Verificar se a previs√£o foi feita com sucesso\n",
    "if 'satisfacao_predita' in df.columns:\n",
    "    print(f\"\\n‚úÖ PREVIS√ÉO DE SATISFA√á√ÉO CONCLU√çDA!\")\n",
    "    print(f\"Distribui√ß√£o das previs√µes:\")\n",
    "    print(df['satisfacao_predita'].value_counts())\n",
    "    \n",
    "    # An√°lise de pedidos de risco\n",
    "    pedidos_risco = df[df['satisfacao_predita'] == 'Baixa']\n",
    "    print(f\"\\n‚ö†Ô∏è PEDIDOS DE RISCO: {len(pedidos_risco)} ({len(pedidos_risco)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(pedidos_risco) > 0:\n",
    "        print(\"\\nüìä CARACTER√çSTICAS DOS PEDIDOS DE RISCO:\")\n",
    "        print(f\"Plataforma mais problem√°tica: {pedidos_risco['platform'].value_counts().index[0]}\")\n",
    "        print(f\"Tempo m√©dio de entrega: {pedidos_risco['actual_delivery_minutes'].mean():.1f} min\")\n",
    "        print(f\"Dist√¢ncia m√©dia: {pedidos_risco['distance_km'].mean():.1f} km\")\n",
    "else:\n",
    "    print(\"‚ùå Previs√£o de satisfa√ß√£o n√£o foi executada. Execute a c√©lula anterior primeiro.\")\n",
    "\n",
    "print(f\"\\nüéØ STATUS DAS AN√ÅLISES:\")\n",
    "print(\"‚úÖ Fase 1: Matriz de Correla√ß√£o, Rentabilidade por Plataforma e Regi√£o\")\n",
    "print(\"‚úÖ Fase 2: Modelo de Previs√£o de Demanda\")\n",
    "print(\"‚úÖ Fase 2: An√°lise de Satisfa√ß√£o\")\n",
    "print(\"‚úÖ Fase 2: Segmenta√ß√£o de Clientes\")\n",
    "print(\"\\nüöÄ TODAS AS AN√ÅLISES AVAN√áADAS IMPLEMENTADAS COM SUCESSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 AN√ÅLISE DETALHADA DOS CLUSTERS DE CLIENTES\n",
    "\n",
    "# An√°lise dos clusters por caracter√≠sticas principais\n",
    "analise_clusters = df.groupby('cluster').agg({\n",
    "    'total_brl': ['count', 'mean', 'std'],\n",
    "    'num_itens': 'mean',\n",
    "    'satisfacao_nivel': 'mean',\n",
    "    'distance_km': 'mean',\n",
    "    'tempo_preparo_minutos': 'mean',\n",
    "    'actual_delivery_minutes': 'mean',\n",
    "    'platform_commission_pct': 'mean',\n",
    "    'eficiencia_entrega': 'mean',\n",
    "    'dia_semana': 'mean',\n",
    "    'hora': 'mean',\n",
    "    'fim_de_semana': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Renomear colunas\n",
    "analise_clusters.columns = [\n",
    "    'Qtd_Pedidos', 'Ticket_Medio', 'Ticket_Std',\n",
    "    'Itens_Medio', 'Satisfacao_Media', 'Distancia_Media',\n",
    "    'Tempo_Prep_Medio', 'Tempo_Entrega_Medio', 'Comissao_Media',\n",
    "    'Eficiencia_Media', 'Dia_Semana_Medio', 'Hora_Media', 'Fim_Semana_%'\n",
    "]\n",
    "\n",
    "print(\"üìä AN√ÅLISE DETALHADA DOS CLUSTERS:\")\n",
    "print(analise_clusters)\n",
    "\n",
    "# An√°lise por plataforma dentro de cada cluster\n",
    "cluster_plataforma = pd.crosstab(df['cluster'], df['platform'], normalize='index') * 100\n",
    "print(f\"\\nüì± DISTRIBUI√á√ÉO DE PLATAFORMAS POR CLUSTER (%):\")\n",
    "print(cluster_plataforma.round(1))\n",
    "\n",
    "# An√°lise por regi√£o dentro de cada cluster\n",
    "cluster_regiao = pd.crosstab(df['cluster'], df['macro_bairro'], normalize='index') * 100\n",
    "print(f\"\\nüìç TOP 3 REGI√ïES POR CLUSTER (%):\")\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    top_regioes = cluster_regiao.loc[cluster].nlargest(3)\n",
    "    print(f\"Cluster {cluster}: {', '.join([f'{regiao}({pct:.1f}%)' for regiao, pct in top_regioes.items()])}\")\n",
    "\n",
    "# Definir perfis dos clusters baseados nas caracter√≠sticas\n",
    "perfis_clusters = {}\n",
    "\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    dados_cluster = df[df['cluster'] == cluster]\n",
    "    \n",
    "    # Calcular m√©tricas do cluster\n",
    "    ticket_medio = dados_cluster['total_brl'].mean()\n",
    "    satisfacao_media = dados_cluster['satisfacao_nivel'].mean()\n",
    "    distancia_media = dados_cluster['distance_km'].mean()\n",
    "    tempo_entrega_medio = dados_cluster['actual_delivery_minutes'].mean()\n",
    "    qtd_pedidos = len(dados_cluster)\n",
    "    \n",
    "    # Definir perfil baseado nas caracter√≠sticas\n",
    "    if ticket_medio > df['total_brl'].quantile(0.75) and satisfacao_media > 4.5:\n",
    "        perfil = \"Clientes Premium\"\n",
    "        estrategia = \"Fideliza√ß√£o e expans√£o de produtos premium\"\n",
    "    elif satisfacao_media < 4.0 and tempo_entrega_medio > df['actual_delivery_minutes'].quantile(0.75):\n",
    "        perfil = \"Clientes de Risco\"\n",
    "        estrategia = \"Melhoria de experi√™ncia e reten√ß√£o urgente\"\n",
    "    elif distancia_media < df['distance_km'].quantile(0.5) and satisfacao_media > 4.0:\n",
    "        perfil = \"Clientes Locais Fi√©is\"\n",
    "        estrategia = \"Expans√£o de produtos e hor√°rios de atendimento\"\n",
    "    elif ticket_medio < df['total_brl'].quantile(0.5) and qtd_pedidos > df['cluster'].value_counts().quantile(0.75):\n",
    "        perfil = \"Clientes de Volume\"\n",
    "        estrategia = \"Programas de fidelidade e descontos por volume\"\n",
    "    else:\n",
    "        perfil = \"Clientes Regulares\"\n",
    "        estrategia = \"Marketing direcionado e upselling\"\n",
    "    \n",
    "    perfis_clusters[cluster] = {\n",
    "        'perfil': perfil,\n",
    "        'estrategia': estrategia,\n",
    "        'ticket_medio': ticket_medio,\n",
    "        'satisfacao_media': satisfacao_media,\n",
    "        'qtd_pedidos': qtd_pedidos\n",
    "    }\n",
    "\n",
    "print(f\"\\nüéØ PERFIS DOS CLUSTERS:\")\n",
    "for cluster, info in perfis_clusters.items():\n",
    "    print(f\"\\nCluster {cluster}: {info['perfil']}\")\n",
    "    print(f\"  Estrat√©gia: {info['estrategia']}\")\n",
    "    print(f\"  Ticket M√©dio: R$ {info['ticket_medio']:.2f}\")\n",
    "    print(f\"  Satisfa√ß√£o: {info['satisfacao_media']:.2f}\")\n",
    "    print(f\"  Quantidade: {info['qtd_pedidos']} pedidos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a630eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZA√á√ïES DA FASE 2 - AN√ÅLISES AVAN√áADAS\n",
    "\n",
    "# Criar figura com subplots para visualizar os resultados da Fase 2\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "\n",
    "# 1. Previs√£o de Demanda - Volume de Pedidos\n",
    "axes[0,0].plot(demanda_diaria.index, demanda_diaria['Volume_Pedidos'], alpha=0.7, label='Volume Real')\n",
    "axes[0,0].plot(demanda_diaria.index, demanda_diaria['Volume_MA_7'], color='red', linewidth=2, label='M√©dia M√≥vel 7 dias')\n",
    "axes[0,0].set_title('Previs√£o de Demanda - Volume de Pedidos')\n",
    "axes[0,0].set_ylabel('Pedidos por dia')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. An√°lise de Satisfa√ß√£o - Distribui√ß√£o\n",
    "satisfacao_counts = df['satisfacao_categoria'].value_counts()\n",
    "axes[0,1].pie(satisfacao_counts.values, labels=satisfacao_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0,1].set_title('Distribui√ß√£o de Satisfa√ß√£o')\n",
    "\n",
    "# 3. An√°lise de Satisfa√ß√£o - Fatores Cr√≠ticos\n",
    "fatores = list(fatores_criticos.keys())\n",
    "correlacoes = list(fatores_criticos.values())\n",
    "colors = ['red' if x < -0.3 else 'orange' if x < -0.1 else 'green' for x in correlacoes]\n",
    "axes[0,2].barh(fatores, correlacoes, color=colors)\n",
    "axes[0,2].set_title('Fatores Cr√≠ticos vs Satisfa√ß√£o')\n",
    "axes[0,2].set_xlabel('Correla√ß√£o')\n",
    "\n",
    "# 4. Segmenta√ß√£o - Distribui√ß√£o dos Clusters\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "axes[1,0].bar(cluster_counts.index, cluster_counts.values, color='skyblue')\n",
    "axes[1,0].set_title('Distribui√ß√£o dos Clusters de Clientes')\n",
    "axes[1,0].set_xlabel('Cluster')\n",
    "axes[1,0].set_ylabel('Quantidade de Pedidos')\n",
    "\n",
    "# 5. Segmenta√ß√£o - Ticket M√©dio por Cluster\n",
    "ticket_cluster = df.groupby('cluster')['total_brl'].mean()\n",
    "axes[1,1].bar(ticket_cluster.index, ticket_cluster.values, color='lightgreen')\n",
    "axes[1,1].set_title('Ticket M√©dio por Cluster')\n",
    "axes[1,1].set_xlabel('Cluster')\n",
    "axes[1,1].set_ylabel('Ticket M√©dio (R$)')\n",
    "\n",
    "# 6. Segmenta√ß√£o - Satisfa√ß√£o por Cluster\n",
    "satisfacao_cluster = df.groupby('cluster')['satisfacao_nivel'].mean()\n",
    "axes[1,2].bar(satisfacao_cluster.index, satisfacao_cluster.values, color='lightcoral')\n",
    "axes[1,2].set_title('Satisfa√ß√£o M√©dia por Cluster')\n",
    "axes[1,2].set_xlabel('Cluster')\n",
    "axes[1,2].set_ylabel('Satisfa√ß√£o (1-5)')\n",
    "\n",
    "# 7. An√°lise Temporal - Satisfa√ß√£o por Hora\n",
    "satisfacao_hora = df.groupby('hora')['satisfacao_nivel'].mean()\n",
    "axes[2,0].plot(satisfacao_hora.index, satisfacao_hora.values, marker='o')\n",
    "axes[2,0].set_title('Satisfa√ß√£o M√©dia por Hora do Dia')\n",
    "axes[2,0].set_xlabel('Hora')\n",
    "axes[2,0].set_ylabel('Satisfa√ß√£o M√©dia')\n",
    "\n",
    "# 8. An√°lise Temporal - Volume por Dia da Semana\n",
    "volume_dia = df.groupby('dia_semana')['total_brl'].count()\n",
    "dias_semana = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'S√°b', 'Dom']\n",
    "axes[2,1].bar(dias_semana, volume_dia.values, color='gold')\n",
    "axes[2,1].set_title('Volume de Pedidos por Dia da Semana')\n",
    "axes[2,1].set_ylabel('Quantidade de Pedidos')\n",
    "\n",
    "# 9. An√°lise de Risco - Pedidos de Baixa Satisfa√ß√£o\n",
    "risco_plataforma = pedidos_risco['platform'].value_counts()\n",
    "axes[2,2].pie(risco_plataforma.values, labels=risco_plataforma.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[2,2].set_title('Pedidos de Risco por Plataforma')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéØ RESUMO DA FASE 2 - AN√ÅLISES AVAN√áADAS IMPLEMENTADAS:\")\n",
    "print(\"‚úÖ Modelo de Previs√£o de Demanda - Otimizar Volume\")\n",
    "print(\"‚úÖ An√°lise de Satisfa√ß√£o - Melhorar Experi√™ncia\") \n",
    "print(\"‚úÖ Segmenta√ß√£o de Clientes - Marketing Direcionado\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analise-de-dados-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
